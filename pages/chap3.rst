
.. slide::

Chapitre 4 - Classification
================

üéØ Objectifs du Chapitre
----------------------


.. important::

   √Ä la fin de ce chapitre, vous saurez : 

   - D√©finir un probleme de classification.
   - Mettre en place un pipeline de classification avec PyTorch.
   - √âvaluer les performances d'un mod√®le de classification.   

.. slide::
üìñ 1. Classification - D√©finition
----------------------
La classification est une t√¢che fondamentale en apprentissage supervis√© o√π l'objectif est de pr√©dire une cat√©gorie ou une classe √† laquelle appartient une observation donn√©e, en se basant sur des donn√©es d'entr√©e. Contrairement √† la r√©gression, qui vise √† pr√©dire une valeur dans un domaine continu, la classification pr√©dit une valeur discr√®te.

L√† o√π la r√©gression revient √† trouver une courbe reliant tous les points, la classification revient √† trouver la (ou les) courbes permettant de s√©parer les diff√©rentes classes.

Discr√®te ? Pas tout √† fait ! En r√©alit√©, un mod√®le de classification ne pr√©dit pas directement une classe, mais plut√¥t une probabilit√© pour chaque classe possible. Par exemple, dans un probl√®me de classification binaire (deux classes), le mod√®le peut pr√©dire une probabilit√© de 0.8 pour la classe 1 et 0.2 pour la classe 0. La classe finale est ensuite d√©termin√©e en appliquant un seuil (par exemple, 0.5) : si la probabilit√© de la classe 1 est sup√©rieure √† 0.5, l'observation est class√©e dans la classe 1, sinon dans la classe 0.

.. slide::
üìñ 2. Pr√©dire une classe - One-Hot Encoding
----------------------
Imaginon un probl√®me de classification √† 3 classes... Comment repr√©senter la variable cible ?

Avec ce que nous connaissons d√©j√†, nous pourrions √™tre tent√©s d'encoder les classes arbitrairement comme suit, et demander au mod√®le de pr√©dire une unique valeur (par r√©gression) :

- Classe A : 0
- Classe B : 1
- Classe C : 2

Cependant, cette mod√©lisation comporte au moins deux probl√®mes majeurs : 

- Elle introduit une notion d'ordre entre les classes (0 < 1 < 2), ce qui n'a pas de sens dans un contexte de classification o√π les classes sont simplement des cat√©gories distinctes sans hi√©rarchie.
- On ne saurait pas comment interpr√©ter des valeurs flotantes interm√©diaires (1.5).

.. slide::
Le One-Hot Encoding est une technique de pr√©traitement des donn√©es utilis√©e pour convertir des variables cat√©gorielles en un format num√©rique que les algorithmes d'apprentissage automatique peuvent comprendre. Cette m√©thode est particuli√®rement utile lorsque les cat√©gories n'ont pas d'ordre intrins√®que, comme les couleurs, les types de fruits, ou les classes dans un probl√®me de classification (voir Figure 1).

Le principe du One-Hot Encoding est de cr√©er une nouvelle colonne pour chaque cat√©gorie unique dans la variable cat√©gorielle. Pour chaque observation, la colonne correspondant √† la cat√©gorie de cette observation est marqu√©e par un 1 (indiquant la pr√©sence de cette cat√©gorie), tandis que toutes les autres colonnes sont marqu√©es par un 0 (indiquant l'absence de ces cat√©gories). Par exemple, si nous avons une variable "Animal" avec les cat√©gories "Chien", "Oiseau", et "Chat", le One-Hot Encoding produira trois nouvelles colonnes : "Animal_Chien", "Animal_Oiseau", et "Animal_Chat".

.. figure:: images/one_hot.png
   :align: center
   :width: 400px
   :alt: Illustration du One-Hot Encoding

   **Figure 1** : Illustration du One-Hot Encoding.

.. slide::
On demande alors au mod√®le d'apprentissage de pr√©dire une probabilit√© qu'une donn√©e appartienne √† chaque classe. Par exemple, pour une observation donn√©e, le mod√®le pourrait pr√©dire les probabilit√©s suivantes :

.. figure:: images/classif.png
   :align: center
   :width: 400px
   :alt: Illustration d'une classification

   **Figure 2** : Exemple d'une classification pour un mod√®le d'apprentissage supervis√©.

Ici, le mod√®le pr√©dit une probabilit√© de 0.3 pour la classe Chien, 0.6 pour la classe Oiseau, et 0.1 pour la classe Chat. La classe finale *pr√©dite* est d√©termin√©e en choisissant la classe avec la probabilit√© la plus √©lev√©e (dans ce cas, Oiseau).

.. slide::
Pour s'assurer que les sorties du mod√®le sont bien des probabilit√©s, on applique souvent une fonction d'activation comme la softmax √† la couche de sortie du mod√®le. La fonction **softmax** convertit les scores bruts (appel√©s **logits**) en probabilit√©s en s'assurant que toutes les valeurs sont positives et que leur somme est √©gale √† 1.

.. math::
   softmax(z)_i = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}
o√π $$z$$ est le tenseur de sortie du mod√®le, $$z_i$$ est le score brut pour la classe $$i$$ dans ce tenseur, et $$K$$ est le nombre total de classes.

.. slide::
Dans la pratique, cette fonction d'activation finale n'est n√©cessaire que si la fonction de co√ªt utilis√©e pour entra√Æner le mod√®le ne l'inclut pas d√©j√† (comme c'est le cas avec la Cross-Entropy Loss en PyTorch).
Il suffit donc d'adapter la couche de sortie du mod√®le pour qu'elle produise un vecteur de taille √©gale au nombre de classes (sans appliquer de fonction d'activation comme la softmax en PyTorch).

.. code-block:: python
   import torch
   import torch.nn.functional as F

   class SimpleClassifMLP(torch.nn.Module):
      def __init__(self, input_dim, num_classes=3):
         super().__init__()
         self.fc1 = torch.nn.Linear(input_dim, 16)
         self.out_layer = torch.nn.Linear(16, num_classes) # couche de sortie pour "num_classes"

      def forward(self, x):
         x = F.relu(self.fc1(x))
         x = self.out_layer(x)
         return x  # logits pour "num_classes"
      

.. slide::
üìñ 3. Optimiser et √©valuer un mod√®le de classification supervis√©
----------------------

Traditionnellement, on dissocie les m√©triques d'optimisation de celles d'√©valuation en classification. En effet, les fonctions de co√ªt utilis√©es pour entra√Æner un mod√®le de classification ne sont pas n√©cessairement les m√™mes que celles utilis√©es pour √©valuer ses performances. 
Cette distinction est n√©cessaire car le mod√®le d'apprentissage a besoin d'une fonction de co√ªt diff√©rentiable pour ajuster ses poids via la r√©tropropagation, tandis que les m√©triques d'√©valuation peuvent √™tre non diff√©rentiables et plus adapt√©es √† la t√¢che sp√©cifique. En l'occurance, les m√©triques d'√©valuation en classification sont souvent bas√©es sur des seuils (par exemple, d√©terminer si une probabilit√© est sup√©rieure √† 0.5 pour classer une observation dans une classe particuli√®re), ce qui n'est pas diff√©rentiable.

.. slide::
3.1. Optimiser un mod√®le de classification (fonction de co√ªt)
~~~~~~~~~~~~~~~~~~~

En classification, la fonction de co√ªt la plus couramment utilis√©e est la **Cross-Entropy Loss** (ou entropie crois√©e). Cette fonction continue mesure la diff√©rence entre les distributions de probabilit√© pr√©dites par le mod√®le et les vraies distributions (celles des √©tiquettes r√©elles).

.. math::
   CrossEntropy(y, \hat{y}) = - \sum_{i=1}^{C} y_i \log(\hat{y}_i)
o√π $$C$$ est le nombre de classes, $$y_i$$ est la valeur binairee (0 ou 1) indiquant si la classe $$i$$ est la vraie classe, et $$\hat{y}_i$$ est la probabilit√© pr√©dite par le mod√®le pour la classe $$i$$.

.. slide::
En PyTorch, la Cross-Entropy Loss est impl√©ment√©e dans la classe `torch.nn.CrossEntropyLoss`, qui combine √† la fois la fonction softmax et le calcul de l'entropie crois√©e en une seule √©tape pour des raisons d'efficacit√© num√©rique.
Voici comment l'utiliser dans un pipeline de classification :
.. code-block:: python
   import torch
   import torch.nn as nn
   import torch.optim as optim

   # Supposons que nous avons un mod√®le, des donn√©es d'entr√©e et des √©tiquettes
   model = SimpleClassifMLP(input_dim=10, num_classes=3)
   inputs = torch.randn(5, 10)  # 5 √©chantillons, 10 caract√©ristiques chacun
   labels = torch.tensor([0, 2, 1, 0, 2])  # √©tiquettes r√©elles pour chaque √©chantillon

   # D√©finir la fonction de co√ªt et l'optimiseur
   criterion = nn.CrossEntropyLoss()
   optimizer = optim.Adam(model.parameters(), lr=0.001)

   # Phase d'entra√Ænement
   model.train()
   optimizer.zero_grad()  # R√©initialiser les gradients
   outputs = model(inputs)  # Obtenir les logits du mod√®le
   loss = criterion(outputs, labels)  # Calculer la perte
   loss.backward()  # R√©tropropagation
   optimizer.step()  # Mise √† jour des poids

‚ö†Ô∏è Notez que les labels doivent √™tre fournis sous forme d'indices de classes (entiers) et non sous forme de vecteurs one-hot. La fonction *CrossEntropyLoss* de PyTorch s'occupe √† la fois de convertir les logits en probabilit√©s (softmax) et de convertir les labels en vecteurs one-hot.

.. slide::
3.2. √âvaluer les performances d'un mod√®le de classification
~~~~~~~~~~~~~~~~~~~

Etant donn√© un mod√®le d'apprentissage, on souhaite √©valuer ses performances sur des donn√©es qu'il n'a jamais vues auparavant. Pour chaque √©chantillon, il y a donc 4 possibilit√©s :

- Vrai Positif (VP) : Le mod√®le pr√©dit la classe positive, et c'est correct.
- Faux Positif (FP) : Le mod√®le pr√©dit la classe positive, mais c'est incorrect.
- Vrai N√©gatif (VN) : Le mod√®le pr√©dit la classe n√©gative, et c'est correct.
- Faux N√©gatif (FN) : Le mod√®le pr√©dit la classe n√©gative, mais c'est incorrect.

.. figure:: images/vpfn.png
   :align: center
   :width: 400px
   :alt: Illustration des possibilit√©s d'erreur en classification

   **Figure 3** : Illustration des possibilit√©s d'erreur en classification, Vrai Positif (VP), Faux Positif (FP), Vrai N√©gatif (VN), Faux N√©gatif (FN). 

C'est sur la base de ces 4 possibilit√©s que sont d√©finies les principales m√©triques d'√©valuation en classification.

.. slide::
üìà **Exactitude (Accuracy)** : La proportion de pr√©dictions correctes par rapport au nombre total de pr√©dictions.

- **Objectif :** Maximiser le nombre de pr√©dictions correctes.
- **Int√©r√™t :** Simple √† comprendre et √† calculer.
- **Limite :** Peut √™tre trompeuse en cas de classes d√©s√©quilibr√©es. Exemple : si 95% des √©chantillons appartiennent √† la classe n√©gative, un mod√®le qui pr√©dit toujours la classe n√©gative aura une exactitude de 95%, mais ne sera pas utile.

.. slide::
üìà **Pr√©cision (Precision)** : La proportion de vraies pr√©dictions positives par rapport au nombre total de pr√©dictions positives.

- **Objectif :** Minimiser les faux positifs.
- **Int√©r√™t :** Utile lorsque les faux positifs co√ªtent cher.
- **Limite :** Ne prend pas en compte les faux n√©gatifs. Exemple : dans un test de d√©pistage d'une maladie rare, un mod√®le avec une haute pr√©cision minimisera les faux positifs, mais pourrait manquer de nombreux cas r√©els (faux n√©gatifs).

.. slide::
üìà **Rappel (Recall)** : La proportion de vraies pr√©dictions positives par rapport au nombre total d'exemples positifs.

- **Objectif :** Maximiser les vrais positifs.
- **Int√©r√™t :** Utile lorsque les faux n√©gatifs co√ªtent cher.
- **Limite :** Ne prend pas en compte les faux positifs. Exemple : dans un test de d√©pistage d'une maladie grave, un mod√®le avec un haut rappel minimisera les faux n√©gatifs, mais pourrait g√©n√©rer de nombreux faux positifs (le mod√®le alerte "√† tort").

.. slide::
üìà **Ratio de faux positifs (FPR)** : La proportion de fausses pr√©dictions positives par rapport au nombre total d'exemples n√©gatifs.

- **Objectif :** Minimiser les faux positifs.
- **Int√©r√™t :** Utile pour √©valuer la performance du mod√®le sur la classe n√©gative.
- **Limite :** Ne prend pas en compte les vrais positifs. Exemple : dans un syst√®me de d√©tection de fraude, un faible FPR est crucial pour √©viter d'alerter √† tort les utilisateurs l√©gitimes.

.. slide::
üìà **F1-score** : La moyenne harmonique de la pr√©cision et du rappel, utile lorsque les classes sont d√©s√©quilibr√©es.

- **Objectif :** Trouver un √©quilibre entre pr√©cision et rappel.
- **Int√©r√™t :** Utile lorsque les classes sont d√©s√©quilibr√©es et qu'il faut trouver un compromis entre √©viter les faux positifs et rater les vrais positifs.
- **Limite :** Ne distingue les faux positifs des faux n√©gatifs. Exemple : dans un syst√®me de recommandation, un F1-score √©lev√© indique que le mod√®le est bon pour recommander des √©l√©ments pertinents tout en minimisant les recommandations non pertinentes.


.. slide::
.. figure:: images/classif_metrics.png
   :align: center
   :width: 800px
   :alt: Mesures de performance en classification

   **Figure 4** : Mesures de performance en classification bas√©es sur les concepts de Vrai Positif (VP), Faux Positif (FP), Vrai N√©gatif (VN), et Faux N√©gatif (FN).

.. slide::
‚äû **Matrice de confusion**

La terminologie VP, FP, VN, FN s'applique naturellement aux probl√®mes de classification binaire. Pour les probl√®mes de classification multi-classes, on peut √©tendre ces concepts en utilisant une approche "un contre tous" (one-vs-all) pour chaque classe.
Par exemple, pour une classe sp√©cifique, on peut consid√©rer cette classe comme la classe positive et toutes les autres classes comme la classe n√©gative. On calcule alors VP, FP, VN, FN pour cette classe sp√©cifique. En r√©p√©tant ce processus pour chaque classe, on peut obtenir des m√©triques d'√©valuation pour chaque classe individuelle.

Une m√©thode classique pour visualiser la performance globale en classification multi-classes est la matrice de confusion. Il s'agit d'un tableau qui r√©sume les performances du mod√®le en affichant le nombre de pr√©dictions correctes et incorrectes pour chaque classe.


.. slide::
.. figure:: images/cm.png
   :align: center
   :width: 600px
   :alt: Matrice de confusion

   **Figure 5** : Matrice de confusion d'un mod√®le d'apprentissage sur un probl√®me de classification d'images √† 10 classes, sur un jeu de donn√©es √©quilibr√© (avec 1000 images par classe).

Chaque ligne de la matrice repr√©sente les instances dans une classe r√©elle, tandis que chaque colonne repr√©sente les instances dans une classe pr√©dite. La diagonale principale (de haut en gauche √† bas en droite) montre le nombre d'instances correctement class√©es pour chaque classe, tandis que les autres cellules montrent les erreurs de classification. Dans la Figure 5, on voit donc que 337 images de "Chat" ont √©t√© incorrectement class√©es comme "Chien". En revanche, les chiens ne sont pas consid√©r√©s comme des chats.

Cette technique permet de voir les classes qui sont souvent confondues entre elles, ce qui peut aider √† identifier les faiblesses du mod√®le et √† orienter les efforts d'am√©lioration.

‚ö†Ô∏è Dans un jeu de donn√©es d√©s√©quilibr√©, la matrice de confusion peut √™tre biais√©e en faveur des classes majoritaires. Par exemple, si une classe n'est repr√©sent√©e que par quelques √©chantillons de donn√©es, il est difficile de voir le nombre de faux n√©gatifs pour cette classe dans la matrice de confusion dont les couleurs sont √©talonn√©es en fonction de toutes les classes.

.. slide::
**Projection en 2D**

Rappel : Classiquement, un r√©seau de neurones profond est compos√© de couches r√©parties en deux phases souvent repr√©sent√©es en double D : 

- Une phase d'extraction de caract√©ristiques (couches cach√©es, le nombre de caract√©ristiques grandit pour permettre une meilleure description des donn√©es dans l'espace latent) 
- Une phase de r√©solution de t√¢che (couches finales, le nombre de caract√©ristiques diminue jusqu'√† atteindre la dimension souhait√©e pour la t√¢che, par exemple 1 pour une r√©gression ou K pour une classification).

Une autre mani√®re de visualiser les performances d'un mod√®le de classification est de projeter les donn√©es dans un espace 2D avec des algorithmes de r√©duction de dimension. 
Cette √©tape est r√©alis√©e les caract√©ristiques extraites par le mod√®le (derni√®re couche avant la phase de r√©solution de la t√¢che dans le mod√®le) car c'est ici que les donn√©es sont le mieux s√©par√©es.

La projection en 2D, r√©alis√©e avec des algorithmes comme t-SNE (t-Distributed Stochastic Neighbor Embedding),  UMAP (Uniform Manifold Approximation and Projection) ou PCA (Principal Component Analysis), garantit (jusqu'√† une certaine limite) que les distances observ√©es en 2D correspondent aux distances dans l'espace des caract√©ristiques. Ainsi, si deux points sont proches en 2D, ils devraient √©galement √™tre proches dans l'espace des caract√©ristiques, et vice versa. Il est alors possible d'observer les donn√©es qui, d'apr√®s le mod√®le d'apprentissage, sont similaires ou diff√©rentes. Id√©alement, les donn√©es similaires doivent avoir la m√™me classe.

.. slide::
.. figure:: images/tsne.png
   :align: center
   :width: 600px
   :alt: Projection 2D des donn√©es

   **Figure 6** : Projection 2D des donn√©es d'un mod√®le d'apprentissage sur un probl√®me de classification d'images √† 10 classes, sur un jeu de donn√©es √©quilibr√© (avec 1000 images par classe).

Dans la Figure 6, chaque point correspond √† une image. La couleur du point d√©termine la classe r√©elle de l'image (v√©rit√© terrain). On peut ainsi observer des groupes de donn√©es bien s√©par√©s des autres, ainsi que des groupes qui ont tendance √† se m√©langer (par exemple "Chien" et "Chat"). Gr√¢ce √† cette visualisation, on peut identifier les classes les mieux discrimin√©es ainsi que les erreurs de classification.

.. slide::
3.3. Validation crois√©e
~~~~~~~~~~~~~~~~~~~



.. slide::
üìñ 4. D√©s√©quilibrage de classes
----------------------

.. slide::
üìñ 5. Classification avanc√©e
----------------------

.. slide::
5.1. Classification multi-label
~~~~~~~~~~~~~~~~~~~

.. slide::
5.1. Classification hi√©rarchique
~~~~~~~~~~~~~~~~~~~