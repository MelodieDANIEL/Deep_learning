.. slide::
Chapitre 2 ‚Äî Perceptron multi-couches 
===========================================

üéØ Objectifs du Chapitre
----------------------


.. important::

    √Ä la fin de cette section,  vous saurez :  

    - Le fonctionnement du perceptron simple.
    - Utiliser une fonction d'activation adapt√©e.  
    - L‚Äôimportance de la normalisation / standardisation des donn√©es et l'usage des epochs.  
    - Construire un r√©seau de neurones avec ``torch.nn``. 
    - Faire un entra√Ænement simple d‚Äôun MLP pour un probl√®me de r√©gression.   
    - Suivre l‚Äô√©volution de la loss et interpr√©ter les r√©sultats.  
    - Utiliser ``torch-summary`` pour inspecter l‚Äôarchitecture du r√©seau.  


.. slide::

üìñ 1. Rappels sur les perceptrons
----------------------

Le perceptron multi-couches (MLP de Multi-Layers Perceptron en anglais) est la brique de base des r√©seaux de neurones modernes. Dans ce chapitre, nous allons l‚Äôappliquer √† des probl√®mes de r√©gression simple. Avant de commencer, voici quelques rappels.

1.1. Perceptron simple
~~~~~~~~~~~~~~~~~~~~~~

Le perceptron est le bloc de base d‚Äôun r√©seau de neurones. Il r√©alise une transformation lin√©aire suivie (ou pas) d‚Äôune fonction d‚Äôactivation telle que :  

  .. math::

     y = \sigma(Wx + b)

  o√π :  
   - $$y$$ est la sortie du perceptron, 
   - $$\sigma$$ est une fonction d‚Äôactivation, 
   - $$W$$ est la matrice des poids,  
   - $$b$$ est le biais et  
   - $$x$$ est l'ensemble des entr√©es du perceptron.  

.. slide::
1.2. Perceptron intuition
~~~~~~~~~~~~~~~~~~~~~~
.. image:: images/chap2_perceptron.png
    :alt: perceptron
    :align: center
    :width: 40%

avec $$y= \sigma(x_1*w_1 + x_2*w_2 + ...+ x_i*w_i + ... + x_n*w_n + b)$$

üí° **Intuition :**

    - Chaque poids $$w_i$$ mesure l‚Äôimportance de la caract√©ristique $$x_i$$.  
    - Le biais $$b$$ d√©place la fronti√®re de d√©cision.  
    - La fonction d‚Äôactivation permet d‚Äôintroduire de la non-lin√©arit√©, indispensable pour mod√©liser des relations complexes mais nous en parlerons plus en d√©tails par la suite.  


.. slide::
1.3. Mise √† jour des param√®tres
~~~~~~~~~~~~~~~~~~~~~~

Un perceptron poss√®de deux types de **param√®tres** : les **poids** et le **biais**.  

Lors de l‚Äôentra√Ænement, on souhaite ajuster ces param√®tres pour am√©liorer les pr√©dictions du mod√®le.  Pour cela, il faut mettre √† jour les poids apr√®s avoir calcul√© la loss gr√¢ce √† la fonction de perte et le gradient gr√¢ce √† l'optimiseur comme expliqu√© dans le chapitre pr√©c√©dent.  

Pour rappel, on met √† jours les param√®tres du mod√®le gr√¢ce √† l'√©quation introduite dans le chapitre pr√©c√©dent. 

.. math::

    \theta \leftarrow \theta - \eta \, \nabla_\theta \mathcal{L}(\theta)

o√π :  

    - $$\theta$$ repr√©sente l‚Äôensemble des param√®tres du mod√®le (ici $$W$$ et $$b$$),  
    - $$\mathcal{L}$$ est la fonction de perte,  
    - $$\nabla_\theta \mathcal{L}$$ est le gradient de la perte par rapport aux param√®tres,  
    - $$\eta$$ est le taux d‚Äôapprentissage (learning rate en anglais).


.. slide::
1.4. Exemples d'applications du perceptron simple
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Un perceptron simple ne peut r√©soudre que les probl√®mes lin√©airement s√©parables puisqu'en trouvant les param√®tres du mod√®le, le perceptron trace une droite dans le plan des entr√©es et s√©pare les points selon qu‚Äôils sont au-dessus ou en dessous de cette droite.

**Exemple 1 : porte logique ET**

+-----+-----+-------+
| x‚ÇÅ  | x‚ÇÇ  | y=ET  |
+=====+=====+=======+
|  0  |  0  |   0   |
+-----+-----+-------+
|  0  |  1  |   0   |
+-----+-----+-------+
|  1  |  0  |   0   |
+-----+-----+-------+
|  1  |  1  |   1   |
+-----+-----+-------+

Dans ce cas, une droite s√©pare bien les deux classes :  

    - la classe $$0$$ (points en bas √† gauche, en haut √† gauche, en bas √† droite),  
    - la classe $$1$$ (point en haut √† droite).  

Un perceptron simple peut donc apprendre cette fonction.

.. slide::
**Exemple 2 : porte logique XOR**

+-----+-----+--------+
| x‚ÇÅ  | x‚ÇÇ  | y=XOR  |
+=====+=====+========+
|  0  |  0  |   0    |
+-----+-----+--------+
|  0  |  1  |   1    |
+-----+-----+--------+
|  1  |  0  |   1    |
+-----+-----+--------+
|  1  |  1  |   0    |
+-----+-----+--------+

Ici, il est impossible de tracer une seule droite qui s√©pare correctement les classes. Autrement dit, XOR n‚Äôest pas lin√©airement s√©parable.  

.. image:: images/chap2_et_vs_xor.png
   :alt: Repr√©sentation du XOR dans le plan (non-s√©parable lin√©airement)
   :align: center
   :width: 300%

**Conclusion :** 

    - Le perceptron simple suffit pour des t√¢ches lin√©aires (comme ET, OU).  
    - Pour r√©soudre des probl√®mes plus complexes comme XOR, il faut introduire plusieurs couches de neurones et des fonctions d‚Äôactivation non-lin√©aires : c‚Äôest le principe du **perceptron multi-couches (MLP)**. 

.. slide::
1.5. Faire un perceptron dans PyTorch
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Pour cr√©er un perceptron simple dans PyTorch, on peut utiliser la fonction ``Linear`` de ``torch.nn``, qui impl√©mente une couche lin√©aire (ou affine) : $$y = Wx + b$$. La fonction ``Linear`` prend en entr√©e le nombre d'entr√©e $$x$$ et le nombre de sortie $$y$$.

.. code-block:: python

    import torch
    import torch.nn as nn

    # Donn√©es ET
    X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32)
    y = torch.tensor([[0],[0],[0],[1]], dtype=torch.float32)

    # Mod√®le lin√©aire (perceptron)
    model = nn.Linear(2, 1, bias=True)

    # Loss function et optimiseur
    loss_fc = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)

    # Entra√Ænement
    for _ in range(500):
        optimizer.zero_grad()
        loss = loss_fc(model(X), y)
        loss.backward()
        optimizer.step()

    # R√©sultat
    with torch.no_grad():
        print((model(X)).round())
        print(model.weight, model.bias)

**Remarque** : si maintenant on change les entr√©es et sorties pour le XOR, le mod√®le ne pourra pas apprendre correctement la fonction (les $$W$$ restent √† 0 comme √† l'initialisation). Vous pouvez faire le test pour v√©rifier.

.. slide::

üìñ 2. Fonction d'activation
-----------

Les fonctions d‚Äôactivation introduisent de la non-lin√©arit√© dans le mod√®le, ce qui permet de mieux capturer des relations complexes dans les donn√©es. Sans une fonction d'activation, un perceptron (ou m√™me plusieurs formant un r√©seau de neurones de plusieurs couches) ne ferait que des combinaisons lin√©aires et ne pourrait pas r√©soudre des probl√®mes non lin√©aires comme XOR. 

.. slide::
2.1. √âquations des fonctions d'activation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Voici quatre fonctions d‚Äôactivation couramment utilis√©es :

1. **Sigmo√Øde** : $$\sigma(x) = \frac{1}{1 + e^{-x}}$$
   - Sortie comprise entre 0 et 1.
   - Utilis√©e pour les probl√®mes de classification binaire.

2. **Tanh** : $$\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$$
   - Sortie comprise entre -1 et 1.
   - Souvent utilis√©e dans les couches cach√©es des r√©seaux de neurones.

3. **ReLU (de Rectified Linear Unit en anglais)** : $$\text{ReLU}(x) = \max(0, x)$$
   - Sortie nulle pour les entr√©es n√©gatives.
   - La plus utilis√©e dans les r√©seaux de neurones profonds en raison de sa simplicit√© et de son efficacit√©.

4. **Softmax** : $$\text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}$$
   - Transforme un vecteur en une distribution de probabilit√© (chaque sortie est comprise entre 0 et 1 et la somme vaut 1).
   - Utilis√©e en sortie des mod√®les de classification multi-classes.

.. slide::
2.2. Repr√©sentation graphique des fonctions d'activation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.. image:: images/chap2_fonctions_d_activation.png
   :alt: Repr√©sentation des fonctions d'activation
   :align: center
   :width: 200%

.. slide::
2.3. Les fonctions d'activation dans PyTorch
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Dans PyTorch, les fonctions d'activation sont disponibles dans la biblioth√®que ``torch.nn``. Voici quelques exemples :

1. **Sigmo√Øde** : ``nn.sigmoid(x)``
2. **Tanh** : ``nn.tanh(x)``
3. **ReLU** : ``nn.relu(x)``
4. **Softmax** : ``nn.softmax(x, dim=1)``


.. slide::
2.4. R√¥le de la fonction d‚Äôactivation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Reprenons le probl√®me ET avec un perceptron.

- **Sans fonction d‚Äôactivation** :  
  Le perceptron calcule une combinaison lin√©aire des entr√©es : $$ z = w_1 x_1 + w_2 x_2 + b $$.

  La sortie est un nombre r√©el, positif ou n√©gatif. Pour classer les donn√©es, on fixe un seuil arbitraire (par exemple : si $$z > 0$$ alors classe 1, sinon 0). La fronti√®re de d√©cision reste **lin√©aire**.

- **Avec une fonction d'activation (la fonction sigmo√Øde par exemple)** :  
  On applique une transformation non lin√©aire : $$\hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}}$$.

  La sortie est toujours comprise entre 0 et 1. On peut alors l‚Äôinterpr√©ter comme une **probabilit√©** qui mesure la confiance du mod√®le dans sa pr√©diction : proche de 0 ‚Üí classe 0 et proche de 1 ‚Üí classe 1. Le seuil devient naturel : **0.5**.

.. note::
Remarque : Dans le cas o√π le probl√®me √† r√©soudre est non lin√©airement s√©parable (comme XOR), une fonction d‚Äôactivation seule ne suffit pas. Il faut empiler plusieurs couches de neurones avec des fonctions d‚Äôactivation entre chaque couche pour capturer la complexit√© des donn√©es.


.. slide::
2.5. Exemple d'utilisation des fonctions d'activation
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Voici un exemple d'utilisation des fonctions d'activation pour le probl√®me ET avec un perceptron :

.. code-block:: python

    import torch
    import torch.nn as nn

    # Donn√©es ET
    X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32)
    y = torch.tensor([[0],[0],[0],[1]], dtype=torch.float32)

    # --- Cas 1 : Perceptron sans activation ---
    linear = nn.Linear(2, 1, bias=True)
    with torch.no_grad():
        linear.weight[:] = torch.tensor([[1., 1.]])  # w1=1, w2=1
        linear.bias[:] = torch.tensor([-1.5])        # b=-1.5

    z = linear(X)  # sortie brute
    print("Sorties sans activation :")
    print(z)

    # --- Cas 2 : Perceptron avec sigmo√Øde ---
    sigmoid = nn.Sigmoid()
    y_hat = sigmoid(z)
    print("\nSorties avec sigmo√Øde :")
    print(y_hat)

Une sortie brute comme -1.5 devient 0.18 apr√®s sigmo√Øde, et 0.5 devient 0.62 : la sigmoid transforme les nombres en valeurs entre 0 et 1, les rendant interpr√©tables comme des probabilit√©s.

.. slide::
2.6. Choisir la fonction d'activation adapt√©e
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
On peut choisir la fonction d‚Äôactivation en fonction de plusieurs crit√®res: le probl√®me √† r√©soudre ou la convergence de l'entra√Ænement.

**Choix selon le contexte** : 

  - Pour une sortie binaire, la sigmo√Øde est adapt√©e car elle renvoie une valeur entre 0 et 1, interpr√©table comme une probabilit√©.  
  - Pour une sortie multi-classes, la fonction Softmax normalise les valeurs pour obtenir une distribution de probabilit√©.  
  - Pour des sorties continues ou pour moduler les valeurs internes, ReLU ou Tanh peuvent √™tre utilis√©es.

**Impact sur l‚Äôapprentissage** :  
  Certaines fonctions d‚Äôactivation influencent la vitesse de convergence. Par exemple, la sigmo√Øde borne les sorties, ce qui peut r√©duire l‚Äôamplitude des gradients et ralentir l‚Äôapprentissage pour de grandes valeurs absolues.

.. slide::
üìñ 3. Epoch
-----------

Lorsqu‚Äôon entra√Æne un mod√®le de machine learning, il est n√©cessaire de pr√©senter plusieurs fois l‚Äôensemble des donn√©es d‚Äôapprentissage $$x$$ au mod√®le afin d‚Äôajuster correctement ses param√®tres.

3.1 D√©finitions
~~~~~~~~~~~~~~~~~~~~~~~~~~

- **It√©ration** : mise √† jour des param√®tres du mod√®le apr√®s avoir trait√© un seul exemple ou un mini-batch.  
- **Batch / mini-batch** : sous-ensemble d‚Äôexemples utilis√© pour calculer la descente de grandient et la mise √† jour des param√®tres.  
- **Epoch** : passage complet sur toutes les donn√©es d‚Äôapprentissage.  

**Exemple** :

Si vous disposez de 1000 exemples et que vous utilisez des mini-batchs de 100 exemples chacun, une epoch correspond √† 10 it√©rations (1000 √∑ 100). Apr√®s chaque epoch, chaque exemple de l‚Äôensemble d‚Äôapprentissage a √©t√© utilis√© exactement une fois pour mettre √† jour les param√®tres du mod√®le.

.. slide::
3.2 Pourquoi effectuer plusieurs epochs‚ÄØ?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Au d√©but de l‚Äôentra√Ænement, le mod√®le commet souvent de grandes erreurs.  Chaque epoch permet aux poids et aux biais de s‚Äôajuster progressivement, am√©liorant ainsi les pr√©dictions. En pratique, plusieurs dizaines ou centaines d‚Äôepochs sont souvent n√©cessaires pour que la loss se stabilise et que le mod√®le converge vers une bonne solution.

üí° **Intuition** : imaginez un perceptron comme un √©l√®ve qui apprend : il ne retient pas tout parfaitement du premier coup. Il faut plusieurs passages sur les m√™mes exercices pour ma√Ætriser la t√¢che.


.. slide::

üìñ 4. Normalisation et standardisation des donn√©es
--------------------------------------------------

Avant d'entra√Æner un mod√®le, il est important de pr√©parer les donn√©es pour que l‚Äôapprentissage soit efficace. Pour cela, deux op√©rations courantes sont la normalisation et la standardisation.

4.1. Normalisation
~~~~~~~~~~~~~~~~~

La normalisation consiste √† mettre les valeurs dans une plage donn√©e, souvent entre 0 et 1. Cela est utile lorsque les donn√©es ont des √©chelles tr√®s diff√©rentes. Pour cela, il faut appliquer la formule suivante √† chaque donn√©e:

.. math::

   x'_i = \frac{x_i - x_\text{min}}{x_\text{max} - x_\text{min}}

- $$x_\text{min}$$ et $$x_\text{max}$$ sont respectivement la valeur minimale et maximale de la variable.  
- $$x'_i$$ est la valeur normalis√©e.

.. slide::
4.2. Exemple de normalisation avec PyTorch
~~~~~~~~~~~~~~~~~

.. code-block:: python

    import torch
    X = torch.tensor([[1., 50.],[2., 60.],[3., 55.]])
    X_min = X.min(dim=0).values
    X_max = X.max(dim=0).values
    X_norm = (X - X_min) / (X_max - X_min)
    print(X_norm)


.. slide::
4.3. Standardisation
~~~~~~~~~~~~~~~~~~

La standardisation consiste √† centrer et r√©duire les variables : on soustrait la moyenne et on divise par l‚Äô√©cart-type. C‚Äôest particuli√®rement utile pour les algorithmes bas√©s sur le gradient (comme les perceptrons), car cela acc√©l√®re la convergence. Pour standardiser les donn√©es voici la formule √† appliquer pour chaque donn√©e :

.. math::

   x'_i = \frac{x_i - \mu}{\sigma}

- $$\mu$$ est la moyenne de la variable.  
- $$\sigma$$ est l‚Äô√©cart-type.  

.. slide::
4.4. Exemple de standardisation avec PyTorch
~~~~~~~~~~~~~~~~~~
 Contrairement √† la normalisation, la standardisation a une fonction dans PyTorch pr√©-impl√©ment√©e nomm√©e ``torch.nn.BatchNorm1d``. Voici comment l'impl√©menter avec PyTorch :

.. code-block:: python
    import torch
    import torch.nn as nn

    X = torch.tensor([[1., 50.],[2., 60.],[3., 55.]], dtype=torch.float32)

    # Standardisation "manuelle"
    X_mean = X.mean(dim=0)
    X_std = X.std(dim=0)
    X_stdized = (X - X_mean) / X_std
    print("Standardisation manuelle :")
    print(X_stdized)

    # Standardisation avec BatchNorm1d
    batchnorm = nn.BatchNorm1d(num_features=2, affine=False)
    X_stdized_bn = batchnorm(X)
    print("\nStandardisation avec BatchNorm1d :")
    print(X_stdized_bn)

.. slide::
4.5. Normalisation vs. Standardisation
~~~~~~~~~~~~~~~~~~
   
La standardisation est souvent pr√©f√©r√©e √† la normalisation car elle est **plus robuste aux valeurs aberrantes** et permet une **convergence plus rapide** du mod√®le.

- **Robustesse aux valeurs aberrantes** : la standardisation centre et r√©duit les donn√©es par rapport √† la moyenne et √† l‚Äô√©cart-type, plut√¥t que de les ramener dans une plage fixe comme la normalisation Min-Max. Une valeur tr√®s grande ou tr√®s petite affecte moins l‚Äô√©chelle globale et n‚Äô√©crase pas les autres donn√©es.

- **Convergence plus rapide** : la standardisation met toutes les variables sur une √©chelle comparable. Sans standardisation, une variable avec de grandes valeurs provoque de tr√®s grands gradients dans sa direction, tandis qu‚Äôune variable plus petite change lentement. Le gradient combin√© suit alors une trajectoire en zigzag, avan√ßant lentement vers le minimum. En standardisant, les gradients sont √©quilibr√©s et le mod√®le descend plus directement vers la solution optimale.

.. slide::
4.6. Ce qui est attendu apr√®s la standardisation
~~~~~~~~~~~~~~~~~~

Apr√®s avoir centr√© et r√©duit les donn√©es, la standardisation permet g√©n√©ralement d'avoir une **moyenne proche de 0** et un **√©cart-type proche de 1** pour chaque variable.

**Pourquoi ?**

  - Une moyenne proche de 0 aide les fonctions d'activation et la descente de gradient √† mieux fonctionner, sans que le mod√®le ne doive apprendre un biais pour d√©caler toutes les donn√©es.
  - Un √©cart-type proche de 1 met toutes les donn√©es sur une √©chelle comparable, ce qui √©vite que certaines variables dans les donn√©es dominent les gradients et permet une descente plus directe vers le minimum de la loss.


.. note::
   Si la standardisation est appliqu√©e sur un mini-batch (par exemple avec ``BatchNorm1d``), la moyenne et l‚Äô√©cart-type sont calcul√©s sur ce mini-batch. Dans ce cas, la moyenne n‚Äôest pas exactement 0 et l‚Äô√©cart-type n‚Äôest pas exactement 1 pour l‚Äôensemble du dataset. De plus, certains modules comme BatchNorm peuvent apprendre un scale et un shift, modifiant l√©g√®rement ces valeurs finales.

**Est-ce grave si ce n'est pas exactement 0 et 1 ?**

  - Pas n√©cessairement : une moyenne et un √©cart-type approximatifs suffisent g√©n√©ralement pour que l'apprentissage reste efficace.
  - Par contre, si les valeurs sont tr√®s √©loign√©es de 0 ou tr√®s dispers√©es, certaines fonctions d'activation peuvent saturer et ralentir la convergence.


.. slide:: 

üìñ 5. R√©seaux de neurones multi-couches (MLP)
--------------------------------------------

Les r√©seaux de neurones multi-couches (MLP, de l'anglais Multi-Layer Perceptron) permettent de r√©soudre des probl√®mes non lin√©aires comme XOR, que le perceptron simple ne peut pas g√©rer. Un MLP se compose de **couches lin√©aires** suivies de **fonctions d'activation**, et peut √™tre construit tr√®s simplement avec ``torch.nn.Sequential``.

5.1. D√©finitions
~~~~~~~~~~~~~~~~

- **Une couche** d'un MLP se compose d'un ensemble de perceptrons. Chaque perceptron (aussi appel√© neurone) re√ßoit les m√™mes entr√©es et produit une sortie individuelle. La combinaison des sorties de tous les perceptrons forme le vecteur de sortie de la couche.

- Il existe plusieurs types de couches :
  - **La couche d'entr√©e** re√ßoit les features du dataset et les transmet √† la premi√®re couche cach√©e.
  - **Les couches cach√©es** sont situ√©es entre l'entr√©e et la sortie, elles permettent de mod√©liser des relations non lin√©aires entre les variables.
  - **La couche de sortie** produit la sortie finale du r√©seau (par exemple, une probabilit√© pour la classification binaire).

.. slide:: 
5.2. Construction d'un MLP
~~~~~~~~~~~~~~~~~~~~~~~~~~

Pour construire un MLP, il faut choisir le nombre de couches et de neurones par couche ainsi que la fonction d'activation √† utiliser apr√®s chaque couche. Il n‚Äôest g√©n√©ralement pas possible de conna√Ætre √† l‚Äôavance le nombre exact √† mettre. On teste plusieurs architectures pour trouver celle qui converge correctement et rapidement.

- Nombre de couches cach√©es : g√©n√©ralement 1 ou 2 couches suffisent pour des probl√®mes simples comme XOR. Pour des probl√®mes plus complexes, plusieurs couches peuvent √™tre n√©cessaires.  
- Nombre de neurones par couche : il n‚Äôexiste pas de r√®gle stricte. On choisit un nombre suffisant pour capturer la complexit√© du probl√®me, mais pas trop pour √©viter le surapprentissage (lorsque le mod√®le s'adapte trop aux donn√©es d'entra√Ænement et ne g√©n√©ralise pas bien sur de nouvelles donn√©es).  
- En pratique, on peut commencer par un petit nombre de neurones et augmenter si le mod√®le n‚Äôarrive pas √† converger correctement.

üí° R√©sum√© :  
Chaque couche d‚Äôun MLP est un ensemble de perceptrons. Les couches cach√©es permettent de mod√©liser la non-lin√©arit√©, et le nombre de couches et de neurones doit √™tre choisi en fonction de la complexit√© du probl√®me et de la performance souhait√©e.


.. slide:: 
5.3. Construire un MLP simple avec ``torch.nn``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Pour cr√©er un MLP dans PyTorch, on utilise principalement :  

- ``Sequential`` : permet d‚Äôempiler facilement les couches les unes apr√®s les autres.  
- ``Linear`` : cr√©e une couche affine, c‚Äôest-√†-dire une transformation de la forme $$y = Wx + b$$.  
- Fonctions d‚Äôactivation : introduisent de la **non-lin√©arit√©** dans le mod√®le (par exemple ``nn.ReLU()`` ou ``nn.Sigmoid()``).

Exemple minimal d‚Äôun r√©seau de neurones pour une r√©gression 1D avec un MLP √† deux couches cach√©es :

.. code-block:: python

   import torch.nn as nn

   model = nn.Sequential(
       nn.Linear(1, 10),   # couche d'entr√©e 1D -> premi√®re couche cach√©e 10 neurones
       nn.ReLU(),           # activation non lin√©aire
       nn.Linear(10, 5),    # deuxi√®me couche cach√©e avec 5 neurones
       nn.ReLU(),           # activation non lin√©aire
       nn.Linear(5, 1)      # couche de sortie 1D
   )

üí° Remarques :  

    - La premi√®re couche transforme l‚Äôentr√©e en un vecteur de dimension 10.
    - La deuxi√®me couche r√©duit ce vecteur √† 5 dimensions, permettant au r√©seau de combiner et transformer les features.
    - Chaque couche cach√©e est suivie d‚Äôune fonction d‚Äôactivation capturant la non-lin√©arit√©. 
    - La couche finale produit la sortie finale du r√©seau.

.. note:: 
    **Important** : La dimension de sortie d‚Äôune couche doit correspondre √† la dimension d‚Äôentr√©e de la couche suivante.  


.. slide:: 
5.4. Construire un MLP avec une classe
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Dans PyTorch, il est courant de d√©finir un mod√®le en cr√©ant une classe qui h√©rite de ``nn.Module``. Cela permet de mieux organiser le code, de r√©utiliser facilement le mod√®le. Dans ce cas, la m√©thode ``forward``  d√©crit comment les donn√©es traversent le r√©seau.

Voici le m√™me exemple que pr√©c√©demment avec une classe :

.. code-block:: python

   import torch
   import torch.nn as nn

   class SimpleMLP(nn.Module):
       def __init__(self):
           super(SimpleMLP, self).__init__()
           self.fc1 = nn.Linear(1, 10)   # premi√®re couche cach√©e
           self.fc2 = nn.Linear(10, 5)   # deuxi√®me couche cach√©e
           self.fc3 = nn.Linear(5, 1)    # couche de sortie
           self.relu = nn.ReLU()         # fonction d'activation

       def forward(self, x):
           x = self.relu(self.fc1(x))
           x = self.relu(self.fc2(x))
           x = self.fc3(x)
           return x

    # Cr√©ation d'une instance du mod√®le
    model = SimpleMLP()

üí° Remarques : 

    - La m√©thode ``forward`` d√©finit comment les donn√©es passent de la couche d'entr√©e √† la sortie, en appliquant les fonctions d‚Äôactivation entre les couches.  
    - L‚Äôavantage de la classe : elle permet de s√©parer la d√©finition du mod√®le et l‚Äôentra√Ænement, ce qui rend le code plus clair et modulable.  
    - On peut facilement r√©utiliser ce mod√®le pour diff√©rentes entr√©es ou probl√®mes.


.. slide::
5.5. R√©soudre XOR avec un MLP
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Comme expliqu√© pr√©c√©demment, un perceptron simple ne peut pas r√©soudre le probl√®me XOR, m√™me avec une fonction d‚Äôactivation, car il ne fait qu‚Äôune s√©paration lin√©aire (une droite).

    - Pour le XOR, il faut un r√©seau de neurones avec au moins une couche cach√©e et une fonction d‚Äôactivation √† la sortie de la couche cach√©e.
    - La fronti√®re de d√©cision apprise n‚Äôest plus une droite mais une courbe form√©e par la combinaison des sorties de plusieurs neurones. Visuellement, cela peut ressembler √† deux demi-plans combin√©s ou √† une courbe ferm√©e entourant certains points, selon l‚Äôactivation utilis√©e (Tanh ou ReLU).


Exemple minimal en PyTorch avec une seule couche cach√©e et une activation non-lin√©aire :

.. code-block:: python

    import torch
    import torch.nn as nn
    import torch.optim as optim
    import matplotlib.pyplot as plt

    # Donn√©es XOR
    X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32)
    y = torch.tensor([[0],[1],[1],[0]], dtype=torch.float32)

    # D√©finition du MLP avec une classe
    class XORMLP(nn.Module):
        def __init__(self):
            super(XORMLP, self).__init__()
            self.fc1 = nn.Linear(2, 4)  # couche cach√©e 1
            self.fc2 = nn.Linear(4, 1)  # couche de sortie
            self.activation = nn.ReLU()
            self.out_activation = nn.Sigmoid()
        
        def forward(self, x):
            x = self.activation(self.fc1(x))
            x = self.out_activation(self.fc2(x))
            return x

    # Cr√©ation du mod√®le
    model = XORMLP()

    # Optimiseur et fonction de perte
    optimizer = optim.Adam(model.parameters(), lr=0.05)
    fc_loss = nn.MSELoss()

    # Entra√Ænement
    for epoch in range(5000):
        y_pred = model(X)
        loss = fc_loss(y_pred, y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    # V√©rification num√©rique
    with torch.no_grad():
        y_pred_train = model(X)
        y_class = (y_pred_train > 0.5).float()
        print("Pr√©dictions (probabilit√©s) :\n", y_pred_train)
        print("Classes pr√©dites :\n", y_class)
        print("Classes r√©elles :\n", y)
        correct = (y_class == y).all()
        print("Toutes les pr√©dictions sont correctes :", correct)

    # Affichage de la fronti√®re de d√©cision
    xx, yy = torch.meshgrid(torch.linspace(-0.5, 1.5, 200),
                            torch.linspace(-0.5, 1.5, 200))
    grid = torch.cat([xx.reshape(-1,1), yy.reshape(-1,1)], dim=1)
    with torch.no_grad():
        zz = model(grid).reshape(xx.shape)

    plt.contourf(xx, yy, zz, levels=[0,0.5,1], alpha=0.3, colors=["red","blue"])
    plt.scatter(X[:,0], X[:,1], c=y[:,0], cmap="bwr", edgecolors="k", s=100)
    plt.title("Fronti√®re de d√©cision XOR avec MLP en classe")
    plt.xlabel("x1")
    plt.ylabel("x2")
    plt.show()

üí° Remarques :

- La fonction d‚Äôactivation dans la couche cach√©e est essentielle pour r√©soudre des probl√®mes non lin√©aires comme XOR.
- La sortie finale est transform√©e par la Sigmo√Øde, produisant une probabilit√© entre 0 et 1 pour la classification binaire.
- M√™me un petit MLP avec une seule couche cach√©e de 4 neurones suffit pour apprendre XOR gr√¢ce √† la non-lin√©arit√© introduite par ReLU.
- L‚Äôutilisation d‚Äôune classe et de la m√©thode ``forward`` rend le code plus modulable et facilite l‚Äôexp√©rimentation avec diff√©rentes architectures de MLP.
- Vous pouvez remplacer la ReLU par une Tanh et voir la diff√©rence dans l'affichage.


.. slide::
5.6. Standardisation et entra√Ænement d'un MLP sur un exemple de r√©gression
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

On repart avec un exemple de r√©gression simple pour illustrer l'importance de la standardisation des donn√©es avant l'entra√Ænement d'un MLP. L'objectif est de pr√©dire la sortie y pour de nouvelles entr√©es x que celles sur lesquelles le mod√®le a √©t√© entra√Æn√©.

.. code-block:: python

   import torch
   import torch.nn as nn
   import torch.optim as optim
   import matplotlib.pyplot as plt

   # Donn√©es
   X = torch.tensor([[0.],[10.],[20.],[30.],[40.],[50.]])
   y = 2*X + 1 # relation lin√©aire exacte
   # y = 2*X + 1 + torch.randn_like(X)*5  # relation lin√©aire bruit√©e

   # Standardisation
   X_mean, X_std = X.mean(), X.std()
   X_stdized = (X - X_mean)/X_std

   # Mod√®le simple
   class MLP(nn.Module):
       def __init__(self):
           super().__init__()
           self.net = nn.Sequential(
               nn.Linear(1, 5),
               nn.ReLU(),
               nn.Linear(5,1)
           )
       def forward(self, x):
           return self.net(x)

   # Mod√®les
   model_no_std = MLP()
   model_std = MLP()

   # Optimiseur
   optimizer_no_std = optim.SGD(model_no_std.parameters(), lr=0.001)
   optimizer_std = optim.SGD(model_std.parameters(), lr=0.01)

   # Entra√Ænement
   for _ in range(5000):
       # Sans standardisation
       pred_no_std = model_no_std(X)
       loss_no_std = ((pred_no_std - y)**2).mean()
       optimizer_no_std.zero_grad()
       loss_no_std.backward()
       optimizer_no_std.step()

       # Avec standardisation
       pred_std = model_std(X_stdized)
       loss_std = ((pred_std - y)**2).mean()
       optimizer_std.zero_grad()
       loss_std.backward()
       optimizer_std.step()

   # Test des pr√©dictions
   X_test = torch.tensor([[0.],[60.]])
   X_test_std = (X_test - X_mean)/X_std

   with torch.no_grad():
       preds_no_std = model_no_std(X_test)
       preds_std = model_std(X_test_std)

   print("Pr√©dictions finales (Sans standardisation) :", preds_no_std.squeeze().tolist())
   print("Pr√©dictions finales (Avec standardisation)  :", preds_std.squeeze().tolist())

   # Visualisation
   plt.scatter(X, y, color='black', label='Donn√©es')
   plt.scatter(X_test, preds_no_std, color='red', label='Sans standardisation')
   plt.scatter(X_test, preds_std, color='blue', label='Avec standardisation')
   plt.legend()
   plt.title("Impact de la standardisation sur la pr√©diction finale")
   plt.xlabel("x")
   plt.ylabel("y")
   plt.show()

.. slide::
5.7. Analyse des r√©sultats de l'exemple de r√©gression
~~~~~~~~~~~~~~~~~~~~~~~~~~
Les sorties attendues sont $$y_true = [1, 121]$$.

- **Sans standardisation** :  
  Pr√©dictions finales $$\approx [1.0, 60.98]$$ ‚Üí Le mod√®le pr√©dit correctement pour $$x=0$$ mais extrapole mal pour $$x=60$$.  Cela montre que l‚Äô√©chelle des donn√©es peut d√©s√©quilibrer la descente de gradient.

- **Avec standardisation** :  
  Pr√©dictions finales $$\approx [0.99999, 120.99]$$ ‚Üí Le mod√®le pr√©dit presque parfaitement la relation lin√©aire. La standardisation permet de centrer et r√©duire les donn√©es, √©quilibrant les gradients et acc√©l√©rant la convergence.

üí° **Conclusion** :

    - La standardisation rend le mod√®le plus stable et fiable pour des valeurs en dehors de l‚Äô√©chelle d‚Äôentra√Ænement.  
    - M√™me pour un r√©seau simple, ne pas standardiser peut provoquer des extrapolations incorrectes, alors que la standardisation corrige ce probl√®me.
    - De plus, si les donn√©es d'entr√©e sont bruit√©es, ne pas standardiser peut d√©grader encore plus les performances du mod√®le. Pour le tester, il suffit de d√©commenter la ligne ``y = 2*X + 1 + torch.randn_like(X)*5`` et relancer l'entra√Ænement.

.. slide::

üìñ 6. Broadcasting
----------------------------

6.1 Qu'est-ce que le broadcasting ?
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Le broadcasting est un m√©canisme qui permet √† PyTorch de faire des op√©rations entre tenseurs de dimensions diff√©rentes sans avoir √† √©crire de boucles. C'est comme cela qu'est fait l'op√©ration de centrage des donn√©es (soustraction de la moyenne) dans la standardisation des donn√©es.

üí° Id√©e principale :

- Si les dimensions des tenseurs sont compatibles, PyTorch r√©plique automatiquement le tenseur de plus petite dimension pour correspondre √† la taille du tenseur le plus grand.
- Cela permet de vectoriser les calculs et de rendre le code plus simple et rapide.

.. slide::
6.2 Exemple de broadcasting pour centrer des donn√©es
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   import torch

   # Matrice 3x2
   X = torch.tensor([[1., 2.],
                     [3., 4.],
                     [5., 6.]])

   # Moyenne de chaque colonne
   mean = X.mean(dim=0)  # dimension (2,)

   # On soustrait la moyenne √† chaque ligne
   X_centered = X - mean  # broadcasting

   print("X centr√© :", X_centered)

üí° Conclusion : M√™me si ``mean`` est un vecteur (dimension 2), PyTorch l‚Äôapplique √† toutes les lignes de ``X``. Le tenseur ``mean`` est automatiquement ‚Äú√©tendu‚Äù pour correspondre √† ``X``.  

‚úÖ R√©sultat : On peut centrer toutes les lignes d‚Äôun coup, sans boucle.



.. slide::
üìñ 7. Observer la loss et d√©terminer le nombre d‚Äôepochs
------------------------------------------------------
Lorsqu‚Äôon entra√Æne un mod√®le, il est essentiel de suivre l‚Äô√©volution de la loss pour savoir si le mod√®le apprend correctement et converge vers une solution. Dans l‚Äôexemple pr√©c√©dent, nous avons compar√© l‚Äôimpact de la standardisation sur les pr√©dictions finales. Nous allons maintenant observer l‚Äô√©volution de la loss pendant l‚Äôentra√Ænement pour mieux comprendre la convergence et d√©terminer un nombre d‚Äôepochs appropri√©. Nous allons continuer √† utiliser les donn√©es suivantes pour entra√Æner le mod√®le :

.. code-block:: python

   # Donn√©es d'entra√Ænement
   X = torch.tensor([[0.],[10.],[20.],[30.],[40.],[50.]])
   y = 2*X + 1

7.1. Suivi de la loss
~~~~~~~~~~~~~~~~~~~~~

Pour suivre la loss pour le mod√®le avec et sans standardisation il faut d'abord cr√©er deux listes pour stocker les valeurs de la loss √† chaque epoch. Pour cela, il suffit d'ajouter le code suivant avant la classe de cr√©ation du mod√®le : 

.. code-block:: python

    ...

    # Listes pour stocker l'√©volution de la loss
    losses_no_std = []
    losses_std = []

    ...


.. slide::
Ensuite, pendant l‚Äôentra√Ænement, on ajoute la valeur de la loss dans les listes √† chaque epoch. Cela se fait comme suit : 

.. code-block:: python

    ...

    # Sans standardisation
    pred_no_std = model_no_std(X)
    
    ...

    optimizer_no_std.step()
    losses_no_std.append(loss_no_std.item()) # Ligne √† ajouter

    # Avec standardisation
    pred_std = model_std(X_stdized)
    
    ...

    optimizer_std.step()
    losses_std.append(loss_std.item()) # Ligne √† ajouter

    ...

.. slide::
Enfin on ajoute les lignes de code suivantes pour tracer les loss √† la fin du code : 

.. code-block:: python

    ...

    # Visualisation de la loss
    plt.plot(losses_no_std, label='Sans standardisation')
    plt.plot(losses_std, label='Avec standardisation')
    plt.xlabel('Epoch')
    plt.ylabel('Loss MSE')
    plt.title("√âvolution de la loss pendant l'entra√Ænement")
    plt.legend()
    plt.show()


.. slide::
7.2. Interpr√©tation du r√©sultat
~~~~~~~~~~~~~~~~~~

- **Convergence** :  
  - Si la loss diminue et se stabilise autour d‚Äôune valeur faible, le mod√®le converge.  
  - Si la loss reste tr√®s √©lev√©e ou diverge, le mod√®le ne converge pas correctement.

- **Choix du nombre d‚Äôepochs** :  
  - En regardant le graphique, on peut d√©terminer √† partir de quel epoch la loss se stabilise.  
  - Cela permet de choisir un nombre d‚Äôepochs suffisant sans sur-entra√Æner inutilement le mod√®le.
  - Dans cet exemple, on d√©couvre que pour le mod√®le qui s'entra√Æne avec standardisation, la loss se stabilise √† 0 autour de 500 epochs. Vous pouvez r√©duire le nombre d'epochs et v√©rifier que 500 epochs suffisent.

.. note::
    **Remarque** : Si vous relancer l'entra√Ænement, le graphique de la loss peut varier √† cause de l'initialisation al√©atoire des poids sauf si vous utilisez un ``seed`` fixe.

.. slide::
7.3. Early Stopping
~~~~~~~~~~~~~~~~~~~~

Pour √©viter de trop entra√Æner le mod√®le, on peut surveiller la loss et arr√™ter l‚Äôentra√Ænement lorsque la perte ne diminue plus. Cela s‚Äôappelle l‚Äôearly stopping. On peut automatiser le processus avec PyTorch. Tout d'abord, il faut remettre le nombre d'epoch √† 5000. Ensuite il faut cr√©er les variables suivantes et les ajouter avant la classe qui construit le mod√®le :

.. code-block:: python

    ...

    # Param√®tres pour l'early stopping
    patience = 50       # nombre d'epochs sans am√©lioration avant arr√™t
    best_loss_std = float('inf') # meilleure loss observ√©e pour le mod√®le avec standardisation (initialis√©e √† l'infini pour que la premi√®re am√©lioration soit toujours accept√©e)
    counter_std = 0 # compteur d'epochs sans am√©lioration

    patience_no_std = 50
    best_loss_no_std = float('inf')    
    counter_no_std = 0

    ...

.. slide::
Ensuite, il faut ajouter le code suivant √† la fin de chaque boucle d'entra√Ænement pour v√©rifier si la loss s'est am√©lior√©e ou non. Si elle ne s'am√©liore pas pendant un certain nombre d'epochs (d√©fini par ``patience``), l'entra√Ænement s'arr√™te automatiquement. Voici le code √† ajouter :

.. code-block:: python

    ...

    # Sans standardisation

    ...


    losses_no_std.append(loss_no_std.item())

    # Early stopping pour le mod√®le sans standardisation (code √† ajouter)
    if loss_no_std.item() < best_loss_no_std:
        best_loss_no_std = loss_no_std.item()
        counter_no_std = 0
    else:
        counter_no_std += 1
    if counter_no_std >= patience_no_std:
        print(f"Arr√™t anticip√© (sans std) √† l'epoch {epoch}, loss = {best_loss_no_std:.4f}")
        break

    # Avec standardisation
   
    ...

    losses_std.append(loss_std.item())

    # Early stopping pour le mod√®le standardis√© (code √† ajouter)
    if loss_std.item() < best_loss_std:
        best_loss_std = loss_std.item()
        counter_std = 0
    else:
        counter_std += 1
    if counter_std >= patience:
        print(f"Arr√™t anticip√© (avec std) √† l'epoch {epoch}, loss = {best_loss_std:.4f}")
        break

    ...

.. slide::

üí° **Remarque** :  

- Cette m√©thode simple permet de d√©terminer un nombre d‚Äôepochs appropri√© automatiquement.  
- Pour cet exemple, le mod√®le sans standardisation des donn√©es ne converge jamais avec une loss $$\approx 0$$ tandis que le mod√®le avec standardisation des donn√©es converge √† partir d'environ 200 epochs.
- Dans la pratique, on combine souvent early stopping avec un jeu de validation pour √©viter le surapprentissage.

.. slide::
üìñ 8. Observer le mod√®le avec ``torch-summary`` et la performance des gradients avec autograd profiler
-------------------

Il existe plusieurs outils PyTorch qui permettent d'inspecter et de profiler les mod√®les. Le but √©tant de parvenir √† identifier les goulots d'√©tranglement et √† optimiser les performances. Parmi eux, on trouve :

- ``torchsummary`` : pour visualiser la structure du mod√®le et le nombre de param√®tres par couche.
- ``torch.autograd.profiler`` : pour profiler le calcul des gradients et identifier les op√©rations co√ªteuses.

8.1. Utiliser ``torchsummary``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

``torchsummary`` permet de visualiser la structure du mod√®le et le nombre de param√®tres par couche avant l'entra√Ænement. Pour l'utiliser, il faut d'abord l'installer :

.. code-block:: bash

    pip install torch-summary

Ensuite, juste apr√®s la d√©finition de votre mod√®le, vous pouvez faire un r√©sum√© du mod√®le :

.. code-block:: python

    from torchsummary import summary

    # Mod√®le standardis√© d√©fini pr√©c√©demment
    # Cr√©er une copie sur CPU pour torchsummary
    model_std_cpu = MLP().to("cpu")

    # R√©sum√© du mod√®le
    # input_size correspond aux dimensions d'un √©chantillon (hors batch)
    # Ici, chaque √©chantillon a 1 feature (scalaire)
    summary(model_std_cpu, input_size=(1,), device="cpu")

.. slide::
Explications¬†:

- ``input_size`` : dimensions d‚Äôun √©chantillon (hors batch).  
  Dans notre exemple, chaque √©chantillon est un scalaire (1 feature), donc ``input_size=(1,)``.  
- ``device`` : est √©gal √† ``"cpu"`` pour √©viter tout conflit CUDA si le mod√®le ou PyTorch envoie certains tenseurs sur GPU.  

- R√©sultat¬†: pour chaque couche, on voit :

  - le type de couche (Linear, ReLU‚Ä¶)
  - la taille des tenseurs interm√©diaires
  - le nombre de param√®tres
  - le nombre de param√®tres entra√Ænables



.. slide::
8.2. R√¥le du profiler
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Pour encore plus am√©liorer la performance de votre mod√®le, PyTorch fournit ``torch.autograd.profiler.profile`` pour profiler le calcul des gradients ce qui permet de :

- Mesurer le temps et la m√©moire consomm√©s par chaque op√©ration.
- Identifier les goulots d'√©tranglement dans le r√©seau.
- Optimiser et d√©bugger les mod√®les complexes.


.. slide::
8.3. Exemple d'utilisation du profiler pour l'exemple de r√©gression
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Pour tester le profiler, il suffit d'ajouter le code suivant juste apr√®s le code de ``torchsummary`` :

.. code-block:: python

    ...

    # torch.autograd.profiler est utilis√© dans ce chapitre pour la simplicit√©
    # Pour des usages avanc√©s (timeline, TensorBoard), on peut utiliser torch.profiler
    import torch.autograd.profiler as profiler

    # Faire un profiling sur une seule passe avant la boucle d'entra√Ænement
    with profiler.profile(use_cuda=True, profile_memory=True) as prof_dummy:
        # Forward + backward sur le mod√®le standardis√©
        pred_std = model_std(X_stdized)
        loss_std = ((pred_std - y)**2).mean()
        optimizer_std.zero_grad()
        loss_std.backward()

    # Afficher le profil CPU (temps d'ex√©cution)
    print("Profil CPU pour le mod√®le standardis√© (une seule passe avant entra√Ænement) :")
    print(prof_dummy.key_averages().table(sort_by="cpu_time_total"))

    # Afficher le profil GPU (m√©moire consomm√©e)
    print(prof_dummy.key_averages().table(sort_by="self_cuda_memory_usage", row_limit=10))

    ...

.. slide::
**Conclusion** : 

    - On peut profiler √† la fois le **temps CPU** et la **m√©moire GPU**.
    - On utilise :
        - ``cpu_time_total`` pour identifier les op√©rations co√ªteuses en calcul,
        - ``self_cuda_memory_usage`` pour rep√©rer celles qui consomment le plus de m√©moire GPU.
    - Le profiler ralentit fortement l'ex√©cution : il ne doit pas √™tre utilis√© pendant tout l‚Äôentra√Ænement, mais seulement ponctuellement pour analyser ou optimiser.

    - Chaque op√©ration ex√©cut√©e sur le CPU par PyTorch y est list√©e avec :
        - ``Self CPU %`` : temps pass√© directement dans l‚Äôop√©ration.
        - ``CPU total %`` : temps total incluant les sous-op√©rations.
        - ``# of Calls`` : nombre d‚Äôappels √† l‚Äôop√©ration.

    - Chaque op√©ration ex√©cut√©e sur le GPU par PyTorch y est list√©e avec :
        - ``Self CUDA Memory Usage`` : m√©moire GPU utilis√©e directement par l‚Äôop√©ration.
        - ``CUDA Memory Usage`` : m√©moire totale incluant les sous-op√©rations.
        - ``# of Calls`` : nombre d‚Äôappels √† l‚Äôop√©ration.

    - Les **couches lin√©aires** (``aten::linear``) prennent la majeure partie du temps : multiplication matricielle + bias.
    - Les **activations** (``ReLU``, ``Tanh``) et les calculs de **loss** (``mean``, ``pow``) consomment moins de temps mais sont n√©cessaires pour propager les gradients.
    - Les op√©rations comme ``detach`` ou ``clone`` apparaissent lorsqu‚Äôon fait des copies ou qu‚Äôon d√©tache un tenseur du graphe pour ne pas calculer de gradient dessus.
    - Ce profilage permet de **visualiser les goulots d‚Äô√©tranglement** et d‚Äôoptimiser l‚Äôentra√Ænement si n√©cessaire.

    - Pour un petit MLP, le plus co√ªteux est le calcul des couches lin√©aires et du backward. Sur des mod√®les plus grands ou avec GPU, ces informations sont cruciales pour comprendre et am√©liorer les performances.


.. slide::
üèãÔ∏è Travaux Pratiques 2
--------------------

.. toctree::

    TP_chap2


