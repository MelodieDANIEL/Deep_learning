.. slide::
Chapitre 2 ‚Äî Perceptron multi-couches 
===========================================

üéØ Objectifs du Chapitre
----------------------


.. important::

    √Ä la fin de cette section,  vous saurez :  

    - Le fonctionnement du perceptron simple.
    - Utiliser une fonction d'activation adapt√©e.  
    - L‚Äôimportance de la normalisation / standardisation des donn√©es et l'usage des epochs.  
    - Construire un r√©seau de neurones avec ``torch.nn``. 
    - Faire un entra√Ænement simple d‚Äôun MLP pour un probl√®me de r√©gression.   
    - Suivre l‚Äô√©volution de la loss et interpr√©ter les r√©sultats.  
    - Utiliser ``torch-summary`` pour inspecter l‚Äôarchitecture du r√©seau.  


.. slide::

üìñ 1. Rappels sur les perceptrons
----------------------

Le perceptron multi-couches (MLP de Multi-Layers Perceptron en anglais) est la brique de base des r√©seaux de neurones modernes. Dans ce chapitre, nous allons l‚Äôappliquer √† des probl√®mes de r√©gression simple. Avant de commencer, voici quelques rappels.

1.1. Perceptron simple
~~~~~~~~~~~~~~~~~~~~~~

Le perceptron est le bloc de base d‚Äôun r√©seau de neurones. Il r√©alise une transformation lin√©aire suivie (ou pas) d‚Äôune fonction d‚Äôactivation telle que :  

  .. math::

     y = \sigma(Wx + b)

  o√π :  
   - $$y$$ est la sortie du perceptron, 
   - $$\sigma$$ est une fonction d‚Äôactivation, 
   - $$W$$ est la matrice des poids,  
   - $$b$$ est le biais et  
   - $$x$$ est l'ensemble des entr√©es du perceptron.  

.. slide::
1.2. Perceptron intuition
~~~~~~~~~~~~~~~~~~~~~~
.. image:: images/chap2_perceptron.png
    :alt: perceptron
    :align: center
    :width: 40%

avec $$y= \sigma(x_1*w_1 + x_2*w_2 + ...+ x_i*w_i + ... + x_n*w_n + b)$$

üí° **Intuition :**

    - Chaque poids $$w_i$$ mesure l‚Äôimportance de la caract√©ristique $$x_i$$.  
    - Le biais $$b$$ d√©place la fronti√®re de d√©cision.  
    - La fonction d‚Äôactivation permet d‚Äôintroduire de la non-lin√©arit√©, indispensable pour mod√©liser des relations complexes mais nous en parleront plus en d√©tails par la suite.  


.. slide::
1.3. Mise √† jour des param√®tres
~~~~~~~~~~~~~~~~~~~~~~

Un perceptron poss√®de deux types de **param√®tres** : les **poids** et le **biais**.  

Lors de l‚Äôentra√Ænement, on souhaite ajuster ces param√®tres pour am√©liorer les pr√©dictions du mod√®le.  Pour cela, il faut mettre √† jour les poids apr√®s avoir calcul√© la loss gr√¢ce √† la fonction de perte et le gradient gr√¢ce √† l'optimiseur comme expliqu√© dans le chapitre pr√©c√©dent.  

Pour rappel, on met √† jours les param√®tres du mod√®le gr√¢ce √† l'√©quation introduite dans le chapitre pr√©c√©dent. 

.. math::

    \theta \leftarrow \theta - \eta \, \nabla_\theta \mathcal{L}(\theta)

o√π :  
- $$\theta$$ repr√©sente l‚Äôensemble des param√®tres du mod√®le (ici $$W$$ et $$b$$),  
- $$\mathcal{L}$$ est la fonction de perte,  
- $$\nabla_\theta \mathcal{L}$$ est le gradient de la perte par rapport aux param√®tres,  
- $$\eta$$ est le taux d‚Äôapprentissage (learning rate en anglais).


.. slide::
1.4. Exemples d'applications du perceptron simple
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Un perceptron simple ne peut r√©soudre que les probl√®mes lin√©airement s√©parables puisque en trouvant les param√®tres du mod√®le, le perceptron trace une droite dans le plan des entr√©es et s√©pare les points selon qu‚Äôils sont au-dessus ou en dessous de cette droite.

**Exemple 1 : porte logique ET**

+-----+-----+-------+
| x‚ÇÅ  | x‚ÇÇ  | y=ET  |
+=====+=====+=======+
|  0  |  0  |   0   |
+-----+-----+-------+
|  0  |  1  |   0   |
+-----+-----+-------+
|  1  |  0  |   0   |
+-----+-----+-------+
|  1  |  1  |   1   |
+-----+-----+-------+

Dans ce cas, une droite s√©pare bien les deux classes :  
- la classe $$0$$ (points en bas √† gauche, en haut √† gauche, en bas √† droite),  
- la classe $$1$$ (point en haut √† droite).  

Un perceptron simple peut donc apprendre cette fonction.

.. slide::
**Exemple 2 : porte logique XOR**

+-----+-----+--------+
| x‚ÇÅ  | x‚ÇÇ  | y=XOR  |
+=====+=====+========+
|  0  |  0  |   0    |
+-----+-----+--------+
|  0  |  1  |   1    |
+-----+-----+--------+
|  1  |  0  |   1    |
+-----+-----+--------+
|  1  |  1  |   0    |
+-----+-----+--------+

Ici, il est impossible de tracer une seule droite qui s√©pare correctement les classes. Autrement dit, XOR n‚Äôest pas lin√©airement s√©parable.  

.. image:: images/chap2_et_vs_xor.png
   :alt: Repr√©sentation du XOR dans le plan (non-s√©parable lin√©airement)
   :align: center
   :width: 300%

**Conclusion :** 

- Le perceptron simple suffit pour des t√¢ches lin√©aires (comme ET, OU).  
- Pour r√©soudre des probl√®mes plus complexes comme XOR, il faut introduire plusieurs couches de neurones et des fonctions d‚Äôactivation non-lin√©aires : c‚Äôest le principe du **perceptron multi-couches (MLP)**. 

.. slide::
1.5. Faire un perceptron dans PyTorch
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Pour cr√©er un perceptron simple dans PyTorch, on peut utiliser la fonction ``Linear`` de ``torch.nn``, qui impl√©mente une couche lin√©aire (ou affine) : $$y = Wx + b$$. La fonction ``Linear`` prend en entr√©e le nombre d'entr√©e $$x$$ et le nombre de sortie $$y$$.

.. code-block:: python

    import torch
    import torch.nn as nn

    # Donn√©es ET
    X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32)
    y = torch.tensor([[0],[0],[0],[1]], dtype=torch.float32)

    # Mod√®le lin√©aire (perceptron)
    model = nn.Linear(2,1)

    # Loss function et optimiseur
    loss_fc = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.1)

    # Entra√Ænement
    for _ in range(500):
        optimizer.zero_grad()
        loss = loss_fc(model(X), y)
        loss.backward()
        optimizer.step()

    # R√©sultat
    with torch.no_grad():
        print((model(X)).round())
        print(model.weight, model.bias)

**Remarque** : si maintenant on change les entr√©es et sorties pour le XOR, le mod√®le ne pourra pas apprendre correctement la fonction (les $$W$$ restent √† 0 comme √† l'initialisation). Vous pouvez faire le test pour v√©rifier.

.. slide::

################################ STOP ICI ################################

################################ STOP ICI ################################

################################ STOP ICI ################################


.. slide::

üìñ 2. Fonction d'activation
-----------

Les fonctions d‚Äôactivation introduisent de la non-lin√©arit√© dans le mod√®le, ce qui permet de mieux capturer des relations complexes dans les donn√©es. Voici quelques fonctions d‚Äôactivation couramment utilis√©es :

1. **Sigmo√Øde** : $$\sigma(x) = \frac{1}{1 + e^{-x}}$$
   - Sortie entre 0 et 1.
   - Utilis√©e pour les probl√®mes de classification binaire.

2. **Tanh** : $$\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$$
   - Sortie entre -1 et 1.
   - Souvent utilis√©e dans les r√©seaux de neurones cach√©s.

3. **ReLU (Rectified Linear Unit)** : $$\text{ReLU}(x) = \max(0, x)$$
   - Sortie nulle pour les entr√©es n√©gatives.
   - Tr√®s utilis√©e dans les r√©seaux de neurones profonds en raison de sa simplicit√© et de son efficacit√©.

4. **Softmax** : $$\text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}$$
   - Transforme un vecteur en une distribution de probabilit√©.
   - Utilis√©e en sortie des mod√®les de classification multi-classes.



.. slide::

üìñ 3. Epoch
-----------

Lorsqu‚Äôon entra√Æne un mod√®le, on doit pr√©senter plusieurs fois l‚Äôensemble des donn√©es d‚Äôapprentissage $$x$$.

3.1 D√©finitions importantes
~~~~~~~~~~~~

- It√©ration : mise √† jour des param√®tres apr√®s avoir trait√© un seul exemple ou un mini-batch.

- Batch / mini-batch : sous-ensemble d‚Äôexemples utilis√©s pour calculer la mise √† jour.

-  Epoch : passage complet sur toutes les donn√©es d‚Äôapprentissage.

**Exemple** :

Si vous avez 1000 exemples et que vous utilisez des mini-batchs de 100 : Une epoch correspond √† 10 it√©rations (1000 √∑ 100).

Apr√®s chaque epoch, chaque exemple a √©t√© utilis√© exactement une fois pour mettre √† jour les param√®tres.

3.2 Pourquoi plusieurs epochs‚ÄØ?
~~~~~~~~~~~~
Au d√©but de l‚Äôentra√Ænement, le mod√®le fait souvent de grandes erreurs.

Chaque epoch permet aux poids et biais de s‚Äôajuster progressivement pour mieux pr√©dire les sorties.

En g√©n√©ral, plusieurs dizaines ou centaines d‚Äôepochs sont n√©cessaires pour que la loss se stabilise.

üí° Intuition : imaginez un perceptron comme un √©l√®ve qui apprend : il ne retient pas tout parfaitement du premier coup ; il faut plusieurs passages sur le m√™me exercice pour ma√Ætriser.





.. slide::
4. Normaliser / standardiser les donn√©es
-----------------------------

Pourquoi normaliser ?  

- Les entr√©es de grande amplitude ralentissent l‚Äôapprentissage.  
- Normaliser permet de mettre toutes les features √† la m√™me √©chelle.  

Deux approches classiques :  

- **Normalisation** : valeurs entre 0 et 1.  
- **Standardisation** : moyenne 0, variance 1.  

Exemple avec scikit-learn :  

.. code-block:: python

   from sklearn.preprocessing import StandardScaler
   scaler = StandardScaler()
   X_scaled = scaler.fit_transform(X)


5. Utiliser ``torch.nn`` pour construire un MLP
------------------------------------------------

- ``Sequential`` : permet d‚Äôempiler les couches facilement.  
- ``Linear`` : couche affine (Wx+b).  
- Fonctions d‚Äôactivation : donnent la non-lin√©arit√© (ex. ``nn.ReLU()``).  

Exemple minimal d‚Äôun r√©seau :  

.. code-block:: python

   import torch.nn as nn

   model = nn.Sequential(
       nn.Linear(1, 10),   # entr√©e 1D -> couche cach√©e 10 neurones
       nn.ReLU(),          
       nn.Linear(10, 1)    # sortie 1D (r√©gression)
   )


6. Suivi de la loss et visualisation
-------------------------------------

- Pendant l‚Äôentra√Ænement, enregistrer la loss √† chaque epoch pour voir si elle diminue.  
- Comparer ``y_pred`` et ``y_true`` avec Matplotlib.  

.. code-block:: python

   import matplotlib.pyplot as plt

   plt.plot(losses)              # courbe de la loss
   plt.scatter(x, y_true)        # donn√©es r√©elles
   plt.scatter(x, y_pred)        # pr√©dictions


7. Inspecter le mod√®le avec ``torch-summary``
----------------------------------------------

Permet de voir le nombre de param√®tres par couche et la structure du r√©seau.  

.. code-block:: python

   from torchsummary import summary
   summary(model, input_size=(1,))








################################ Activation fonction ######################################
Parler de la softmax, relu , etc.
##########################################################################################



################################ MLP ######################################

faire une classe avec fonction pour les couches et une pour le forward comme : 
..code-block:: python   
    class MLP(nn.Module):
        def __init__(self, input_size, hidden_size, output_size):
            super(MLP, self).__init__()
            self.fc1 = nn.Linear(input_size, hidden_size)
            self.fc2 = nn.Linear(hidden_size, output_size)

        def forward(self, x):
            x = F.relu(self.fc1(x))
            x = self.fc2(x)
            return x


parler de dataset loader et parler de broadcasting ?

- parler de .detach() et .clone() ?

- parler de autograd profiler.profile

- parler de la gestion des outliers
##########################################################################################











