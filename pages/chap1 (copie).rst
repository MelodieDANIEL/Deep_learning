
.. slide::

Chapitre 1 - Introduction √† PyTorch et Optimisation de Mod√®les
================

üéØ Objectifs du Chapitre
----------------------


.. important::

   √Ä la fin de ce chapitre, vous saurez : 

   - Cr√©er et manipuler des tenseurs PyTorch sur CPU et GPU.
   - Calculer automatiquement les gradients √† l‚Äôaide de ``autograd``.
   - D√©finir une fonction de co√ªt.
   - Utiliser un optimiseur pour ajuster les param√®tres d‚Äôun mod√®le.
   - Impl√©menter une boucle d'entra√Ænement simple.

.. slide::

üìñ 1. Qu'est-ce que PyTorch ? 
----------------------
PyTorch est une biblioth√®que Python de machine learning open-source d√©velopp√©e par Facebook (FAIR). Elle est con√ßue pour faciliter la cr√©ation et l'entra√Ænement de mod√®les, en particulier dans le domaine du deep learning. 

Elle repose principalement sur deux √©l√©ments :

A) Les *tenseurs*, des structures de donn√©es similaires aux tableaux NumPy (``ndarray``), mais avec des fonctionnalit√©s suppl√©mentaires pour :
    
    - le calcul diff√©rentiel automatique,
    - l'acc√©l√©ration GPU,
    - l‚Äôentra√Ænement de r√©seaux de neurones.

B) Le module ``autograd`` permet de calculer automatiquement les gradients n√©cessaires √† l'entra√Ænement des mod√®les, en suivant toutes les op√©rations effectu√©es sur les tenseurs.

.. slide::

D'autres biblioth√®ques Python similaires existent, comme :

- TensorFlow : d√©velopp√© par Google, tr√®s utilis√© pour des d√©ploiements √† grande √©chelle.
- Keras : interface haut niveau de TensorFlow, plus simple mais moins flexible.
- JAX : plus r√©cent, optimis√© pour la recherche et les calculs scientifiques √† haute performance.

.. slide::

Dans le cadre de ce cours, nous utiliserons PyTorch car :

- elle est largement adopt√©e par la communaut√© de la recherche en deep learning,
- elle est plus lisible et plus facile √† d√©boguer que TensorFlow et JAX,
- elle offre plus de possibilit√©s que Keras,
- elle est bien document√©e et est l'une des biblioth√®ques les plus utilis√©es en science des donn√©es (Data Science en anglais) et en apprentissage machine (Machine Learning en anglais).

.. slide::

üìñ 2. Qu'est-ce qu'un tenseur ?
----------------------

Les **tenseurs** sont la structure de base de PyTorch. Ce sont des tableaux multidimensionnels similaires aux ``ndarray`` de NumPy, mais avec des fonctionnalit√©s suppl√©mentaires pour le GPU et le calcul automatique des gradients. Un tenseur est une structure de donn√©es qui g√©n√©ralise les matrices √† un nombre quelconque de dimensions:

- Un scalaire est un tenseur 0D.  
- Un vecteur est un tenseur 1D.  
- Une matrice est un tenseur 2D.  
- On peut avoir des tenseurs 3D, 4D, etc.   

Les tenseurs √† haute dimensions sont tr√®s utilis√©s en deep learning (par exemple pour les images ou les vid√©os). Nous allons voir comment cr√©er et manipuler des tenseurs dans PyTorch. Vous pouvez copier-coller les exemples de code ci-dessous dans un notebook Jupyter pour les tester et voir les affichages. Pour utiliserles fonctions de PyTorch, il faut d'abord l'importer :
.. code-block:: python

   import torch

.. slide::
    
üìñ 3. Cr√©ation de tenseurs
----------------------

Il existe plusieurs mani√®res de cr√©er un tenseur en PyTorch.

3.1 √Ä partir de donn√©es Python (listes ou tuples)
~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   # Depuis une liste
   a = torch.tensor([1, 2, 3])
   print(a)

   # Depuis une liste de listes (matrice)
   b = torch.tensor([[1, 2, 3], [4, 5, 6]])
   print(b)

   # On peut aussi sp√©cifier le type de donn√©es
   c = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)
   print(c, c.dtype)

.. slide::
3.2 Avec des fonctions de construction
~~~~~~~~~~~~~~~~~~~
.. code-block:: python

   # Tenseur rempli de z√©ros
   z = torch.zeros(2, 3)
   print(z)

   # Tenseur rempli de uns
   o = torch.ones(2, 3)
   print(o)

   # Tenseur vide (valeurs non initialis√©es)
   e = torch.empty(2, 3)
   print(e)

   # Identit√© (matrice diagonale)
   eye = torch.eye(3)
   print(eye)

.. slide::
3.3 Avec des suites r√©guli√®res
~~~~~~~~~~~~~~~~~~~
PyTorch permet de g√©n√©rer facilement des suites de nombres avec des pas r√©guliers. Deux fonctions sont particuli√®rement utiles :

1. **torch.arange(debut, fin, pas)**  

   - Cr√©e une suite en commen√ßant √† ``debut``  
   - S‚Äôarr√™te *avant* ``fin`` (attention, la borne sup√©rieure est exclue !)  
   - Utilise le ``pas`` indiqu√©  

.. code-block:: python

   # De 0 √† 8 inclus, avec un pas de 2
   r = torch.arange(0, 10, 2)
   print("torch.arange(0, 10, 2) :", r)

   # De 5 √† 20 exclu, avec un pas de 3
   r2 = torch.arange(5, 20, 3)
   print("torch.arange(5, 20, 3) :", r2)

   # ‚ö†Ô∏è Remarque : la borne sup√©rieure (ici 10 ou 20) n'est jamais incluse

.. slide::
2. **torch.linspace(debut, fin, steps)**  

   - Cr√©e une suite de ``steps`` valeurs r√©guli√®rement espac√©es  
   - Inclut **√† la fois** ``debut`` et ``fin``  

.. code-block:: python

   # 5 valeurs entre 0 et 1 inclus
   l = torch.linspace(0, 1, steps=5)
   print("torch.linspace(0, 1, steps=5) :", l)

   # 4 valeurs entre -1 et 1 inclus
   l2 = torch.linspace(-1, 1, steps=4)
   print("torch.linspace(-1, 1, steps=4) :", l2)

**R√©sum√© des diff√©rences**

- ``arange`` ‚Üí on fixe le **pas** entre les valeurs, la fin est exclue.  
- ``linspace`` ‚Üí on fixe le **nombre de valeurs**, la fin est incluse.  

Exemple comparatif :

.. code-block:: python

   print(torch.arange(0, 1, 0.25))   # [0.00, 0.25, 0.50, 0.75]
   print(torch.linspace(0, 1, 5))    # [0.00, 0.25, 0.50, 0.75, 1.00]


.. slide::
3.4 Avec des nombres al√©atoires
~~~~~~~~~~~~~~~~~~~

.. code-block:: python
   # Attention dans les exemples suivants, les crochets [] veulent dire que la valeur de la borne est incluse, contrairement √† aux parenth√®ses () qui signifient que la borne est exclue.
   # Uniforme entre [0, 1)
   u = torch.rand(2, 2)
   print("Uniforme [0,1) :\n", u)

   # Distribution normale (moyenne=0, √©cart-type=1)
   n = torch.randn(2, 2)
   print("Normale standard (0,1) :\n", n)

   # Distribution normale avec moyenne (mean) et √©cart-type (std) choisis
   custom = torch.normal(mean=2.0, std=3.0, size=(2,2))
   print("Normale (moyenne=10, √©cart-type=2) :\n", custom)

   # Fixer la graine pour la reproductibilit√©
   torch.manual_seed(42)
   print("Reproductibilit√© :\n", torch.rand(2, 2))  # toujours le m√™me r√©sultat


.. slide::
üìñ 4. Conna√Ætre la forme d'un tenseur
------------------------

Un tenseur peut avoir n‚Äôimporte quelle dimension. La m√©thode ``.shape`` permet de conna√Ætre sa taille.

.. code-block:: python

   # Scalaire (0D)
   s = torch.tensor(5)
   print("Scalaire :", s, "shape =", s.shape)

   # Vecteur (1D)
   v = torch.tensor([1, 2, 3, 4])
   print("Vecteur :", v, "shape =", v.shape)

   # Matrice (2D)
   m = torch.tensor([[1, 2, 3], [4, 5, 6]])
   print("Matrice :\n", m, "shape =", m.shape)

   # Tenseur 3D (par exemple, 2 matrices de taille 3x3)
   t3 = torch.zeros(2, 3, 3)
   print("Tenseur 3D shape =", t3.shape)

   # Tenseur 4D (par exemple, un mini-batch de 10 images RGB de 32x32)
   t4 = torch.zeros(10, 3, 32, 32)
   print("Tenseur 4D shape =", t4.shape)


.. slide::
üìñ 5. Types de tenseurs et conversion
------------------------

- Vous pouvez sp√©cifier le type de donn√©es (``dtype``) lors de la cr√©ation :

.. code-block:: python

   x = torch.tensor([1.2, 3.4, 5.6])
   print(x.dtype)     # float32 par d√©faut

   x_int = x.to(torch.int32)
   print(x_int, x_int.dtype)

   x_float64 = x.double()
   print(x_float64, x_float64.dtype)

- Conversion d‚Äôun tenseur existant :

.. code-block:: python

   x_int = x.to(torch.int32)
   print(x_int.dtype)

.. slide::
üìñ 6. Op√©rations de base
------------------------

PyTorch supporte de nombreuses op√©rations sur les tenseurs :

.. code-block:: python

   a = torch.tensor([1, 2, 3])
   b = torch.tensor([4, 5, 6])

   # Addition
   print(a + b)

   # Multiplication √©l√©ment par √©l√©ment
   print(a * b)

   # Produit matriciel
   mat1 = torch.rand(2, 3)
   mat2 = torch.rand(3, 4)
   print(torch.mm(mat1, mat2))

.. slide::
üìñ 7. Tenseurs sur GPU
------------------------

Pour profiter de l‚Äôacc√©l√©ration GPU, il suffit de d√©placer un tenseur sur le device CUDA :

.. code-block:: python

   if torch.cuda.is_available():
       device = torch.device("cuda")
       x_gpu = x.to(device)
       print("Tenseur sur GPU :", x_gpu)
   else:
       print("Pas de GPU disponible, utilisation du CPU.")

.. slide::
üìñ 8.  Manipulation avanc√©e des tenseurs
--------------------

Une fois cr√©√©s, les tenseurs peuvent √™tre transform√©s et r√©arrang√©s. PyTorch fournit de nombreuses fonctions pour modifier leur forme, leurs dimensions ou leur ordre.

8.1 Changer la forme avec ``view`` et ``reshape``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``view`` : retourne un nouveau tenseur qui partage la m√™me m√©moire que l‚Äôoriginal. Cela implique que le tenseur soit contigu. Un tenseur est dit contigu lorsque ses donn√©es sont stock√©es de mani√®re cons√©cutive en m√©moire, c‚Äôest-√†-dire que PyTorch peut lire tous les √©l√©ments dans l‚Äôordre sans sauts.  
Certaines op√©rations, comme la transposition (`t()`), rendent le tenseur non contigu, et dans ce cas ``view`` √©choue.
- ``reshape`` : similaire √† ``view``, mais plus flexible car il tente d‚Äôutiliser la m√©moire existante, mais cr√©e une copie si n√©cessaire. ``reshape`` fonctionne dans tous les cas de figures.

.. code-block:: python

   x = torch.arange(12)   # tenseur 1D [0, 1, ..., 11]
   print("x :", x)

   # Transformer en matrice 3x4
   x_view = x.view(3, 4)
   print("view en 3x4 :\n", x_view)

   # Transformer en matrice 2x6
   x_reshape = x.reshape(2, 6)
   print("reshape en 2x6 :\n", x_reshape)

.. slide::
Autre exemple pour illustrer la diff√©rence entre ``view`` et ``reshape`` :

.. code-block:: python

   # Cr√©ation d'un tenseur 2x3
   x = torch.arange(6).view(2, 3)
   print("x :\n", x)
   print("Contigu :", x.is_contiguous())

   # Transposition ‚Üí rend le tenseur non contigu
   y = x.t()
   print("\ny (transpos√©) :\n", y)
   print("Contigu :", y.is_contiguous())

   # view √©choue sur un tenseur non contigu
   try:
       z = y.view(6)
   except Exception as e:
       print("\nErreur avec view :", e)

   # reshape fonctionne toujours
   z2 = y.reshape(6)
   print("\nreshape fonctionne :", z2)

.. slide::
8.2 Changer l‚Äôordre des dimensions : ``permute``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``permute`` r√©arrange les dimensions dans un nouvel ordre.  
- Tr√®s utile pour manipuler les donn√©es d‚Äôimages ou de s√©quences.

.. code-block:: python

   # Exemple avec un tenseur 3D (batch, hauteur, largeur)
   t = torch.randn(2, 3, 4)  # forme (2, 3, 4)
   print("Tenseur original :", t.shape)

   # Inverser l'ordre (largeur, hauteur, batch)
   p = t.permute(2, 1, 0)
   print("Apr√®s permute :", p.shape)

.. slide::
8.3 Ajouter ou supprimer des dimensions : ``unsqueeze`` et ``squeeze``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``unsqueeze(dim)`` : ajoute une dimension de taille 1 √† la position ``dim``.  
- ``squeeze()`` : supprime toutes les dimensions de taille 1.  

.. code-block:: python

   v = torch.tensor([1, 2, 3])
   print("Forme initiale :", v.shape)

   v_unsq = v.unsqueeze(0)  # ajoute une dimension au d√©but
   print("Apr√®s unsqueeze(0) :", v_unsq.shape)

   v_sq = v_unsq.squeeze()  # supprime les dimensions de taille 1
   print("Apr√®s squeeze() :", v_sq.shape)

.. slide::
8.4 Concat√©ner ou empiler des tenseurs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``torch.cat`` : concat√®ne le long d‚Äôune dimension existante.  
- ``torch.stack`` : empile en ajoutant une nouvelle dimension.  

.. code-block:: python

   a = torch.tensor([1, 2, 3])
   b = torch.tensor([4, 5, 6])

   cat = torch.cat((a, b), dim=0)
   print("torch.cat :", cat)

   stack = torch.stack((a, b), dim=0)
   print("torch.stack :", stack)
   print("Forme de stack :", stack.shape)

.. slide::
üìñ 9. Autograd avec PyTorch
-----------------------

En Deep Learning, nous travaillons souvent avec des fonctions compliqu√©es d√©pendant de plusieurs variables. Pour entra√Æner un mod√®le, nous avons besoin de calculer automatiquement les d√©riv√©es de ces fonctions. C'est l√† qu'intervient Autograd qui est le moteur de diff√©rentiation automatique de PyTorch. 

9.1 Cr√©ation d'un tenseur suivi
~~~~~~~~~~~~~~~~~~~

Pour qu'un tenseur suive les op√©rations et calcule les gradients automatiquement, il faut d√©finir ``requires_grad=True`` :

.. code-block:: python

    x = torch.tensor([2.0, 3.0], requires_grad=True)
    print(x)

Ici, ``x`` est maintenant un tenseur avec suivi des gradients. Toutes les op√©rations futures sur ce tenseur seront enregistr√©es pour pouvoir calculer les d√©riv√©es automatiquement.


.. slide::
9.2 Op√©rations sur les tenseurs
~~~~~~~~~~~~~~~~~~~

Toutes les op√©rations effectu√©es sur ce tenseur sont automatiquement enregistr√©es dans un graphe computationnel dynamique.

.. code-block:: python

    y = x ** 2 + 3 * x # y = [y1, y2]
    print(y)

Dans ce cas :

- ``x`` est la variable d'entr√©e.
- ``y`` est calcul√© √† partir de ``x`` avec les op√©rations ``x**2`` et ``3*x``.

Chaque op√©ration devient un n≈ìud du graphe et PyTorch garde la trace des d√©pendances pour pouvoir calculer les gradients.


############################## Stop ICI ##############################
############################## Stop ICI ##############################
############################## Stop ICI ##############################
############################## Stop ICI ##############################

.. slide::

Ici :

- Les n≈ìuds ``x^2`` et ``3*x`` repr√©sentent les op√©rations effectu√©es sur ``x``.
- Le n≈ìud ``y`` combine ces deux r√©sultats.
- Le graphe permet √† PyTorch desavoir quelles d√©riv√©es calculer et dans quel ordre.


üìñ 10. Graphe computationnel
-----------------------------

Un graphe computationnel est une structure qui repr√©sente toutes les op√©rations effectu√©es sur les tenseurs. Chaque n≈ìud du graphe correspond √† un tenseur ou √† une op√©ration math√©matique, et les ar√™tes indiquent les d√©pendances entre eux.

Pour visualiser le graphe dans PyTorch, on peut utiliser ``torchviz`` :

.. code-block:: python

    from torchviz import make_dot

    z = y.sum()
    make_dot(z, params={'x': x})

.. note::

    Cela produira une image avec des n≈ìuds pour chaque op√©ration et des fl√®ches indiquant les d√©pendances :

- Les n≈ìuds ``x^2`` et ``3*x`` repr√©sentent les op√©rations effectu√©es sur ``x``.
- Le n≈ìud ``y`` combine ces deux r√©sultats.
- Le graphe permet √† PyTorch de savoir quelles d√©riv√©es calculer et dans quel ordre.

.. slide::
üìñ 11. Calcul des gradients et r√©tropropagation 
-----------------------

Autograd utilise ce graphe pour calculer automatiquement les d√©riv√©es par rapport √† ``x``, en utilisant la m√©thode ``backward()`` :

.. code-block:: python
    z = y.sum()  # z = y1 + y2
    z.backward()
    print(x.grad)

- ``backward()`` calcule les d√©riv√©es de ``z`` par rapport √† chaque √©l√©ment de ``x``.
- ``x.grad`` contient maintenant les gradients.

PyTorch parcourt le graphe **en sens inverse** (principe de la r√©tropropagation) :

1. Commence par la sortie ``z``.
2. Recule vers les n≈ìuds pr√©c√©dents (``y`` puis ``x``) en appliquant la r√®gle de d√©rivation.
3. Stocke le gradient dans ``x.grad``.

Calcul des gradients dans notre exemple :

- ``dz/dy = 1`` car z = y.sum() 
- ``dy/dx = d√©riv√©e de (x^2 + 3*x) = 2*x + 3``
- ``dx = dz/dy * dy/dx = 2*x + 3``

On obtient donc :

.. code-block:: python

    print(x.grad)  # tensor([7., 9.])

.. slide::
**D√©tail du calcul des gradients **

On a :

.. math::

    y = [y_1, y_2] = [x_1^2 + 3x_1,\; x_2^2 + 3x_2]

et

.. math::

    z = y_1 + y_2

**√âtape 1 : d√©riv√©e de z par rapport √† y**

\[
\frac{\partial z}{\partial y_1} = 1, \quad \frac{\partial z}{\partial y_2} = 1
\]

**√âtape 2 : d√©riv√©e de y par rapport √† x**

- Pour :math:`y_1 = x_1^2 + 3x_1`  
  \[
  \frac{\partial y_1}{\partial x_1} = 2x_1 + 3
  \]

- Pour :math:`y_2 = x_2^2 + 3x_2`  
  \[
  \frac{\partial y_2}{\partial x_2} = 2x_2 + 3
  \]

**√âtape 3 : application de la r√®gle de la cha√Æne**

\[
\frac{\partial z}{\partial x_1} = \frac{\partial z}{\partial y_1} \cdot \frac{\partial y_1}{\partial x_1} 
= 1 \cdot (2x_1 + 3)
\]

\[
\frac{\partial z}{\partial x_2} = \frac{\partial z}{\partial y_2} \cdot \frac{\partial y_2}{\partial x_2} 
= 1 \cdot (2x_2 + 3)
\]

---

R√©sultat num√©rique pour notre exemple :  

.. code-block:: python

    print(x)       # tensor([2., 3.], requires_grad=True)
    print(x.grad)  # tensor([7., 9.])

Car :

- Pour :math:`x_1 = 2` ‚Üí :math:`\frac{\partial z}{\partial x_1} = 2*2 + 3 = 7`  
- Pour :math:`x_2 = 3` ‚Üí :math:`\frac{\partial z}{\partial x_2} = 2*3 + 3 = 9`

---

Ainsi, Autograd reproduit automatiquement ce calcul gr√¢ce au graphe computationnel et √† la r√®gle de la cha√Æne.


.. slide::
üìñ 12. D√©sactivation du suivi des gradients
~~~~~~~~~~~~~~~~~~~

Pour certaines op√©rations, par exemple lors de l'√©valuation d'un mod√®le, il est inutile
de calculer les gradients. On peut alors d√©sactiver le suivi avec ``torch.no_grad()`` :

.. code-block:: python

    with torch.no_grad():
        z = x * 2
    print(z)

Cela permet d'√©conomiser de la m√©moire et d'acc√©l√©rer les calculs.












**D√©tail du calcul des gradients **

On a :

.. math::

    y = [y_1, y_2] = [x_1^2 + 3x_1,\; x_2^2 + 3x_2]


et

.. math::

    z = y_1 + y_2

**√âtape 1 : d√©riv√©e de z par rapport √† y**

.. math::
    [
    \frac{\partial z}{\partial y_1} = 1, \quad \frac{\partial z}{\partial y_2} = 1
    ]

**√âtape 2 : d√©riv√©e de y par rapport √† x**

- Pour 

.. math::
    
    y_1 = x_1^2 + 3x_1 

On a 
.. math::
  [
  \frac{\partial y_1}{\partial x_1} = 2x_1 + 3
  ]

- Pour 

.. math:: 
    
    y_2 = x_2^2 + 3x_2

On a 
.. math::  
  [
  \frac{\partial y_2}{\partial x_2} = 2x_2 + 3
  ]

**√âtape 3 : application de la r√®gle de la cha√Æne**

.. math::
    [
    \frac{\partial z}{\partial x_1} = \frac{\partial z}{\partial y_1} \cdot \frac{\partial y_1}{\partial x_1} 
    = 1 \cdot (2x_1 + 3)
    ]
.. math::
    [
    \frac{\partial z}{\partial x_2} = \frac{\partial z}{\partial y_2} \cdot \frac{\partial y_2}{\partial x_2} 
    = 1 \cdot (2x_2 + 3)
    ]

.. slide::
**R√©sultat num√©rique pour notre exemple** :

.. code-block:: python

    print(x)       # tensor([2., 3.], requires_grad=True)
    print(x.grad)  # tensor([7., 9.])

Car :

- Pour :math:`x_1 = 2` ‚Üí :math:`\frac{\partial z}{\partial x_1} = 2*2 + 3 = 7`  
- Pour :math:`x_2 = 3` ‚Üí :math:`\frac{\partial z}{\partial x_2} = 2*3 + 3 = 9`

---

Ainsi, Autograd reproduit automatiquement ce calcul gr√¢ce au graphe computationnel et √† la r√®gle de la cha√Æne.

.. slide::
üìñ 12. D√©sactivation du suivi des gradients
~~~~~~~~~~~~~~~~~~~

Pour certaines op√©rations, par exemple lors de l'√©valuation d'un mod√®le, il est inutile
de calculer les gradients. On peut alors d√©sactiver le suivi avec ``torch.no_grad()`` :

.. code-block:: python

    with torch.no_grad():
        z = x * 2
    print(z)

Cela permet d'√©conomiser de la m√©moire et d'acc√©l√©rer les calculs.








################################# POUR LE TP #####################
Exemple concret : petite boucle d'entra√Ænement
----------------------------------------------

On peut illustrer l'utilisation d'Autograd pour entra√Æner un r√©seau tr√®s simple
(une seule couche lin√©aire) :

.. code-block:: python

    # Cr√©ation de donn√©es factices
    X = torch.randn(5, 1, requires_grad=False)
    y_true = 2 * X + 1

    # Param√®tres √† apprendre
    w = torch.randn(1, requires_grad=True)
    b = torch.randn(1, requires_grad=True)

    # Boucle d'entra√Ænement simple
    learning_rate = 0.1
    for epoch in range(10):
        y_pred = X * w + b
        loss = ((y_pred - y_true) ** 2).mean()

        loss.backward()  # calcul des gradients

        # Mise √† jour des param√®tres
        with torch.no_grad():
            w -= learning_rate * w.grad
            b -= learning_rate * b.grad

            # r√©initialisation des gradients
            w.grad.zero_()
            b.grad.zero_()

        print(f"Epoch {epoch+1}, loss: {loss.item()}")



Conclusion
----------

Autograd permet de calculer automatiquement les d√©riv√©es et de mettre √† jour les
param√®tres lors de l'entra√Ænement d'un r√©seau de neurones. La combinaison de
``requires_grad=True``, ``backward()`` et ``no_grad()`` constitue le coeur de la
programmation avec PyTorch.

################################# POUR LE TP #####################




.. math::

   L(y, \hat{y}) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2

- :math:`y_i` est la valeur r√©elle (target),
- :math:`\hat{y}_i` est la pr√©diction du mod√®le,
- on fait la moyenne sur tous les exemples.

.. code-block:: python

    import torch
    import torch.nn as nn

    # Valeurs r√©elles et pr√©dictions
    y_true = torch.tensor([2.0, 3.0, 4.0])
    y_pred = torch.tensor([2.5, 2.7, 4.2])

    # D√©finition de la fonction de perte MSE
    loss_fn = nn.MSELoss()

    # Calcul de la perte
    loss = loss_fn(y_pred, y_true)
    print(loss)

La perte est un **nombre unique** qui r√©sume l‚Äôerreur moyenne

La fonction MSE (de Mean Squared Error en anglais) est tr√®s utilis√©e en r√©gression :

.. math::

   L(y, \hat{y}) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2

- ``yi`` est la valeur r√©elle (target),
- ``y^i`` est la pr√©diction du mod√®le.

.. code-block:: python

    import torch
    import torch.nn as nn

    # Valeurs r√©elles et pr√©dictions
    y_true = torch.tensor([2.0, 3.0, 4.0])
    y_pred = torch.tensor([2.5, 2.7, 4.2])

    # D√©finition de la fonction de perte MSE
    loss_fn = nn.MSELoss()

    # Calcul de la perte
    loss = loss_fn(y_pred, y_true)
    print(loss)  # valeur scalaire

Ici, la perte est un **scalaire** (un seul nombre) qui r√©sume l‚Äôerreur moyenne.