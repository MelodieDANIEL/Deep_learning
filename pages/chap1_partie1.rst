
.. slide::

Chapitre 1 - Introduction √† PyTorch et Optimisation de Mod√®les (partie 1)
================

üéØ Objectifs du Chapitre
----------------------


.. important::

   √Ä la fin de ce chapitre, vous saurez : 

   - Cr√©er et manipuler des tenseurs PyTorch sur CPU et GPU.
   - Calculer automatiquement les gradients √† l‚Äôaide de ``autograd``.
   - D√©finir une fonction de perte.
   - Utiliser un optimiseur pour ajuster les param√®tres d‚Äôun mod√®le.
   - Impl√©menter une boucle d'entra√Ænement simple.

.. slide::

üìñ 1. Qu'est-ce que PyTorch ? 
----------------------
PyTorch est une biblioth√®que Python de machine learning open-source d√©velopp√©e par Facebook (FAIR). Elle est con√ßue pour faciliter la cr√©ation et l'entra√Ænement de mod√®les, en particulier dans le domaine du deep learning. 

Elle repose principalement sur deux √©l√©ments :

A) Les *tenseurs*, des structures de donn√©es similaires aux tableaux NumPy (``ndarray``), mais avec des fonctionnalit√©s suppl√©mentaires pour :
    
    - le calcul diff√©rentiel automatique,
    - l'acc√©l√©ration GPU,
    - l‚Äôentra√Ænement de r√©seaux de neurones.

B) Le module ``autograd`` permet de calculer automatiquement les gradients n√©cessaires √† l'entra√Ænement des mod√®les, en suivant toutes les op√©rations effectu√©es sur les tenseurs.

.. slide::

D'autres biblioth√®ques Python similaires existent, comme :

- TensorFlow : d√©velopp√© par Google, tr√®s utilis√© pour des d√©ploiements √† grande √©chelle.
- Keras : interface haut niveau de TensorFlow, plus simple mais moins flexible.
- JAX : plus r√©cent, optimis√© pour la recherche et les calculs scientifiques √† haute performance.

.. slide::

Dans le cadre de ce cours, nous utiliserons PyTorch car :

- elle est largement adopt√©e par la communaut√© de la recherche en deep learning,
- elle est plus lisible et plus facile √† d√©boguer que TensorFlow et JAX,
- elle offre plus de possibilit√©s que Keras,
- elle est bien document√©e et est l'une des biblioth√®ques les plus utilis√©es en science des donn√©es (Data Science en anglais) et en apprentissage machine (Machine Learning en anglais).

.. slide::

üìñ 2. Qu'est-ce qu'un tenseur ?
----------------------

Les **tenseurs** sont la structure de base de PyTorch. Ce sont des tableaux multidimensionnels similaires aux ``ndarray`` de NumPy, mais avec des fonctionnalit√©s suppl√©mentaires pour le GPU et le calcul automatique des gradients. Un tenseur est une structure de donn√©es qui g√©n√©ralise les matrices √† un nombre quelconque de dimensions:

- Un scalaire est un tenseur 0D.  
- Un vecteur est un tenseur 1D.  
- Une matrice est un tenseur 2D.  
- On peut avoir des tenseurs 3D, 4D, etc.   

Les tenseurs √† haute dimension sont tr√®s utilis√©s en deep learning (par exemple pour les images ou les vid√©os). Nous allons voir comment cr√©er et manipuler des tenseurs dans PyTorch. Pour utiliser les fonctions de PyTorch, il faut d'abord l'importer :
.. code-block:: python

   import torch

.. note::

   Vous devez copier-coller les exemples de code ci-dessous dans un notebook Jupyter pour les tester et voir les affichages.

.. slide::
    
üìñ 3. Cr√©ation de tenseurs
----------------------

Il existe plusieurs mani√®res de cr√©er un tenseur en PyTorch.

3.1. √Ä partir de donn√©es Python (listes ou tuples)
~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   # Depuis une liste
   a = torch.tensor([1, 2, 3])
   print(a)

   # Depuis une liste de listes (matrice)
   b = torch.tensor([[1, 2, 3], [4, 5, 6]])
   print(b)

   # On peut aussi sp√©cifier le type de donn√©es
   c = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)
   print(c, c.dtype)

.. slide::
3.2. Avec des fonctions de construction
~~~~~~~~~~~~~~~~~~~
.. code-block:: python

   # Tenseur rempli de z√©ros
   z = torch.zeros(2, 3)
   print(z)

   # Tenseur rempli de uns
   o = torch.ones(2, 3)
   print(o)

   # Tenseur vide (valeurs non initialis√©es)
   e = torch.empty(2, 3)
   print(e)

   # Identit√© (matrice diagonale)
   eye = torch.eye(3)
   print(eye)

.. slide::
3.3. Avec des suites r√©guli√®res
~~~~~~~~~~~~~~~~~~~
PyTorch permet de g√©n√©rer facilement des suites de nombres avec des pas r√©guliers. Deux fonctions sont particuli√®rement utiles :

1. **torch.arange(debut, fin, pas)**  

   - Cr√©e une suite en commen√ßant √† ``debut``  
   - S‚Äôarr√™te avant ``fin`` (attention, la borne sup√©rieure est exclue !)  
   - Utilise le ``pas`` indiqu√©  

.. code-block:: python

   # De 0 √† 8 inclus, avec un pas de 2
   r = torch.arange(0, 10, 2)
   print("torch.arange(0, 10, 2) :", r)

   # De 5 √† 20 exclu, avec un pas de 3
   r2 = torch.arange(5, 20, 3)
   print("torch.arange(5, 20, 3) :", r2)

   # ‚ö†Ô∏è Remarque : la borne sup√©rieure (ici 10 ou 20) n'est jamais incluse

.. slide::
2. **torch.linspace(debut, fin, steps)**  

   - Cr√©e une suite de ``steps`` valeurs r√©guli√®rement espac√©es  
   - Inclut **√† la fois** ``debut`` et ``fin``  

.. code-block:: python

   # 5 valeurs entre 0 et 1 inclus
   l = torch.linspace(0, 1, steps=5)
   print("torch.linspace(0, 1, steps=5) :", l)

   # 4 valeurs entre -1 et 1 inclus
   l2 = torch.linspace(-1, 1, steps=4)
   print("torch.linspace(-1, 1, steps=4) :", l2)

**R√©sum√© des diff√©rences**

- ``arange`` ‚Üí on fixe le **pas** entre les valeurs, la fin est exclue.  
- ``linspace`` ‚Üí on fixe le **nombre de valeurs**, la fin est incluse.  

Exemple comparatif :

.. code-block:: python

   print(torch.arange(0, 1, 0.25))   # [0.00, 0.25, 0.50, 0.75]
   print(torch.linspace(0, 1, 5))    # [0.00, 0.25, 0.50, 0.75, 1.00]


.. slide::
3.4. Avec des nombres al√©atoires
~~~~~~~~~~~~~~~~~~~

.. code-block:: python
   # Attention dans les exemples suivants, les crochets [] veulent dire que la valeur de la borne est incluse, contrairement √† aux parenth√®ses () qui signifient que la borne est exclue.
   # Uniforme entre [0, 1)
   u = torch.rand(2, 2)
   print("Uniforme [0,1) :\n", u)

   # Distribution normale (moyenne=0, √©cart-type=1)
   n = torch.randn(2, 2)
   print("Normale standard (0,1) :\n", n)

   # Distribution normale avec moyenne (mean) et √©cart-type (std) choisis
   custom = torch.normal(mean=2.0, std=3.0, size=(2,2))
   print("Normale (moyenne=10, √©cart-type=2) :\n", custom)

   # Fixer la graine pour la reproductibilit√©
   torch.manual_seed(42)
   print("Reproductibilit√© :\n", torch.rand(2, 2))  # toujours le m√™me r√©sultat


.. slide::
üìñ 4. Conna√Ætre la forme d'un tenseur
------------------------

Un tenseur peut avoir n‚Äôimporte quelle dimension. La m√©thode ``.shape`` permet de conna√Ætre sa taille.

.. code-block:: python

   # Scalaire (0D)
   s = torch.tensor(5)
   print("Scalaire :", s, "shape =", s.shape)

   # Vecteur (1D)
   v = torch.tensor([1, 2, 3, 4])
   print("Vecteur :", v, "shape =", v.shape)

   # Matrice (2D)
   m = torch.tensor([[1, 2, 3], [4, 5, 6]])
   print("Matrice :\n", m, "shape =", m.shape)

   # Tenseur 3D (par exemple, 2 matrices de taille 3x3)
   t3 = torch.zeros(2, 3, 3)
   print("Tenseur 3D shape =", t3.shape)

   # Tenseur 4D (par exemple, un mini-batch de 10 images RGB de 32x32)
   t4 = torch.zeros(10, 3, 32, 32)
   print("Tenseur 4D shape =", t4.shape)


.. slide::
üìñ 5. Types de tenseurs et conversion
------------------------

- Vous pouvez sp√©cifier le type de donn√©es (``dtype``) lors de la cr√©ation :

.. code-block:: python

   x = torch.tensor([1.2, 3.4, 5.6])
   print(x.dtype)     # float32 par d√©faut

   x_int = x.to(torch.int32)
   print(x_int, x_int.dtype)

   x_float64 = x.double()
   print(x_float64, x_float64.dtype)

- Conversion d‚Äôun tenseur existant :

.. code-block:: python

   x_int = x.to(torch.int32)
   print(x_int.dtype)

.. slide::
üìñ 6. Op√©rations de base
------------------------

PyTorch supporte de nombreuses op√©rations sur les tenseurs :

.. code-block:: python

   a = torch.tensor([1, 2, 3])
   b = torch.tensor([4, 5, 6])

   # Addition
   print(a + b)

   # Multiplication √©l√©ment par √©l√©ment
   print(a * b)

   # Produit matriciel
   mat1 = torch.rand(2, 3)
   mat2 = torch.rand(3, 4)
   print(torch.mm(mat1, mat2))

.. slide::
üìñ 7. Tenseurs sur GPU
------------------------

Pour profiter de l‚Äôacc√©l√©ration GPU, il suffit de d√©placer un tenseur sur le device CUDA. Pour cela, on a 3 options :

7.1. Placer un tenseur directement sur le GPU lors de sa cr√©ation
~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   if torch.cuda.is_available():
       device = torch.device("cuda")
       tenseur_gpu = torch.zeros(2, 3, device=device)
       print("Tenseur sur GPU :", tenseur_gpu)
   else:
       print("Pas de GPU disponible, utilisation du CPU.")

.. slide::
7.2. D√©placer un tenseur existant sur le GPU avec ``.to(device)``
~~~~~~~~~~~~~~~~~~~~
.. code-block:: python

   if torch.cuda.is_available():
       device = torch.device("cuda")
       x_gpu = x.to(device)
       print("Tenseur sur GPU :", x_gpu)
   else:
       print("Pas de GPU disponible, utilisation du CPU.")

.. slide::
7.3. Forcer la cr√©ation de tous les tenseurs sur le GPU
~~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   if torch.cuda.is_available():
       device = torch.device("cuda")
       torch.set_default_device(device)
       x_defaut_gpu = torch.zeros(2, 3)  # sera cr√©√© sur le GPU par d√©faut
       print("Tenseur par d√©faut sur GPU :", x_defaut_gpu)
   else:
       print("Pas de GPU disponible, utilisation du CPU.")

.. slide::
üìñ 8.  Manipulation avanc√©e des tenseurs
--------------------

Une fois cr√©√©s, les tenseurs peuvent √™tre transform√©s et r√©arrang√©s. PyTorch fournit de nombreuses fonctions pour modifier leur forme, leurs dimensions ou leur ordre.

8.1. Changer la forme avec ``view`` et ``reshape``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``view`` : retourne un nouveau tenseur qui partage la m√™me m√©moire que l‚Äôoriginal. Cela implique que le tenseur soit contigu. Un tenseur est dit contigu lorsque ses donn√©es sont stock√©es de mani√®re cons√©cutive en m√©moire, c‚Äôest-√†-dire que PyTorch peut lire tous les √©l√©ments dans l‚Äôordre sans sauts.  
Certaines op√©rations, comme la transposition (``t()``), rendent le tenseur non contigu, et dans ce cas ``view`` √©choue.
- ``reshape`` : similaire √† ``view``, mais plus flexible car il tente d‚Äôutiliser la m√©moire existante, mais cr√©e une copie si n√©cessaire. ``reshape`` fonctionne dans tous les cas de figures.

.. code-block:: python

   x = torch.arange(12)   # tenseur 1D [0, 1, ..., 11]
   print("x :", x)

   # Transformer en matrice 3x4
   x_view = x.view(3, 4)
   print("view en 3x4 :\n", x_view)

   # Transformer en matrice 2x6
   x_reshape = x.reshape(2, 6)
   print("reshape en 2x6 :\n", x_reshape)

.. slide::
Autre exemple pour illustrer la diff√©rence entre ``view`` et ``reshape`` :

.. code-block:: python

   # Cr√©ation d'un tenseur 2x3
   x = torch.arange(6).view(2, 3)
   print("x :\n", x)
   print("Contigu :", x.is_contiguous())

   # Transposition ‚Üí rend le tenseur non contigu
   y = x.t()
   print("\ny (transpos√©) :\n", y)
   print("Contigu :", y.is_contiguous())

   # view √©choue sur un tenseur non contigu
   try:
       z = y.view(6)
   except Exception as e:
       print("\nErreur avec view :", e)

   # reshape fonctionne toujours
   z2 = y.reshape(6)
   print("\nreshape fonctionne :", z2)

.. slide::
8.2. Changer l‚Äôordre des dimensions : ``permute``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``permute`` r√©arrange les dimensions dans un nouvel ordre.  
- Tr√®s utile pour manipuler les donn√©es d‚Äôimages ou de s√©quences.

.. code-block:: python

   # Exemple avec un tenseur 3D (batch, hauteur, largeur)
   t = torch.randn(2, 3, 4)  # forme (2, 3, 4)
   print("Tenseur original :", t.shape)

   # Inverser l'ordre (largeur, hauteur, batch)
   p = t.permute(2, 1, 0)
   print("Apr√®s permute :", p.shape)

.. slide::
8.3. Ajouter ou supprimer des dimensions : ``unsqueeze`` et ``squeeze``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``unsqueeze(dim)`` : ajoute une dimension de taille 1 √† la position ``dim``.  
- ``squeeze()`` : supprime toutes les dimensions de taille 1.  

.. code-block:: python

   v = torch.tensor([1, 2, 3])
   print("Forme initiale :", v.shape)

   v_unsq = v.unsqueeze(0)  # ajoute une dimension au d√©but
   print("Apr√®s unsqueeze(0) :", v_unsq.shape)

   v_sq = v_unsq.squeeze()  # supprime les dimensions de taille 1
   print("Apr√®s squeeze() :", v_sq.shape)

.. slide::
8.4. Concat√©ner ou empiler des tenseurs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``torch.cat`` : concat√®ne le long d‚Äôune dimension existante.  
- ``torch.stack`` : empile en ajoutant une nouvelle dimension.  

.. code-block:: python

   a = torch.tensor([1, 2, 3])
   b = torch.tensor([4, 5, 6])

   cat = torch.cat((a, b), dim=0)
   print("torch.cat :", cat)

   stack = torch.stack((a, b), dim=0)
   print("torch.stack :", stack)
   print("Forme de stack :", stack.shape)

.. slide::
üìñ 9. Autograd avec PyTorch
-----------------------

En Deep Learning, nous travaillons souvent avec des fonctions compliqu√©es d√©pendant de plusieurs variables. Pour entra√Æner un mod√®le, nous avons besoin de calculer automatiquement les d√©riv√©es de ces fonctions. C'est l√† qu'intervient Autograd qui est le moteur de diff√©rentiation automatique de PyTorch. 

9.1. Cr√©ation d'un tenseur suivi
~~~~~~~~~~~~~~~~~~~

Pour qu'un tenseur suive les op√©rations et calcule les gradients automatiquement, il faut d√©finir ``requires_grad=True`` :

.. code-block:: python

    x = torch.tensor([2.0, 3.0], requires_grad=True)
    print(x)

Ici, ``x`` est un tenseur avec suivi des gradients. Toutes les op√©rations futures sur ce tenseur seront enregistr√©es pour pouvoir calculer les d√©riv√©es automatiquement.


.. slide::
9.2. Op√©rations sur les tenseurs
~~~~~~~~~~~~~~~~~~~

Toutes les op√©rations effectu√©es sur ce tenseur sont automatiquement enregistr√©es dans un graphe computationnel dynamique.

.. code-block:: python

    y = x ** 2 + 3 * x # y = [y1, y2]
    print(y)

Dans ce cas :

- ``x`` est la variable d'entr√©e.
- ``y`` est calcul√© √† partir de ``x`` avec les op√©rations ``x**2`` et ``3*x``.

Chaque op√©ration devient un n≈ìud du graphe et PyTorch garde la trace des d√©pendances pour pouvoir calculer les gradients.

.. slide::
üìñ 10. Graphe computationnel
-----------------------------

Un graphe computationnel est une structure qui repr√©sente toutes les op√©rations effectu√©es sur les tenseurs. Chaque n≈ìud du graphe correspond √† un tenseur ou √† une op√©ration math√©matique, et les ar√™tes indiquent les d√©pendances entre eux.

10.1. ``torchviz``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Pour visualiser le graphe dans PyTorch, on peut utiliser ``torchviz`` (qu'il faudra installer avec ``pip install torchviz``)  :

.. code-block:: python

    from torchviz import make_dot

    z = y.sum()
    make_dot(z, params={'x': x})

Cela produira une image avec des n≈ìuds pour chaque op√©ration et des fl√®ches indiquant les d√©pendances :

- Les n≈ìuds $$x^2$$ et $$3x$$ repr√©sentent les op√©rations effectu√©es sur $$x$$.
- Le n≈ìud $$y$$ combine ces deux r√©sultats.
- Le graphe permet √† PyTorch de savoir quelles d√©riv√©es calculer et dans quel ordre.

.. slide::
10.2. Note sur le graphe g√©n√©r√© par PyTorch
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Quand on visualise le graphe interne avec un outil comme ``torchviz`` :

- Le **bloc jaune avec ()** correspond au tenseur final (ici ``z``).
- Les **blocs interm√©diaires** (``PowBackward0``, ``AddBackward0``, etc.) repr√©sentent
  les op√©rations qui seront diff√©renti√©es telles que ``PowBackward0`` est l'op√©ration inverse associ√©e √† ``x**2``, ``MulBackward0`` celle associ√©e √† ``3*x``, 
  ``AddBackward0`` combine les deux r√©sultats et repr√©sente ``y`` et enfin ``SumBackward0`` correspond au ``y.sum()`` qui est √©gal √† ``z``.
- Le **bloc ``AccumulateGrad``** correspond √† l‚Äôendroit o√π le gradient est stock√©
  dans la variable d‚Äôentr√©e (ici ``x.grad``).

.. slide::
üìñ 11. Calcul des gradients et r√©tropropagation 
-----------------------

Autograd utilise ce graphe pour calculer automatiquement les d√©riv√©es par rapport √† ``x``, en utilisant la m√©thode ``backward()`` :

.. code-block:: python
    z = y.sum()  # z = y1 + y2
    z.backward()
    print(x.grad)

- ``backward()`` calcule les d√©riv√©es de ``z`` par rapport √† chaque √©l√©ment de ``x``.
- ``x.grad`` contient maintenant les gradients.


.. slide::
11.1. But de la r√©tropropagation
~~~~~~~~~~~~~~

Le but est de minimiser une fonction de perte en ajustant les param√®tres du mod√®le. La r√©tropropagation permet de calculer efficacement les gradients n√©cessaires pour mettre √† jour ces param√®tres via des algorithmes d'optimisation comme la descente de gradient.

Le gradient d‚Äôune fonction $$f(x)$$ est la pente de la courbe en un point. Le gradient indique la direction de variation la plus forte de la fonction : c‚Äôest comme une boussole qui pointe vers la direction o√π la fonction cro√Æt le plus vite. Pour minimiser la perte, on avance dans la direction oppos√©e. Voici comment on calcule le gradient :

- En 1D : $$f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}$$
- En plusieurs dimensions : $$\nabla f(x) = \left( \frac{\partial f}{\partial x_1}, \dots, \frac{\partial f}{\partial x_n} \right)$$

Par exemple si $$f(x) = x^2$$ alors : 

.. figure:: images/chap1_grad.png
   :alt: 
   :align: center

- Pour \( x < 0 \), gradient n√©gatif ‚Üí la fonction d√©cro√Æt. 
- Pour \( x > 0 \), gradient positif ‚Üí la fonction cro√Æt. 
- Au minimum (en \( x=0 \)), gradient nul.

.. note::

   Pour minimiser la fonction de perte, il faut trouver \(x\) pour lequel $$\nabla f(x) = 0$$.  
   **Attention** : un gradient nul peut aussi correspondre √† un maximum. En apprentissage, on esp√®re converger vers un minimum.

.. slide::
11.2. Principe de la r√©tropropagation
~~~~~~~~~~~~~~~~~

Le principe de la r√©tropropagation signifie que PyTorch parcourt le graphe **en sens inverse** pour faire le calcul des d√©riv√©es. Si on repart sur l'exemple de la section pr√©c√©dente, la r√©tropropagation dans PyTorch :


1. Commence par la sortie ``z``.
2. Recule vers les n≈ìuds pr√©c√©dents (``y`` puis ``x``) en appliquant la r√®gle de d√©rivation.
3. Stocke le gradient dans ``x.grad``.

.. slide::
11.3. Calcul des gradients dans notre exemple
~~~~~~~~~~~~~~~~~

- $$\frac{dz}{dy} = 1$$ car $$z = y.sum()$$ 
- $$\frac{dy}{dx} =$$ d√©riv√©e de $$(x^2 + 3*x) = 2*x + 3$$
- $$\frac{dz}{dx} = \frac{dz}{dy} * \frac{dy}{dx} = 2*x + 3$$

On obtient donc :

.. code-block:: python

    print(x.grad)  # tensor([7., 9.])

.. slide::
11.4. D√©tail du calcul des gradients
~~~~~~~~~~~~~~~~~

On a $$y = [y_1, y_2] = [x_1¬≤ + 3x_1,  x_2¬≤ + 3x_2]$$ et $$z = y_1 + y_2$$.


**√âtape 1 : d√©riv√©e de z par rapport √† y**

Comme $$z = y_1 + y_2$$, on a $$\frac{dz}{dy_1} = 1$$ et $$\frac{dz}{dy_2} = 1$$.

On peut regrouper sous forme vectorielle, telle que $$\frac{dz}{dy} = [\frac{dz}{dy_1}, \frac{dz}{dy_2}] = [1, 1]$$.

**√âtape 2 : d√©riv√©e de y par rapport √† x**

On a $$\frac{dy_1}{dx_1} = 2x_1 + 3$$ et $$\frac{dy_2}{dx_2} = 2x_2 + 3$$.
On peut aussi regrouper sous forme vectorielle, telle que $$\frac{dy}{dx} = [\frac{dy_1}{dx_1}, \frac{dy_2}{dx_2}] = [2x_1 + 3, 2x_2 + 3]$$.

**√âtape 3 : application de la r√®gle de la cha√Æne**

Pour obtenir les d√©riv√©es de z par rapport √† x, on applique la r√®gle de la cha√Æne :

$$\frac{dz}{dx} = [\frac{dz}{dx_1}, \frac{dz}{dx_2}] = \frac{dz}{dy} * \frac{dy}{dx}$$ et $$\frac{dz}{dx} = [\frac{dz}{dy_1}*\frac{dy_1}{dx_1}, \frac{dz}{dy_2}*\frac{dy_2}{dx_2}] = [1 * (2x_1 + 3), 1 * (2x_2 + 3)]$$ 

et donc $$\frac{dz}{dx} = [2x_1 + 3, 2x_2 + 3]$$. 

.. slide::
11.5. R√©sultat num√©rique pour notre exemple 
~~~~~~~~~~~~~~~~~

.. code-block:: python

    print(x)       # tensor([2., 3.], requires_grad=True)
    print(x.grad)  # tensor([7., 9.])

Car :

- Pour $$x_1 = 2 ‚Üí \frac{dz}{dx_1} = 2*2 + 3 = 7$$
- Pour $$x_2 = 3 ‚Üí \frac{dz}{dx_2} = 2*3 + 3 = 9$$

Ainsi, Autograd reproduit automatiquement ce calcul gr√¢ce au graphe computationnel et √† la r√®gle de la cha√Æne.

.. slide::
üìñ 12. Manipuler les tenseurs sans gradients 
---------------------
En PyTorch, il est souvent utile de s√©parer certaines op√©rations du calcul des gradients. Voici trois outils pour cela : ``.detach()``, ``.clone()`` et ``torch.no_grad()``.

12.1. ``.detach()``
~~~~~~~~~~~~~~~~~~

- Cr√©e un nouveau tenseur avec les m√™mes valeurs que l‚Äôoriginal, mais sans suivre le calcul des gradients.
- Utile pour utiliser ou visualiser des valeurs sans affecter la r√©tropropagation.

.. code-block:: python

   x = torch.tensor([1.0, 2.0], requires_grad=True)
   y = x * 2
   z = y.detach()  # z ne calcule pas de gradient
   print(z)

.. slide::
12.2. ``.clone()``
~~~~~~~~~~~~~~~~~

- Cr√©e une copie ind√©pendante d‚Äôun tenseur.
- La copie peut continuer √† calculer des gradients si ``requires_grad=True``.
- Utile pour conserver un √©tat avant modification.

.. code-block:: python

   y_clone = y.clone()
   print(y_clone)

.. slide::
12.3. ``torch.no_grad()``
~~~~~~~~~~~~~~~~~~~~~~~~

- Contexte qui emp√™che toutes les op√©rations √† l‚Äôint√©rieur de lui de calculer des gradients.
- Utile pour l'√©valuation du mod√®le, quand on ne veut pas mettre √† jour les param√®tres du mod√®le.
- Permet d'√©conomiser de la m√©moire et d'acc√©l√©rer les calculs.

.. code-block:: python

   with torch.no_grad():
       y_no_grad = x * 2
       print(y_no_grad)

.. slide::
üçÄ Exercice 1 : Calculer le gradient d‚Äôune fonction simple avec PyTorch
----------------

Consid√©rons la fonction suivante : $$f(a) = a^2 + a$$, avec $$a = 1.0$$.

**Consigne :** Utiliser les deux approches suivantes pour calculer le gradient de cette fonction par rapport √† $$a$$ :

   .. step:: 
      
      1) Calculez √† la main la d√©riv√©e de $$f$$ par rapport √† $$a$$. Puis √©valuez ce gradient pour $$a = 1.0$$.

   .. step:: 

      2) Faites l'impl√©mentation de la m√™me fonction avec PyTorch, calculez et √©valuez son gradient.

   .. step:: 

      3) Comparez le r√©sultat obtenu par PyTorch avec le calcul manuel.

**Astuce :**
.. spoiler::
    .. discoverList::
        La d√©riv√©e de $$f(a)$$ par rapport √† $$a$$ est √©gale √† $$2a + 1$$

**R√©sultat attendu :** Le gradient est √©gal √† 3 dans les deux cas.   