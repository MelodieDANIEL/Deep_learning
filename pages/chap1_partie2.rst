
.. slide::

Chapitre 1 - Introduction √† PyTorch et Optimisation de Mod√®les (partie 2)
================

üéØ Objectifs du Chapitre
----------------------

.. important::

   √Ä la fin de ce chapitre, vous saurez : 

   - Cr√©er et manipuler des tenseurs PyTorch sur CPU et GPU.
   - Calculer automatiquement les gradients √† l‚Äôaide de ``autograd``.
   - D√©finir une fonction de perte.
   - Utiliser un optimiseur pour ajuster les param√®tres d‚Äôun mod√®le.
   - Impl√©menter une boucle d'entra√Ænement simple.

.. slide::
üìñ 13. Les fonctions de perte (Loss Functions)
-------------------------------

Lorsqu‚Äôon entra√Æne un r√©seau de neurones, l‚Äôobjectif est de minimiser l‚Äôerreur entre les pr√©dictions du mod√®le et les valeurs attendues. Cette erreur est mesur√©e par une fonction de perte (loss function en anglais).

Une fonction de perte prend en entr√©e :

    - la sortie du mod√®le (la pr√©diction),
    - la valeur cible (la r√©ponse attendue, donn√©e par les donn√©es d‚Äôapprentissage),

et retourne un nombre r√©el qui indique "√† quel point le mod√®le s'est tromp√©".

Par cons√©quent, plus la perte est grande ‚Üí plus le mod√®le se trompe et plus la perte est petite ‚Üí plus le mod√®le est proche de la bonne r√©ponse.

.. slide::
üìñ 14. Pourquoi la fonction de perte est essentielle ?
----------------------------------------------------
La fonction de perte est essentielle pour plusieurs raisons :

    - Elle quantifie l'erreur du mod√®le : elle donne une mesure num√©rique de la performance du mod√®le.
    - Elle permet de guider l'apprentissage : le mod√®le apprend en essayant de r√©duire cette valeur.
    - Elle est le point de d√©part de la r√©tropropagation : les gradients sont calcul√©s √† partir de la fonction de perte.
    - Elle est utilis√©e par les algorithmes d'optimisation pour ajuster les param√®tres du mod√®le.
    - Elle permet de comparer diff√©rents mod√®les : en utilisant la m√™me fonction de perte, on peut √©valuer quel mod√®le est le meilleur.
    - Elle est essentielle pour le processus d'entra√Ænement : sans fonction de perte, le mod√®le n'aurait aucun signal pour savoir comment s‚Äôam√©liorer.

.. slide::
üìñ 15. R√©gression & Erreur quadratique moyenne (MSE)
----------------------------------------------------

15.1. D√©finitions
~~~~~~~~~~~~~~~~~
On appelle r√©gression le cas o√π le mod√®le doit pr√©dire une valeur num√©rique par exemple : la temp√©rature demain, la taille d‚Äôune personne, etc.

Dans ce cas, la fonction de perte la plus utilis√©e est l‚Äôerreur quadratique moyenne (MSE de l'anglais Mean Squared Error) :

.. math::

   L(y, \hat{y}) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2,

o√π :

    - $$L$$ est la fonction de perte,
    - $$n$$ est le nombre de donn√©es,
    - $$y_i$$ est la valeur attendue (target) et
    - $$\hat{y}_i$$ est la pr√©diction du mod√®le.

La fonction MSE calcule la moyenne des erreurs au carr√© de toutes les donn√©es.

.. slide::
15.2. Exemple d'une r√©gression avec MSE dans PyTorch
~~~~~~~~~~~~~~~~~~~~~
Pour utiliser la fonction MSE dans PyTorch, on peut utiliser la classe ``nn.MSELoss()``. Pour cela, il faut d'abord importer le module ``torch.nn`` qui contient les fonctions de perte :
.. code-block:: python

    import torch.nn as nn

**Exemple** : 

.. code-block:: python

    # Valeurs r√©elles et pr√©dictions
    y_true = torch.tensor([2.0, 3.0, 4.0])
    y_pred = torch.tensor([2.5, 2.7, 4.2])

    # D√©finition de la fonction de perte MSE
    loss_fn = nn.MSELoss()

    # Calcul de la perte
    loss = loss_fn(y_pred, y_true)
    print(loss)

.. slide::
üìñ 16. Classification & Entropie crois√©e
------------------------------------------------------------

16.1. D√©finitions
~~~~~~~~~~~~~~~~~~~

On appelle classification le cas o√π le mod√®le doit pr√©dire √† quelle cat√©gorie appartient la donn√©e parmi plusieurs possibles par exemple : "chat" ou "chien", ou bien "spam" ou "non spam", etc.

Dans ce cas, la fonction de perte la plus courante est l'entropie crois√©e (Cross-Entropy Loss en anglais). Elle compare la probabilit√© pr√©dite par le mod√®le et la vraie cat√©gorie (donn√©e par les donn√©es d‚Äôapprentissage) :

.. math::
   L(y, \hat{y}) = -\sum_{i=1}^n y_i \log(\hat{y}_i),
o√π :

    - $$L$$ est la fonction de perte,
    - $$n$$ est le nombre de classes,
    - $$y_i$$ est la valeur attendue (target) pour la classe $$i$$ ((souvent cod√©e en *one-hot encoding*, c'est-√†-dire un vecteur avec un 1 pour la bonne classe et 0 pour les autres),
    - $$\hat{y}_i$$ est la probabilit√© pr√©dite par le mod√®le pour la classe $$i$$.

La fonction enropie crois√©e mesure la distance entre la distribution de probabilit√© pr√©dite par le mod√®le et la distribution de probabilit√© r√©elle (la vraie classe).
La pr√©sence de la somme permet de prendre en compte toutes les classes.   Mais, dans le cas du *one-hot encoding*, seul le terme correspondant √† la vraie classe reste (puisque tous les autres $$y_i$$ valent 0).

.. slide::
16.2. Pourquoi l'entropie crois√©e ?
~~~~~~~~~~~~~~~~~~~
L'entropie crois√©e est utilis√©e car :

    - Elle est adapt√©e aux probl√®mes de classification multi-classes.
    - Elle p√©nalise fortement les erreurs de classification, surtout lorsque la probabilit√© pr√©dite pour la classe correcte est faible.
    - Elle est diff√©rentiable, ce qui permet de l'utiliser avec les algorithmes d'optimisation bas√©s sur la r√©tropropagation.

.. slide::
16.3. Exemple d'une classification avec Cross-Entropy Loss 
~~~~~~~~~~~~~~~~~~~~
Prenons un exemple o√π on a 3 classes possibles : "Chat", "Chien", "Oiseau". Nous avons : 

- La sortie du mod√®le suivante : $$\hat{y} = [0.7, 0.2, 0.1]$$ et
- imaginons que la vraie classe est "Chat", donc $$y = [1, 0, 0]$$.

Alors :

.. math::

    L = - \big( 1 \cdot \log(0.7) + 0 \cdot \log(0.2) + 0 \cdot \log(0.1) \big)

Les termes multipli√©s par 0 disparaissent :

.. math::

    L = -\log(0.7)

üëâ La perte est faible car le mod√®le a donn√© une forte probabilit√© √† la bonne classe.

Si au contraire le mod√®le avait pr√©dit : $$\hat{y} = [0.2, 0.7, 0.1]$$ :

.. math::

    L = -\log(0.2)

üëâ La perte serait plus grande, car la probabilit√© attribu√©e √† la bonne classe ("Chat") est faible.


.. slide::
16.4. Le m√™me exemple dans PyTorch 
~~~~~~~~~~~~~~~~~~~~

Pour utiliser la fonction Cross-Entropy Loss dans PyTorch, on peut utiliser la classe ``nn.CrossEntropyLoss()`` du module ``torch.nn``.

.. code-block:: python

    # D√©finition de la fonction de perte
    loss_fn = nn.CrossEntropyLoss()

    # Cas 1 : le mod√®le pr√©dit correctement (forte valeur pour "Chat")
    logits1 = torch.tensor([[2.0, 1.0, 0.1]])  # sortie brute du mod√®le qui sera convertie √† l'aide d'une fonction de PyTorch en probabilit√©s
    y_true = torch.tensor([0])  # la vraie classe est "Chat" (indice 0)

    loss1 = loss_fn(logits1, y_true)
    print("Perte (bonne pr√©diction) :", loss1.item())

    # Cas 2 : le mod√®le se trompe (forte valeur pour "Chien")
    logits2 = torch.tensor([[0.2, 2.0, 0.1]])  # sortie brute du mod√®le qui sera convertie √† l'aide d'une fonction de PyTorch en probabilit√©s
    loss2 = loss_fn(logits2, y_true)
    print("Perte (mauvaise pr√©diction) :", loss2.item())

.. slide::
üìñ 17. Optimisation
-----------------------

L‚Äôoptimisation est l‚Äô√©tape qui permet d‚Äôajuster les param√®tres du mod√®le pour qu‚Äôil r√©alise mieux la t√¢che demand√©e.  

L‚Äôid√©e est simple :  

1. On calcule la perte (loss en anglais) qui indique l‚Äôerreur du mod√®le.  
2. On calcule le gradient de la perte par rapport aux param√®tres (gr√¢ce √† Autograd).  
3. On met √† jour les param√®tres dans la bonne direction (celle qui diminue la perte).  

C‚Äôest un processus it√©ratif qui se r√©p√®te jusqu‚Äô√† ce que le mod√®le apprenne correctement.


.. slide::
üìñ 18. Descente de gradient
-----------------------

L‚Äôalgorithme d‚Äôoptimisation le plus courant est la descente de gradient (ou Gradient Descent en anglais). 

18.1. Principe et formule de la descente de gradient
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Imaginons une montagne :  
- La hauteur correspond √† la valeur de la fonction de perte.  
- Le but est de descendre la montagne pour atteindre la vall√©e (la perte minimale).  
- Le gradient indique la pente : on suit la pente descendante pour r√©duire la perte.

Formule de mise √† jour des param√®tres :

.. math::

   \theta_{new} = \theta_{old} - \eta \cdot \nabla_\theta L(\theta)

o√π :  

- $$\theta$$ repr√©sente l‚Äôensemble des param√®tres du mod√®le,  
- $$L$$ est la fonction de perte,  
- $$\eta$$ est le taux d‚Äôapprentissage (*learning rate* en anglais) : il contr√¥le la taille des pas et  
- $$\nabla_\theta L(\theta)$$ d√©signe le vecteur des d√©riv√©es partielles de $$L$$ par rapport √† chacun des param√®tres.  


.. slide::
üìñ 18.2. Exemple simple de la descente de gradient
~~~~~~~~~~~~~~~~~~~~~~~~
Prenons un exemple tr√®s simple : nous voulons ajuster un seul param√®tre $$a$$ pour approximer une fonction.

Supposons que le mod√®le soit une droite passant par l‚Äôorigine :

.. math::

   f(x) = a x

Nous avons une donn√©e d‚Äôapprentissage :  

- Entr√©e : $$x = 2$$  
- Sortie attendue : $$y = 4$$  

On part du param√®tre initial : $$a = 0$$.

.. slide::
**1. Fonction de perte**

On utilise l‚Äôerreur quadratique (MSE) pour mesurer l‚Äô√©cart entre la pr√©diction et la vraie valeur :

.. math::

   L(a) = (f(x) - y)^2 = (a * 2 - 4)^2


**2. Calcul du gradient**

On d√©rive la perte par rapport √† $$a$$ :

.. math::

   \frac{\partial L}{\partial a} = 2 * (a * 2 - 4) * 2 = 8a - 16

.. slide::

**3. Mise √† jour avec descente de gradient**

On choisit un taux d‚Äôapprentissage $$\eta = 0.1$$ et on applique la formule :

.. math::

   a_{new} = a_{old} - \eta \cdot \frac{\partial L}{\partial a}


**4. Exemple num√©rique**

- Point de d√©part : $$a = 0$$  
- Gradient : $$\frac{\partial L}{\partial a} = 8 * 0 - 16 = -16$$  
- Mise √† jour :  

.. math::

   a_{new} = 0 - 0.1 * (-16) = 1.6

üëâ Apr√®s une √©tape, $$a$$ se rapproche d√©j√† de la bonne valeur (qui devrait √™tre $$a = 2$$ pour que $$f(x) = 2 * 2 = 4$$).  

En r√©p√©tant plusieurs mises √† jour, $$a$$ converge vers 2, et la perte devient de plus en plus faible.


.. slide::
üìñ 19. Descente de gradient avec PyTorch
----------------------------------------

PyTorch fournit le module ``torch.optim`` qui impl√©mente plusieurs algorithmes d‚Äôoptimisation. Dans PyTorch, l‚Äôalgorithme de descente de gradient est appel√© SGD (Stochastic Gradient Descent) et peut √™tre import√© via ``torch.optim.SGD`` :

.. code-block:: python
   import torch.optim as optim

On reprend le mod√®le simple :

- Mod√®le : $$f(x) = ax$$
- Objectif : trouver $$a$$ tel que $$f(x) ‚âà y$$
- Jeu de donn√©es : $$x = [1, 2, 3, 4], y = [2, 4, 6, 8]$$
- Param√®tre initial : $$a = 0$$
- Taux d'apprentissage : $$\eta = lr = 0.1$$

.. slide::
.. code-block:: python
    # Donn√©es
    x = torch.tensor([1.0, 2.0, 3.0, 4.0])
    y = torch.tensor([2.0, 4.0, 6.0, 8.0])
    a = torch.tensor([0.0], requires_grad=True)

    # Optimiseur : descente de gradient
    optimizer = optim.SGD([a], lr=0.1)

    # Fonction de perte : MSE
    loss_fn = nn.MSELoss()

    for i in range(10):
        # 1. Remettre les gradients √† z√©ro avant de recalculer
        optimizer.zero_grad()
        
        # 2. Calcul de la pr√©diction
        y_pred = a * x
        
        # 3. Calcul de la perte avec MSE
        loss = loss_fn(y_pred, y)
        
        # 4. Calcul automatique des gradients
        loss.backward()
        
        # 5. Mise √† jour du param√®tre a
        optimizer.step()
        
        print(f"Iter {i+1}: a = {a.item()}, loss = {loss.item()}")

.. note::

      Explications des nouvelles lignes de code :

         - ``optimizer.zero_grad()`` : remet √† z√©ro les gradients calcul√©s lors de la derni√®re it√©ration.  
         Sinon, PyTorch additionne les gradients √† chaque ``backward()``, ce qui fausserait les calculs.
         
         - ``optimizer.step()`` : applique la mise √† jour des param√®tres selon la r√®gle de la descente de gradient :  
         $$a_{new} = a_{old} - lr * \frac{\partial loss}{\partial a}$$.
         

Dans cet exemple, SGD converge tr√®s vite car le probl√®me est simple.
 
.. slide::
üìñ 20. Optimiseur Adam
--------------------------------------

20.1. D√©finition
~~~~~~~~~~~~~~~~~~
Adam est un autre algorithme d'optimisation qui adapte le pas pour chaque param√®tre gr√¢ce √† une moyenne mobile des gradients ($$m_t$$ ) et une moyenne mobile des carr√©s des gradients ($$v_t$$).  

On d√©finit :

- $$g_t = \nabla_\theta L(\theta)$$ : le gradient √† l'it√©ration t  
- $$m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t$$ : moyenne mobile des gradients (1er moment)  
- $$v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2$$ : moyenne mobile des carr√©s des gradients (2e moment)  
- $$\hat{m}_t = \frac{m_t}{1-\beta_1^t}$$ : correction de biais pour le 1er moment  
- $$\hat{v}_t = \frac{v_t}{1-\beta_2^t}$$ : correction de biais pour le 2e moment  
- $$\epsilon$$ : petite constante pour √©viter la division par z√©ro  

La mise √† jour des param√®tres est alors :

.. math::
  \theta_{\text{new}} = \theta_{\text{old}} - \eta \cdot \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}

üí° Interpr√©tation :

- $$m_t$$ capture la direction moyenne des gradients (ce qui √©vite les oscillations),  
- $$v_t$$ ajuste le pas selon la variance des gradients (pour qu'il ne soitpas plus grand si le gradient est bruit√©),  
- $$\epsilon$$ emp√™che la division par z√©ro et
- la correction de biais $$\hat{m}_t, \hat{v}_t$$ est importante surtout au d√©but pour ne pas sous-estimer les moments.

.. slide::
20.2. Adam vs. SGD
~~~~~~~~~~~~~~~~~~~~~
 Diff√©rences entre Adam et la descente de gradient classique (SGD) :

    1. **SGD** applique la m√™me r√®gle de mise √† jour pour tous les param√®tres √† chaque it√©ration :  
       $$\theta_{new} = \theta_{old} - lr * \frac{\partial L}{\partial \theta}$$.
       
    2. **Adam** adapte le taux d'apprentissage pour chaque param√®tre individuellement,  
       en utilisant des moyennes mobiles des gradients et des carr√©s des gradients.  
       Cela permet souvent une convergence plus rapide et plus stable.
    
    3. La syntaxe PyTorch reste tr√®s similaire : on utilise toujours ``optimizer.zero_grad()``, ``loss.backward()`` et ``optimizer.step()``. On peut reprendre le m√™me mod√®le simple que pr√©c√©demment √† titre d'exemple.

.. note::
   ‚ö†Ô∏è Remarque : Dans le cadre de ce cours, nous utiliserons principalement Adam pour sa robustesse et sa facilit√© d'utilisation. Nous allons surtout utiliser l'impl√©mentation de ADAM dans Pytorch sans avoir √† recoder les √©quations. Elles sont √©nonc√©es √† titre informatif.

.. slide::
20.3. Impl√©mentation d'Adam avec PyTorch
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Dans PyTorch, Adam est impl√©ment√© via ``torch.optim.Adam`` :

.. code-block:: python
    # Donn√©es
    x = torch.tensor([1.0, 2.0, 3.0, 4.0])
    y = torch.tensor([2.0, 4.0, 6.0, 8.0])
    a = torch.tensor([0.0], requires_grad=True)

    # Optimiseur : Adam
    optimizer = torch.optim.Adam([a], lr=0.1)

    # Fonction de perte : MSE
    loss_fn = nn.MSELoss()

    for i in range(50):
        optimizer.zero_grad()  # remise √† z√©ro des gradients
        y_pred = a * x
        loss = loss_fn(y_pred, y)  # perte MSE
        loss.backward()  # calcul automatique des gradients
        optimizer.step()  # mise √† jour du param√®tre
        
        print(f"Iter {i+1}: a = {a.item()}, loss = {loss.item()}")

üí° Remarques :

   - Pour des probl√®mes **simples** comme $$f(x)=ax$$, SGD converge tr√®s vite et Adam peut sembler plus lent sur peu d‚Äôit√©rations.  
   - Pour des **mod√®les complexes** avec beaucoup de param√®tres et des gradients bruit√©s, Adam est souvent plus efficace gr√¢ce √† ses ajustements adaptatifs.


.. slide::
‚öñÔ∏è Exercice 2 : Trouver la droite qui passe au mieux par les donn√©es avec MSE
------------------------------------

Dans cet exercice, vous allez impl√©menter une **boucle d'entra√Ænement simple** pour ajuster les param√®tres d'une droite aux donn√©es fournies.

On vous donne les donn√©es suivantes :

.. code-block:: python

    # Donn√©es bruit√©es suivantes
    import numpy as np
    x = np.random.rand(1000)
    y_true = x * 1.54 + 12.5 + np.random.rand(1000)*0.2
    

**Objectif :** Trouver une droite de la forme :

.. math::

    y = f(x) =a x + b

o√π : $$a$$ et $$b$$ sont des param√®tres appris automatiquement en minimisant l'erreur entre les pr√©dictions du mod√®le et les donn√©es r√©elles.

**Consigne :** √âcrire un programme qui ajuste les param√®tres $$a$$ et $$b$$ de la droite aux donn√©es fournies en utilisant  PyTorch.

.. step::
    1) Dans un premier temps, vous pouvez faire une boucle de 10000 it√©rations et coder vous-m√™me la fonction de perte.

.. step::
    2) Affichez les param√®tres appris $$a$$ et $$b$$.

.. step::
    3) Ensuite, trouvez un moyen plus intelligent d'arr√™ter l'entra√Ænement de telle sorte que le mod√®le converge avec le minimum d'it√©rations.

.. step::
    4) Affichez le nombre d'it√©rations n√©cessaires pour converger.

.. step::
    5) Tracez les donn√©es r√©elles et les donn√©es pr√©dites pour comparer visuellement le r√©sultat.

.. step::
    6) Utilisez la fonction de perte MSE fournie par PyTorch et affichez les param√®tres appris $$a$$ et $$b$$.

.. step::
    7) V√©rifiez que le r√©sultat des param√®tres et le trac√© sont similaires √† ceux obtenus avec la boucle d'entra√Ænement manuelle.


**Remarque :** Pour utiliser ``matplotlib``, vous devez l'installer avec la commande suivante :

.. code-block:: bash
    pip install matplotlib

Puis, vous pouvez l'importer dans votre code avec :

.. code-block:: python
    import matplotlib.pyplot as plt
    %matplotlib inline #√Ä ajouter si vous utilisez Jupyter Notebook


**Astuce :**
.. spoiler::
    .. discoverList::
        1. Cr√©er les param√®tres : $$a$$ et $$b$$ sous forme de tenseurs d√©rivables.
        2. Initialiser les param√®tres : $$a$$ et $$b$$ √† z√©ro.
        3. Cr√©er un optimiseur Adam (``torch.optim.Adam``) avec un taux d'apprentissage (learning rate) de 1e-3.
        4. Utiliser une fonction de perte en codant l'√©quation de la MSE (``torch.mean((y_true - y_pred) ** 2)`` ou ``loss = torch.sum((y_pred - y_true) ** 2) / y_true.shape[0]``).
        5. Impl√©menter une boucle d'entra√Ænement (par exemple 100000 it√©rations) avec l'optimiseur ADAM.
        6. √Ä chaque it√©ration :
            - calculer les pr√©dictions,
            - calculer la perte,
            - effectuer la r√©tropropagation,
            - mettre √† jour les param√®tres : $$a$$ et $$b$$.

        7. Il faut arr√™ter l'entra√Ænement lorsque la perte est suffisamment faible (par exemple, inf√©rieure √† 0.01)

**R√©sultat attendu :** Vous devez obtenir un graphique o√π :  
    - les points bleus correspondent aux donn√©es r√©elles (``y_true``),  
    - et une droite rouge correspond aux pr√©dictions (``y_pred``).  

Exemple d‚Äôaffichage attendu :

.. image:: images/chap1_exo_2_resultat.png
    :alt: droite ajust√©e aux points
    :align: center


.. slide::
‚öñÔ∏è Exercice 3 : Trouver la droite qui passe au mieux par les donn√©es avec une fonction de perte de type valeur absolue
--------------------------------------------------

**Objectif** :  
L'objectif est le m√™me que celui de l'exercice pr√©c√©dent (faire de la r√©gression lin√©aire), mais cette fois-ci,  vous allez utiliser une fonction de perte de type valeur absolue (MAE de l'anglais Mean Absolute Error)  au lieu de la MSE. L‚Äôid√©e de cet exercice est de comparer deux optimisateurs SGD et Adam.

**Consignes :**  Impl√©menter une boucle d'entra√Ænement pour ajuster les param√®tres d'une droite aux donn√©es fournies dans l'exercice pr√©c√©dent en utilisant une fonction de perte de type valeur absolue et en r√©utilisant l'impl√©mentation de l'exercice pr√©c√©dent.

.. step:: 
 
    1) R√©utilisez la boucle d'entra√Ænement de l‚Äôexercice pr√©c√©dent qui s'arr√™te au bout de 2500 it√©rations et qui utilise un learning rate de 0.01.  

.. step:: 
    2) Remplacez la fonction de perte MSE par une fonction de perte de type MAE. Il faudra chercher dans la documentation comment l'impl√©menter dans PyTorch.  
   
.. step::    
    3) Testez avec l‚Äôoptimiseur SGD puis avec l‚Äôoptimiseur Adam.  

.. step:: 
    4) Pour chaque optimiseur, affichez les param√®tres appris $$a$$ et $$b$$.

.. step::
    5) Tracez les donn√©es r√©elles et les donn√©es pr√©dites pour comparer visuellement les r√©sultats.  

.. step::
    6) Comparez les deux m√©thodes : que constatez-vous en termes de stabilit√© et de vitesse de convergence ?  

.. step::
    7) Expliquez quel optimiseur est meilleur et pourquoi?

.. step::
    8) Essayez de modifier le taux d'apprentissage (learning rate) pour voir son impact sur la convergence ainsi que le nombre d'it√©rations n√©cessaires.

**Astuce :**
.. spoiler::
    .. discoverList::
        - La valeur absolue dans PyTorch s'obtient avec la fonction ``nn.L1Loss()``.
        - Adam g√®re mieux ce type de fonction de perte non d√©rivable partout.


**R√©sultat attendu :**
Vous devez obtenir des valeurs pour les param√®tres proches de :

    - Adam -> a = 1.5451, b = 12.5996
    - SGD  -> a = 2.3039, b = 12.1880


et un graphique similaire √† celui ci-dessous :

.. image:: images/chap1_exo_3_resultat.png
    :alt: droite ajust√©e aux points
    :align: center



.. slide::
üèãÔ∏è Exercices Suppl√©mentaires
--------------------

.. toctree::

    exos_sup_chap1