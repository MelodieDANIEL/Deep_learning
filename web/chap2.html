<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8" />
<link rel="stylesheet" type="text/css" href="css/style.css" />
<title>Intro Python - Chapitre 2 ‚Äî Perceptron multi-couches </title>

                <meta http-equiv="X-UA-Compatible" content="IE=edge">
                <meta name="viewport" content="viewport-fit=cover, width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
            

                <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
                <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
            
<link href="https://fonts.googleapis.com/css2?family=Gentium+Basic&display=swap" rel="stylesheet"> 
<link rel="stylesheet" type="text/css" href="slidey/bootstrap/css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" href="slidey/bootstrap-icons/font/bootstrap-icons.css" />
<link rel="stylesheet" type="text/css" href="slidey/highlight.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.menu.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.step.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.code.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.slide.css" />
<script type="text/javascript" src="slidey/js/jquery.js"></script>
<script type="text/javascript" src="slidey/js/slidey.permalink.js"></script>
<script type="text/javascript" src="slidey/js/slidey.menu.js"></script>
<script type="text/javascript" src="slidey/js/slidey.mobile.js"></script>
<script type="text/javascript" src="slidey/js/slidey.spoilers.js"></script>
<script type="text/javascript" src="slidey/js/slidey.steps.js"></script>
<script type="text/javascript" src="slidey/js/slidey.js"></script>
<script type="text/javascript" src="slidey/js/main.js"></script>
<script type="text/javascript" src="slidey/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="slidey/highlight/highlight.pack.js"></script>
<link rel="icon" type="image/x-icon" href="favicon.ico" />
</head>
<body>
<!-- Modal log-in window -->
<div class="modal fade" id="loginWindow">
  <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
            <h5 class="modal-title">Log-in</h5>
            <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
          </div>    
        <div class="modal-body">
            <form>
                Mot de passe&nbsp;:<br />
                <input class="form-control" type="password" name="password" />
            </form>
        </div>
      </div><!-- /.modal-content -->
    </div><!-- /.modal-dialog -->
</div>

<div class="core">

    <script>hljs.highlightAll();</script>

<!-- Extra-controls for mobile device -->
<div class="mobileControls">
    <div class="btn-group">
        <a href="javascript:void(0)" class="left btn btn-light btn-lg">
            <i class="bi bi-arrow-up"></i>
        </a>
        <a href="javascript:void(0)" class="right btn btn-light btn-lg">
            <i class="bi bi-arrow-down"></i>
        </a>
        <a href="javascript:void(0)" class="up btn btn-light btn-lg">
            <i class="bi bi-arrow-left"></i>
        </a>
        <a href="javascript:void(0)" class="down btn btn-light btn-lg">
            <i class="bi bi-arrow-right"></i>
        </a>
        <a href="javascript:void(0)" class="login btn btn-light btn-lg">
            <i class="bi bi-lock"></i>
        </a>
    </div>
</div>

<!-- Controls -->
<div class="slideMode">
    <div class="btn-group">
        <a href="javascript:void(0)" class="btn btn-light btn-lg slideModeSlide"><i class="bi bi-film"></i></a>
        <a href="javascript:void(0)" class="btn btn-light btn-lg followMode"><i class="bi bi-stopwatch"></i> </a>
        <a href="index.html" class="btn btn-light btn-lg goHome"><i class="bi bi-house"></i></a>
    </div>
</div>

<div class="exitSlideMode">
    <div class="btn-group">
        <a href="javascript:void(0)" class="btn btn-light btn-lg followMode"><i class="bi bi-stopwatch"></i></a>
        <a href="javascript:void(0)" class="btn btn-light btn-lg showMobile"><i class="bi bi-phone"></i></a>
        <a href="javascript:void(0)" class="btn btn-light btn-lg stopShow">
            <span class="currentSlideNumber">
            </span>
            <i class="bi bi-x-lg"></i>
        </a>
    </div>
</div>

<!-- Browsing menu -->
<div class="menu">
</div>

<div class="contents container">

<div class="slide ">
<a id="title.1"></a><h1>Chapitre 2 ‚Äî Perceptron multi-couches </h1>
<a id="title.1.1"></a><h2>üéØ Objectifs du Chapitre</h2>
<div class="alert alert-light p-2 fs-5 text-center"><p>√Ä la fin de cette section,  vous saurez :  </p>
<ul><li class="dash">Le fonctionnement du perceptron simple.</li>
<li class="dash">Utiliser une fonction d&#039;activation adapt√©e.</li>
<li class="dash">L‚Äôimportance de la normalisation / standardisation des donn√©es et l&#039;usage des epochs.</li>
<li class="dash">Construire un r√©seau de neurones avec <code>torch.nn</code>.</li>
<li class="dash">Faire un entra√Ænement simple d‚Äôun MLP pour un probl√®me de r√©gression.</li>
<li class="dash">Suivre l‚Äô√©volution de la loss et interpr√©ter les r√©sultats.</li>
<li class="dash">Utiliser <code>torch-summary</code> pour inspecter l‚Äôarchitecture du r√©seau.</li>
</ul>

</div>
</div><div class="slide ">
<a id="title.1.2"></a><h2>üìñ 1. Rappels sur les perceptrons</h2>
<p>Le perceptron multi-couches (MLP de Multi-Layers Perceptron en anglais) est la brique de base des r√©seaux de neurones modernes. Dans ce chapitre, nous allons l‚Äôappliquer √† des probl√®mes de r√©gression simple. Avant de commencer, voici quelques rappels.</p>
<a id="title.1.2.1"></a><h3>1.1. Perceptron simple</h3>
<p>Le perceptron est le bloc de base d‚Äôun r√©seau de neurones. Il r√©alise une transformation lin√©aire suivie (ou pas) d‚Äôune fonction d‚Äôactivation telle que :  </p>
<blockquote>$$y = \sigma(Wx + b)$$
<p>o√π : <br /> - \(y\) est la sortie du perceptron,<br /> - \(\sigma\) est une fonction d‚Äôactivation,<br /> - \(W\) est la matrice des poids, <br /> - \(b\) est le biais et <br /> - \(x\) est l&#039;ensemble des entr√©es du perceptron.</p>
</blockquote>
</div><div class="slide ">
<a id="title.1.2.2"></a><h3>1.2. Perceptron intuition</h3>
<img src="images/chap2_perceptron.png"  alt="perceptron" align="center" width="40%" />
<p>avec \(y= \sigma(x_1*w_1 + x_2*w_2 + ...+ x_i*w_i + ... + x_n*w_n + b)\)</p>
<p>üí° <strong>Intuition :</strong></p>
<ul><li class="dash">Chaque poids \(w_i\) mesure l‚Äôimportance de la caract√©ristique \(x_i\).</li>
<li class="dash">Le biais \(b\) d√©place la fronti√®re de d√©cision.</li>
<li class="dash">La fonction d‚Äôactivation permet d‚Äôintroduire de la non-lin√©arit√©, indispensable pour mod√©liser des relations complexes mais nous en parleront plus en d√©tails par la suite.</li>
</ul>

</div><div class="slide ">
<a id="title.1.2.3"></a><h3>1.3. Mise √† jour des param√®tres</h3>
<p>Un perceptron poss√®de deux types de <strong>param√®tres</strong> : les <strong>poids</strong> et le <strong>biais</strong>.  </p>
<p>Lors de l‚Äôentra√Ænement, on souhaite ajuster ces param√®tres pour am√©liorer les pr√©dictions du mod√®le.  Pour cela, il faut mettre √† jour les poids apr√®s avoir calcul√© la loss gr√¢ce √† la fonction de perte et le gradient gr√¢ce √† l&#039;optimiseur comme expliqu√© dans le chapitre pr√©c√©dent.  </p>
<p>Pour rappel, on met √† jours les param√®tres du mod√®le gr√¢ce √† l&#039;√©quation introduite dans le chapitre pr√©c√©dent. </p>
$$\theta \leftarrow \theta - \eta \, \nabla_\theta \mathcal{L}(\theta)$$
<p>o√π :  </p>
<ul><li class="dash">\(\theta\) repr√©sente l‚Äôensemble des param√®tres du mod√®le (ici \(W\) et \(b\)),</li>
<li class="dash">\(\mathcal{L}\) est la fonction de perte,</li>
<li class="dash">\(\nabla_\theta \mathcal{L}\) est le gradient de la perte par rapport aux param√®tres,</li>
<li class="dash">\(\eta\) est le taux d‚Äôapprentissage (learning rate en anglais).</li>
</ul>

</div><div class="slide ">
<a id="title.1.2.4"></a><h3>1.4. Exemples d&#039;applications du perceptron simple</h3>
<p>Un perceptron simple ne peut r√©soudre que les probl√®mes lin√©airement s√©parables puisque en trouvant les param√®tres du mod√®le, le perceptron trace une droite dans le plan des entr√©es et s√©pare les points selon qu‚Äôils sont au-dessus ou en dessous de cette droite.</p>
<p><strong>Exemple 1 : porte logique ET</strong></p>
<table class="table table-striped"><tbody><tr><th>x‚ÇÅ</th><th>x‚ÇÇ</th><th>y=ET</th></tr><tr><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>0</td></tr><tr><td>1</td><td>0</td><td>0</td></tr><tr><td>1</td><td>1</td><td>1</td></tr></tbody></table>
<p>Dans ce cas, une droite s√©pare bien les deux classes :  </p>
<ul><li class="dash">la classe \(0\) (points en bas √† gauche, en haut √† gauche, en bas √† droite),</li>
<li class="dash">la classe \(1\) (point en haut √† droite).</li>
</ul>

<p>Un perceptron simple peut donc apprendre cette fonction.</p>
</div><div class="slide ">
<p><strong>Exemple 2 : porte logique XOR</strong></p>
<table class="table table-striped"><tbody><tr><th>x‚ÇÅ</th><th>x‚ÇÇ</th><th>y=XOR</th></tr><tr><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>1</td></tr><tr><td>1</td><td>0</td><td>1</td></tr><tr><td>1</td><td>1</td><td>0</td></tr></tbody></table>
<p>Ici, il est impossible de tracer une seule droite qui s√©pare correctement les classes. Autrement dit, XOR n‚Äôest pas lin√©airement s√©parable.  </p>
<img src="images/chap2_et_vs_xor.png"  alt="Repr√©sentation du XOR dans le plan (non-s√©parable lin√©airement)" align="center" width="300%" />
<p><strong>Conclusion :</strong> </p>
<ul><li class="dash">Le perceptron simple suffit pour des t√¢ches lin√©aires (comme ET, OU).</li>
<li class="dash">Pour r√©soudre des probl√®mes plus complexes comme XOR, il faut introduire plusieurs couches de neurones et des fonctions d‚Äôactivation non-lin√©aires : c‚Äôest le principe du <strong>perceptron multi-couches (MLP)</strong>.</li>
</ul>

</div><div class="slide ">
<a id="title.1.2.5"></a><h3>1.5. Faire un perceptron dans PyTorch</h3>
<p>Pour cr√©er un perceptron simple dans PyTorch, on peut utiliser la fonction <code>Linear</code> de <code>torch.nn</code>, qui impl√©mente une couche lin√©aire (ou affine) : \(y = Wx + b\). La fonction <code>Linear</code> prend en entr√©e le nombre d&#039;entr√©e \(x\) et le nombre de sortie \(y\).</p>
<pre><code class="python hljs">import torch
import torch.nn as nn

# Donn√©es ET
X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32)
y = torch.tensor([[0],[0],[0],[1]], dtype=torch.float32)

# Mod√®le lin√©aire (perceptron)
model = nn.Linear(2, 1, bias=True)

# Loss function et optimiseur
loss_fc = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)

# Entra√Ænement
for _ in range(500):
    optimizer.zero_grad()
    loss = loss_fc(model(X), y)
    loss.backward()
    optimizer.step()

# R√©sultat
with torch.no_grad():
    print((model(X)).round())
    print(model.weight, model.bias)</code></pre>
<p><strong>Remarque</strong> : si maintenant on change les entr√©es et sorties pour le XOR, le mod√®le ne pourra pas apprendre correctement la fonction (les \(W\) restent √† 0 comme √† l&#039;initialisation). Vous pouvez faire le test pour v√©rifier.</p>
</div><div class="slide ">
<a id="title.1.3"></a><h2>üìñ 2. Fonction d&#039;activation</h2>
<p>Les fonctions d‚Äôactivation introduisent de la non-lin√©arit√© dans le mod√®le, ce qui permet de mieux capturer des relations complexes dans les donn√©es. Sans une fonction d&#039;activation, un perceptron (ou m√™me plusieurs formant un r√©seau de neurones de plusieurs couches) ne ferait que des combinaisons lin√©aires et ne pourrait pas r√©soudre des probl√®mes non lin√©aires comme XOR. </p>
</div><div class="slide ">
<a id="title.1.3.1"></a><h3>2.1. √âquations des fonctions d&#039;activation</h3>
<p>Voici quatres fonctions d‚Äôactivation couramment utilis√©es :</p>
<ol><li class=""><strong>Sigmo√Øde</strong> : \(\sigma(x) = \frac{1}{1 + e^{-x}}\)</li>
<ul><li class="dash">Sortie comprise entre 0 et 1.</li>
<li class="dash">Utilis√©e pour les probl√®mes de classification binaire.</li>
</ul>
<li class=""><strong>Tanh</strong> : \(\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}\)</li>
<ul><li class="dash">Sortie comprise entre -1 et 1.</li>
<li class="dash">Souvent utilis√©e dans les couches cach√©es des r√©seaux de neurones.</li>
</ul>
<li class=""><strong>ReLU (de Rectified Linear Unit en anglais)</strong> : \(\text{ReLU}(x) = \max(0, x)\)</li>
<ul><li class="dash">Sortie nulle pour les entr√©es n√©gatives.</li>
<li class="dash">La plus utilis√©e dans les r√©seaux de neurones profonds en raison de sa simplicit√© et de son efficacit√©.</li>
</ul>
<li class=""><strong>Softmax</strong> : \(\text{Softmax}(x_i) = \frac{e^{x_i}}{\sum_{j} e^{x_j}}\)</li>
<ul><li class="dash">Transforme un vecteur en une distribution de probabilit√© (chaque sortie est comprise entre 0 et 1 et la somme vaut 1).</li>
<li class="dash">Utilis√©e en sortie des mod√®les de classification multi-classes.</li>
</ul>
</ol>

</div><div class="slide ">
<a id="title.1.3.2"></a><h3>2.2. Repr√©sentation graphique des fonctions d&#039;activation</h3>
<img src="images/chap2_fonctions_d_activation.png"  alt="Repr√©sentation des fonctions d&#039;activation" align="center" width="200%" />
</div><div class="slide ">
<a id="title.1.3.3"></a><h3>2.3. Les fonctions d&#039;activation dans PyTorch</h3>
<p>Dans PyTorch, les fonctions d&#039;activation sont disponibles dans la biblioth√®que `torch.nn`. Voici quelques exemples :</p>
<ol><li class=""><strong>Sigmo√Øde</strong> : <code>nn.sigmoid(x)</code></li>
<li class=""><strong>Tanh</strong> : <code>nn.tanh(x)</code></li>
<li class=""><strong>ReLU</strong> : <code>nn.relu(x)</code></li>
<li class=""><strong>Softmax</strong> : <code>nn.softmax(x, dim=1)</code></li>
</ol>

</div><div class="slide ">
<a id="title.1.3.4"></a><h3>2.4. R√¥le de la fonction d‚Äôactivation</h3>
<p>Reprenons le probl√®me ET avec un perceptron.</p>
<ul><li class="dash"><strong>Sans fonction d‚Äôactivation</strong> :
  Le perceptron calcule une combinaison lin√©aire des entr√©es : \( z = w_1 x_1 + w_2 x_2 + b \).
  La sortie est un nombre r√©el, positif ou n√©gatif. Pour classer les donn√©es, on fixe un seuil arbitraire (par exemple : si \(z > 0\) alors classe 1, sinon 0). La fronti√®re de d√©cision reste <strong>lin√©aire</strong>.</li>
<li class="dash"><strong>Avec une fonction d&#039;activation (la fonction sigmo√Øde par exemple)</strong> :
  On applique une transformation non lin√©aire : \(\hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}}\).
  La sortie est toujours comprise entre 0 et 1. On peut alors l‚Äôinterpr√©ter comme une <strong>probabilit√©</strong> qui mesure la confiance du mod√®le dans sa pr√©diction : proche de 0 ‚Üí classe 0 et proche de 1 ‚Üí classe 1. Le seuil devient naturel : <strong>0.5</strong>.</li>
</ul>

<div class="alert alert-info"><p>Remarque : Dans le cas o√π le probl√®me √† r√©soudre est non lin√©airement s√©parable (comme XOR), une fonction d‚Äôactivation seule ne suffit pas. Il faut empiler plusieurs couches de neurones avec des fonctions d‚Äôactivation entre chaque couche pour capturer la complexit√© des donn√©es.</p></div>
</div><div class="slide ">
<a id="title.1.3.5"></a><h3>2.5. Exemple d&#039;utilisation des fonctions d&#039;activation</h3>
<p>Voici un exemple d&#039;utilisation des fonctions d&#039;activation pour le probl√®me ET avec un perceptron :</p>
<pre><code class="python hljs">import torch
import torch.nn as nn

# Donn√©es ET
X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32)
y = torch.tensor([[0],[0],[0],[1]], dtype=torch.float32)

# --- Cas 1 : Perceptron sans activation ---
linear = nn.Linear(2, 1, bias=True)
with torch.no_grad():
    linear.weight[:] = torch.tensor([[1., 1.]])  # w1=1, w2=1
    linear.bias[:] = torch.tensor([-1.5])        # b=-1.5

z = linear(X)  # sortie brute
print(&quot;Sorties sans activation :&quot;)
print(z)

# --- Cas 2 : Perceptron avec sigmo√Øde ---
sigmoid = nn.Sigmoid()
y_hat = sigmoid(z)
print(&quot;\nSorties avec sigmo√Øde :&quot;)
print(y_hat)</code></pre>
<p>Une sortie brute comme -1.5 devient 0.18 apr√®s sigmo√Øde, et 0.5 devient 0.62 : la sigmoid transforme les nombres en valeurs entre 0 et 1, les rendant interpr√©tables comme des probabilit√©s.</p>
</div><div class="slide ">
<a id="title.1.3.6"></a><h3>2.6. Choisir la fonction d&#039;activation adapt√©e</h3>
<p>On peut choisir la fonction d‚Äôactivation en fonction de plusieurs crit√®res: le probl√®me √† r√©soudre ou la convergence de l&#039;entra√Ænement.</p>
<p><strong>Choix selon le contexte</strong> : </p>
<ul><li class="dash">Pour une sortie binaire, la sigmo√Øde est adapt√©e car elle renvoie une valeur entre 0 et 1, interpr√©table comme une probabilit√©.</li>
<li class="dash">Pour une sortie multi-classes, la fonction Softmax normalise les valeurs pour obtenir une distribution de probabilit√©.</li>
<li class="dash">Pour des sorties continues ou pour moduler les valeurs internes, ReLU ou Tanh peuvent √™tre utilis√©es.</li>
</ul>

<p><strong>Impact sur l‚Äôapprentissage</strong> : <br />  Certaines fonctions d‚Äôactivation influencent la vitesse de convergence. Par exemple, la sigmo√Øde borne les sorties, ce qui peut r√©duire l‚Äôamplitude des gradients et ralentir l‚Äôapprentissage pour de grandes valeurs absolues.</p>
</div><div class="slide ">
<a id="title.1.4"></a><h2>üìñ 3. Epoch</h2>
<p>Lorsqu‚Äôon entra√Æne un mod√®le de machine learning, il est n√©cessaire de pr√©senter plusieurs fois l‚Äôensemble des donn√©es d‚Äôapprentissage \(x\) au mod√®le afin d‚Äôajuster correctement ses param√®tres.</p>
<a id="title.1.4.1"></a><h3>3.1 D√©finitions</h3>
<ul><li class="dash"><strong>It√©ration</strong> : mise √† jour des param√®tres du mod√®le apr√®s avoir trait√© un seul exemple ou un mini-batch.</li>
<li class="dash"><strong>Batch / mini-batch</strong> : sous-ensemble d‚Äôexemples utilis√© pour calculer la descente de grandient et la mise √† jour des param√®tres.</li>
<li class="dash"><strong>Epoch</strong> : passage complet sur toutes les donn√©es d‚Äôapprentissage.</li>
</ul>

<p><strong>Exemple</strong> :</p>
<p>Si vous disposez de 1000 exemples et que vous utilisez des mini-batchs de 100 exemples chacun, une epoch correspond √† 10 it√©rations (1000 √∑ 100). Apr√®s chaque epoch, chaque exemple de l‚Äôensemble d‚Äôapprentissage a √©t√© utilis√© exactement une fois pour mettre √† jour les param√®tres du mod√®le.</p>
</div><div class="slide ">
<a id="title.1.4.2"></a><h3>3.2 Pourquoi effectuer plusieurs epochs‚ÄØ?</h3>
<p>Au d√©but de l‚Äôentra√Ænement, le mod√®le commet souvent de grandes erreurs.  Chaque epoch permet aux poids et aux biais de s‚Äôajuster progressivement, am√©liorant ainsi les pr√©dictions. En pratique, plusieurs dizaines ou centaines d‚Äôepochs sont souvent n√©cessaires pour que la loss se stabilise et que le mod√®le converge vers une bonne solution.</p>
<p>üí° <strong>Intuition</strong> : imaginez un perceptron comme un √©l√®ve qui apprend : il ne retient pas tout parfaitement du premier coup. Il faut plusieurs passages sur les m√™mes exercices pour ma√Ætriser la t√¢che.</p>
</div><div class="slide ">
<a id="title.1.5"></a><h2>üìñ 4. Normalisation et standardisation des donn√©es</h2>
<p>Avant d&#039;entra√Æner un mod√®le, il est important de pr√©parer les donn√©es pour que l‚Äôapprentissage soit efficace. Pour cela, deux op√©rations courantes sont la normalisation et la standardisation.</p>
<a id="title.1.5.1"></a><h3>4.1. Normalisation</h3>
<p>La normalisation consiste √† mettre les valeurs dans une plage donn√©e, souvent entre 0 et 1. Cela est utile lorsque les donn√©es ont des √©chelles tr√®s diff√©rentes. Pour ceal , il faut appliquer la formule suivante √† chaque donn√©e:</p>
$$x'_i = \frac{x_i - x_\text{min}}{x_\text{max} - x_\text{min}}$$
<ul><li class="dash">\(x_\text{min}\) et \(x_\text{max}\) sont respectivement la valeur minimale et maximale de la variable.</li>
<li class="dash">\(x'_i\) est la valeur normalis√©e.</li>
</ul>

</div><div class="slide ">
<a id="title.1.5.2"></a><h3>4.2. Exemple de normalisation avec PyTorch</h3>
<pre><code class="python hljs">import torch
X = torch.tensor([[1., 50.],[2., 60.],[3., 55.]])
X_min = X.min(dim=0).values
X_max = X.max(dim=0).values
X_norm = (X - X_min) / (X_max - X_min)
print(X_norm)</code></pre>
</div><div class="slide ">
<a id="title.1.5.3"></a><h3>4.3. Standardisation</h3>
<p>La standardisation consiste √† centrer et r√©duire les variables : on soustrait la moyenne et on divise par l‚Äô√©cart-type. C‚Äôest particuli√®rement utile pour les algorithmes bas√©s sur le gradient (comme les perceptrons), car cela acc√©l√®re la convergence. Pour standardiser les donn√©es voici la formule √† appliquer pour chaque donn√©e :</p>
$$x'_i = \frac{x_i - \mu}{\sigma}$$
<ul><li class="dash">\(\mu\) est la moyenne de la variable.</li>
<li class="dash">\(\sigma\) est l‚Äô√©cart-type.</li>
</ul>

</div><div class="slide ">
<a id="title.1.5.4"></a><h3>4.4. Exemple de standardisation avec PyTorch</h3>
<blockquote><p>Contrairement √† la normalisation, la standardisation a une fonction dans PyTorch pr√©-impl√©ment√©e nomm√©e <code>torch.nn.BatchNorm1d</code>. Voici comment l&#039;impl√©menter avec PyTorch :</p>
</blockquote>
<pre><code class="python hljs">import torch
import torch.nn as nn

X = torch.tensor([[1., 50.],[2., 60.],[3., 55.]], dtype=torch.float32)

# Standardisation &quot;manuelle&quot;
X_mean = X.mean(dim=0)
X_std = X.std(dim=0)
X_stdized = (X - X_mean) / X_std
print(&quot;Standardisation manuelle :&quot;)
print(X_stdized)

# Standardisation avec BatchNorm1d
batchnorm = nn.BatchNorm1d(num_features=2, affine=False)
X_stdized_bn = batchnorm(X)
print(&quot;\nStandardisation avec BatchNorm1d :&quot;)
print(X_stdized_bn)</code></pre>
</div><div class="slide ">
<a id="title.1.5.5"></a><h3>4.5. Normalisation vs. Standardisation</h3>
<p>La standardisation est souvent pr√©f√©r√©e √† la normalisation car elle est <strong>plus robuste aux valeurs aberrantes</strong> et permet une <strong>convergence plus rapide</strong> du mod√®le.</p>
<ul><li class="dash"><strong>Robustesse aux valeurs aberrantes</strong> : la standardisation centre et r√©duit les donn√©es par rapport √† la moyenne et √† l‚Äô√©cart-type, plut√¥t que de les ramener dans une plage fixe comme la normalisation Min-Max. Une valeur tr√®s grande ou tr√®s petite affecte moins l‚Äô√©chelle globale et n‚Äô√©crase pas les autres donn√©es.</li>
<li class="dash"><strong>Convergence plus rapide</strong> : la standardisation met toutes les variables sur une √©chelle comparable. Sans standardisation, une variable avec de grandes valeurs provoque de tr√®s grands gradients dans sa direction, tandis qu‚Äôune variable plus petite change lentement. Le gradient combin√© suit alors une trajectoire en zigzag, avan√ßant lentement vers le minimum. En standardisant, les gradients sont √©quilibr√©s et le mod√®le descend plus directement vers la solution optimale.</li>
</ul>

</div><div class="slide ">
<a id="title.1.5.6"></a><h3>4.6. Ce qui est attendu apr√®s la standardisation</h3>
<p>Apr√®s avoir centr√© et r√©duit les donn√©es, la standardisation permet g√©n√©ralement d&#039;avoir une <strong>moyenne proche de 0</strong> et un <strong>√©cart-type proche de 1</strong> pour chaque variable.</p>
<p><strong>Pourquoi ?</strong></p>
<ul><li class="dash">Une moyenne proche de 0 aide les fonctions d&#039;activation et la descente de gradient √† mieux fonctionner, sans que le mod√®le doive apprendre un biais pour d√©caler toutes les donn√©es.</li>
<li class="dash">Un √©cart-type proche de 1 met toutes les donn√©es sur une √©chelle comparable, ce qui √©vite que certaines variables dans dans les donn√©es dominent les gradients et permet une descente plus directe vers le minimum de la loss.</li>
</ul>

<div class="alert alert-info"><p>Si la standardisation est appliqu√©e sur un mini-batch (par exemple avec BatchNorm1d), la moyenne et l‚Äô√©cart-type sont calcul√©s sur ce mini-batch. Dans ce cas, la moyenne n‚Äôest pas exactement 0 et l‚Äô√©cart-type n‚Äôest pas exactement 1 pour l‚Äôensemble du dataset. De plus, certains modules comme BatchNorm peuvent apprendre un scale et un shift, modifiant l√©g√®rement ces valeurs finales.</p>
</div>
<p><strong>Est-ce grave si ce n&#039;est pas exactement 0 et 1 ?</strong></p>
<ul><li class="dash">Pas n√©cessairement : une moyenne et un √©cart-type approximatifs suffisent g√©n√©ralement pour que l&#039;apprentissage reste efficace.</li>
<li class="dash">Par contre, si les valeurs sont tr√®s √©loign√©es de 0 ou tr√®s dispers√©es, certaines fonctions d&#039;activation peuvent saturer et ralentir la convergence.</li>
</ul>

</div><div class="slide ">
<a id="title.1.6"></a><h2>üìñ 5. R√©seaux de neurones multi-couches (MLP)</h2>
<p>Les r√©seaux de neurones multi-couches (MLP, de l&#039;anglais Multi-Layer Perceptron) permettent de r√©soudre des probl√®mes non lin√©aires comme XOR, que le perceptron simple ne peut pas g√©rer. Un MLP se compose de <strong>couches lin√©aires</strong> suivies de <strong>fonctions d&#039;activation</strong>, et peut √™tre construit tr√®s simplement avec <code>torch.nn.Sequential</code>.</p>
<a id="title.1.6.1"></a><h3>5.1. D√©finitions</h3>
<ul><li class="dash"><strong>Une couche</strong> d&#039;un MLP se compose d&#039;un ensemble de perceptrons. Chaque perceptron (aussi appel√© neurone) re√ßoit les m√™mes entr√©es et produit une sortie individuelle. La combinaison des sorties de tous les perceptrons forme le vecteur de sortie de la couche.</li>
<li class="dash">Il existe plusieurs types de couches :</li>
<ul><li class="dash"><strong>La couche d&#039;entr√©e</strong> re√ßoit les features du dataset et les transmet √† la premi√®re couche cach√©e.</li>
<li class="dash"><strong>Les couches cach√©es</strong> sont situ√©es entre l&#039;entr√©e et la sortie, elles permettent de mod√©liser des relations non lin√©aires entre les variables.</li>
<li class="dash"><strong>La couche de sortie</strong> produit la sortie finale du r√©seau (par exemple, une probabilit√© pour la classification binaire).</li>
</ul>
</ul>

</div><div class="slide ">
<a id="title.1.6.2"></a><h3>5.2. Construction d&#039;un MLP</h3>
<p>Pour construire un MLP, il faut choisir le nombre de couches et de neurones par couche ainsi que la fonction d&#039;activation √† utiliser apr√®s chaque couche. Il n‚Äôest g√©n√©ralement pas possible de conna√Ætre √† l‚Äôavance le nombre exact √† mettre. On teste plusieurs architectures pour trouver celle qui converge correctement et rapidement.</p>
<ul><li class="dash">Nombre de couches cach√©es : g√©n√©ralement 1 ou 2 couches suffisent pour des probl√®mes simples comme XOR. Pour des probl√®mes plus complexes, plusieurs couches peuvent √™tre n√©cessaires.</li>
<li class="dash">Nombre de neurones par couche : il n‚Äôexiste pas de r√®gle stricte. On choisit un nombre suffisant pour capturer la complexit√© du probl√®me, mais pas trop pour √©viter le surapprentissage (lorsque le mod√®le s&#039;adapte trop aux donn√©es d&#039;entra√Ænement et ne g√©n√©ralise pas bien sur de nouvelles donn√©es).</li>
<li class="dash">En pratique, on peut commencer par un petit nombre de neurones et augmenter si le mod√®le n‚Äôarrive pas √† converger correctement.</li>
</ul>

<p>üí° R√©sum√© : <br />Chaque couche d‚Äôun MLP est un ensemble de perceptrons. Les couches cach√©es permettent de mod√©liser la non-lin√©arit√©, et le nombre de couches et de neurones doit √™tre choisi en fonction de la complexit√© du probl√®me et de la performance souhait√©e.</p>
</div><div class="slide ">
<a id="title.1.6.3"></a><h3>5.3. Construire un MLP simple avec <code>torch.nn</code></h3>
<p>Pour cr√©er un MLP dans PyTorch, on utilise principalement :  </p>
<ul><li class="dash"><code>Sequential</code> : permet d‚Äôempiler facilement les couches les unes apr√®s les autres.</li>
<li class="dash"><code>Linear</code> : cr√©e une couche affine, c‚Äôest-√†-dire une transformation de la forme \(y = Wx + b\).</li>
<li class="dash">Fonctions d‚Äôactivation : introduisent de la <strong>non-lin√©arit√©</strong> dans le mod√®le (par exemple <code>nn.ReLU()</code> ou <code>nn.Sigmoid()</code>).</li>
</ul>

<p>Exemple minimal d‚Äôun r√©seau de neurones pour une r√©gression 1D avec un MLP √† deux couches cach√©es :</p>
<pre><code class="python hljs">import torch.nn as nn

model = nn.Sequential(
    nn.Linear(1, 10),   # couche d&#039;entr√©e 1D -&gt; premi√®re couche cach√©e 10 neurones
    nn.ReLU(),           # activation non lin√©aire
    nn.Linear(10, 5),    # deuxi√®me couche cach√©e avec 5 neurones
    nn.ReLU(),           # activation non lin√©aire
    nn.Linear(5, 1)      # couche de sortie 1D
)</code></pre>
<p>üí° Remarques :  </p>
<ul><li class="dash">La premi√®re couche transforme l‚Äôentr√©e en un vecteur de dimension 10.</li>
<li class="dash">La deuxi√®me couche r√©duit ce vecteur √† 5 dimensions, permettant au r√©seau de combiner et transformer les features.</li>
<li class="dash">Chaque couche cach√©e est suivie d‚Äôune fonction d‚Äôactivation pour capturer la non-lin√©arit√©.</li>
<li class="dash">La couche finale produit la sortie finale du r√©seau.</li>
</ul>

<div class="alert alert-info"><p><strong>Important</strong> : La dimension de sortie d‚Äôune couche doit correspondre √† la dimension d‚Äôentr√©e de la couche suivante.</p>
</div>
</div><div class="slide ">
<a id="title.1.6.4"></a><h3>5.4. Construire un MLP avec une classe</h3>
<p>Dans PyTorch, il est courant de d√©finir un mod√®le en cr√©ant une classe qui h√©rite de <code>nn.Module</code>. Cela permet de mieux organiser le code, de r√©utiliser le mod√®le facilement. Dans ce cas, la m√©thode <code>forward</code>  d√©crit comment les donn√©es traversent le r√©seau.</p>
<p>Voici le m√™me exemple que pr√©c√©demment avec une classe :</p>
<pre><code class="python hljs">import torch
import torch.nn as nn

class SimpleMLP(nn.Module):
    def __init__(self):
        super(SimpleMLP, self).__init__()
        self.fc1 = nn.Linear(1, 10)   # premi√®re couche cach√©e
        self.fc2 = nn.Linear(10, 5)   # deuxi√®me couche cach√©e
        self.fc3 = nn.Linear(5, 1)    # couche de sortie
        self.relu = nn.ReLU()         # fonction d&#039;activation

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x

 # Cr√©ation d&#039;une instance du mod√®le
 model = SimpleMLP()</code></pre>
<p>üí° Remarques : </p>
<ul><li class="dash">La m√©thode <code>forward</code> d√©finit comment les donn√©es passent de la couche d&#039;entr√©e √† la sortie, en appliquant les fonctions d‚Äôactivation entre les couches.</li>
<li class="dash">L‚Äôavantage de la classe : elle permet de s√©parer la d√©finition du mod√®le et l‚Äôentra√Ænement, ce qui rend le code plus clair et modulable.</li>
<li class="dash">On peut facilement r√©utiliser ce mod√®le pour diff√©rentes entr√©es ou probl√®mes.</li>
</ul>

</div><div class="slide ">
<a id="title.1.6.5"></a><h3>5.5. R√©soudre XOR avec un MLP</h3>
<p>Comme expliqu√© pr√©c√©demment, un perceptron simple ne peut pas r√©soudre le probl√®me XOR, m√™me avec une fonction d‚Äôactivation, car il ne fait qu‚Äôune s√©paration lin√©aire (une droite).</p>
<ul><li class="dash">Pour le XOR, il faut un r√©seau de neurones avec au moins une couche cach√©e et une fonction d‚Äôactivation √† la sortie de la couche cach√©e.</li>
<li class="dash">La fronti√®re de d√©cision apprise n‚Äôest plus une droite mais une courbe form√©e par la combinaison des sorties de plusieurs neurones. Visuellement, cela peut ressembler √† deux demi-plans combin√©s ou √† une courbe ferm√©e entourant certains points, selon l‚Äôactivation utilis√©e (Tanh ou ReLU).</li>
</ul>

<p>Exemple minimal en PyTorch avec une seule couche cach√©e et une activation non-lin√©aire :</p>
<pre><code class="python hljs">import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

# Donn√©es XOR
X = torch.tensor([[0,0],[0,1],[1,0],[1,1]], dtype=torch.float32)
y = torch.tensor([[0],[1],[1],[0]], dtype=torch.float32)

# D√©finition du MLP avec une classe
class XORMLP(nn.Module):
    def __init__(self):
        super(XORMLP, self).__init__()
        self.fc1 = nn.Linear(2, 4)  # couche cach√©e 1
        self.fc2 = nn.Linear(4, 1)  # couche de sortie
        self.activation = nn.ReLU()
        self.out_activation = nn.Sigmoid()
    
    def forward(self, x):
        x = self.activation(self.fc1(x))
        x = self.out_activation(self.fc2(x))
        return x

# Cr√©ation du mod√®le
model = XORMLP()

# Optimiseur et fonction de perte
optimizer = optim.Adam(model.parameters(), lr=0.05)
fc_loss = nn.MSELoss()

# Entra√Ænement
for epoch in range(5000):
    y_pred = model(X)
    loss = fc_loss(y_pred, y)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

# V√©rification num√©rique
with torch.no_grad():
    y_pred_train = model(X)
    y_class = (y_pred_train &gt; 0.5).float()
    print(&quot;Pr√©dictions (probabilit√©s) :\n&quot;, y_pred_train)
    print(&quot;Classes pr√©dites :\n&quot;, y_class)
    print(&quot;Classes r√©elles :\n&quot;, y)
    correct = (y_class == y).all()
    print(&quot;Toutes les pr√©dictions sont correctes :&quot;, correct)

# Affichage de la fronti√®re de d√©cision
xx, yy = torch.meshgrid(torch.linspace(-0.5, 1.5, 200),
                        torch.linspace(-0.5, 1.5, 200))
grid = torch.cat([xx.reshape(-1,1), yy.reshape(-1,1)], dim=1)
with torch.no_grad():
    zz = model(grid).reshape(xx.shape)

plt.contourf(xx, yy, zz, levels=[0,0.5,1], alpha=0.3, colors=[&quot;red&quot;,&quot;blue&quot;])
plt.scatter(X[:,0], X[:,1], c=y[:,0], cmap=&quot;bwr&quot;, edgecolors=&quot;k&quot;, s=100)
plt.title(&quot;Fronti√®re de d√©cision XOR avec MLP en classe&quot;)
plt.xlabel(&quot;x1&quot;)
plt.ylabel(&quot;x2&quot;)
plt.show()</code></pre>
<p>üí° Remarques :</p>
<ul><li class="dash">La fonction d‚Äôactivation dans la couche cach√©e est essentielle pour r√©soudre des probl√®mes non lin√©aires comme XOR.</li>
<li class="dash">La sortie finale est transform√©e par la Sigmo√Øde, produisant une probabilit√© entre 0 et 1 pour la classification binaire.</li>
<li class="dash">M√™me un petit MLP avec une seule couche cach√©e de 4 neurones suffit pour apprendre XOR gr√¢ce √† la non-lin√©arit√© introduite par ReLU.</li>
<li class="dash">L‚Äôutilisation d‚Äôune classe et de la m√©thode <code>forward</code> rend le code plus modulable et facilite l‚Äôexp√©rimentation avec diff√©rentes architectures de MLP.</li>
<li class="dash">Vous pouvez remplacer la ReLU par une Tanh et voir la diff√©rence dans l&#039;affichage.</li>
</ul>

</div><div class="slide ">
<a id="title.1.6.6"></a><h3>5.6. Standardisation et entra√Ænement d&#039;un MLP sur un exemple de r√©gression</h3>
<p>On repart avec un exemple de r√©gression simple pour illustrer l&#039;importance de la standardisation des donn√©es avant l&#039;entra√Ænement d&#039;un MLP. L&#039;objectif est de pr√©dire la sortie y pour de nouvelles entr√©es x que celles sur lesquelles le mod√®le a √©t√© entra√Æn√©.</p>
<pre><code class="python hljs">import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

# Donn√©es
X = torch.tensor([[0.],[10.],[20.],[30.],[40.],[50.]])
y = 2*X + 1 # relation lin√©aire exacte
# y = 2*X + 1 + torch.randn_like(X)*5  # relation lin√©aire bruit√©e

# Standardisation
X_mean, X_std = X.mean(), X.std()
X_stdized = (X - X_mean)/X_std

# Mod√®le simple
class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(1, 5),
            nn.ReLU(),
            nn.Linear(5,1)
        )
    def forward(self, x):
        return self.net(x)

# Mod√®les
model_no_std = MLP()
model_std = MLP()

# Optimiseur
optimizer_no_std = optim.SGD(model_no_std.parameters(), lr=0.001)
optimizer_std = optim.SGD(model_std.parameters(), lr=0.01)

# Entra√Ænement
for _ in range(5000):
    # Sans standardisation
    pred_no_std = model_no_std(X)
    loss_no_std = ((pred_no_std - y)**2).mean()
    optimizer_no_std.zero_grad()
    loss_no_std.backward()
    optimizer_no_std.step()

    # Avec standardisation
    pred_std = model_std(X_stdized)
    loss_std = ((pred_std - y)**2).mean()
    optimizer_std.zero_grad()
    loss_std.backward()
    optimizer_std.step()

# Test des pr√©dictions
X_test = torch.tensor([[0.],[60.]])
X_test_std = (X_test - X_mean)/X_std

with torch.no_grad():
    preds_no_std = model_no_std(X_test)
    preds_std = model_std(X_test_std)

print(&quot;Pr√©dictions finales (Sans standardisation) :&quot;, preds_no_std.squeeze().tolist())
print(&quot;Pr√©dictions finales (Avec standardisation)  :&quot;, preds_std.squeeze().tolist())

# Visualisation
plt.scatter(X, y, color=&#039;black&#039;, label=&#039;Donn√©es&#039;)
plt.scatter(X_test, preds_no_std, color=&#039;red&#039;, label=&#039;Sans standardisation&#039;)
plt.scatter(X_test, preds_std, color=&#039;blue&#039;, label=&#039;Avec standardisation&#039;)
plt.legend()
plt.title(&quot;Impact de la standardisation sur la pr√©diction finale&quot;)
plt.xlabel(&quot;x&quot;)
plt.ylabel(&quot;y&quot;)
plt.show()</code></pre>
</div><div class="slide ">
<a id="title.1.6.7"></a><h3>5.7. Analyse des r√©sultats de l&#039;exemple de r√©gression</h3>
<p>Les sorties attendues sont \(y_true = [1, 121]\).</p>
<ul><li class="dash"><strong>Sans standardisation</strong> :
  Pr√©dictions finales \(\approx [1.0, 60.98]\) ‚Üí Le mod√®le pr√©dit correctement pour \(x=0\) mais extrapole mal pour \(x=60\).  Cela montre que l‚Äô√©chelle des donn√©es peut d√©s√©quilibrer la descente de gradient.</li>
<li class="dash"><strong>Avec standardisation</strong> :
  Pr√©dictions finales \(\approx [0.99999, 120.99]\) ‚Üí Le mod√®le pr√©dit presque parfaitement la relation lin√©aire. La standardisation permet de centrer et r√©duire les donn√©es, √©quilibrant les gradients et acc√©l√©rant la convergence.</li>
</ul>

<p>üí° <strong>Conclusion</strong> :</p>
<ul><li class="dash">La standardisation rend le mod√®le plus stable et fiable pour des valeurs en dehors de l‚Äô√©chelle d‚Äôentra√Ænement.</li>
<li class="dash">M√™me pour un r√©seau simple, ne pas standardiser peut provoquer des extrapolations incorrectes, alors que la standardisation corrige ce probl√®me.</li>
<li class="dash">De plus, si les donn√©es d&#039;entr√©e sont bruit√©es, ne pas standardiser peut d√©grader encore plus les performances du mod√®le. Pour le tester, il suffit de d√©commenter la ligne <code>y = 2*X + 1 + torch.randn_like(X)*5</code> et relancer l&#039;entra√Ænement.</li>
</ul>

</div><div class="slide ">
<a id="title.1.7"></a><h2>üìñ 6. Broadcasting</h2>
<a id="title.1.7.1"></a><h3>6.1 Qu&#039;est-ce que le broadcasting ?</h3>
<p>Le broadcasting est un m√©canisme qui permet √† PyTorch de faire des op√©rations entre tenseurs de dimensions diff√©rentes sans avoir √† √©crire de boucles. C&#039;est comme cela qu&#039;est fait l&#039;op√©ration de centrage des donn√©es (soustraction de la moyenne) dans la standardisation des donn√©es.</p>
<p>üí° Id√©e principale :</p>
<ul><li class="dash">Si les dimensions des tenseurs sont compatibles, PyTorch r√©plique automatiquement le tenseur de plus petite dimension pour correspondre √† la taille du tenseur le plus grand.</li>
<li class="dash">Cela permet de vectoriser les calculs et de rendre le code plus simple et rapide.</li>
</ul>

</div><div class="slide ">
<a id="title.1.7.2"></a><h3>6.2 Exemple de broadcasting pour centrer des donn√©es</h3>
<pre><code class="python hljs">import torch

# Matrice 3x2
X = torch.tensor([[1., 2.],
                  [3., 4.],
                  [5., 6.]])

# Moyenne de chaque colonne
mean = X.mean(dim=0)  # dimension (2,)

# On soustrait la moyenne √† chaque ligne
X_centered = X - mean  # broadcasting

print(&quot;X centr√© :&quot;, X_centered)</code></pre>
<p>üí° Conclusion : M√™me si <code>mean</code> est un vecteur (dimension 2), PyTorch l‚Äôapplique √† toutes les lignes de <code>X</code>. Le tenseur <code>mean</code> est automatiquement ‚Äú√©tendu‚Äù pour correspondre √† <code>X</code>.  </p>
<p>‚úÖ R√©sultat : On peut centrer toutes les lignes d‚Äôun coup, sans boucle.</p>
</div><div class="slide ">
<a id="title.1.8"></a><h2>üìñ 7. Observer la loss et d√©terminer le nombre d‚Äôepochs</h2>
<p>Lorsqu‚Äôon entra√Æne un mod√®le, il est essentiel de suivre l‚Äô√©volution de la loss pour savoir si le mod√®le apprend correctement et converge vers une solution. Dans l‚Äôexemple pr√©c√©dent, nous avons compar√© l‚Äôimpact de la standardisation sur les pr√©dictions finales. Nous allons maintenant observer l‚Äô√©volution de la loss pendant l‚Äôentra√Ænement pour mieux comprendre la convergence et d√©terminer un nombre d‚Äôepochs appropri√©. Nous allons continuer √† utiliser les donn√©es suivantes pour entra√Æner le mod√®le :</p>
<pre><code class="python hljs"># Donn√©es d&#039;entra√Ænement
X = torch.tensor([[0.],[10.],[20.],[30.],[40.],[50.]])
y = 2*X + 1</code></pre>
<a id="title.1.8.1"></a><h3>7.1. Suivi de la loss</h3>
<p>Pour suivre la loss pour le mod√®le avec et sans standardisation il faut d&#039;abord cr√©er deux listes pour stocker les valeurs de la loss √† chaque epoch. Pour cela, il suffit d&#039;ajouter le code suivant avant la classe de cr√©ation du mod√®le : </p>
<pre><code class="python hljs">...

# Listes pour stocker l&#039;√©volution de la loss
losses_no_std = []
losses_std = []

...</code></pre>
</div><div class="slide ">
<p>Ensuite, pendant l‚Äôentra√Ænement, on ajoute la valeur de la loss √† dans les listes pour chaque epoch. Cela ce fait comme suit : </p>
<pre><code class="python hljs">...

# Sans standardisation
pred_no_std = model_no_std(X)

...

optimizer_no_std.step()
losses_no_std.append(loss_no_std.item()) # Ligne √† ajouter

# Avec standardisation
pred_std = model_std(X_stdized)

...

optimizer_std.step()
losses_std.append(loss_std.item()) # Ligne √† ajouter

...</code></pre>
</div><div class="slide ">
<p>Enfin on ajoute les lignes de code suivante pour tracer les loss √† la fin du code : </p>
<pre><code class="python hljs">...

# Visualisation de la loss
plt.plot(losses_no_std, label=&#039;Sans standardisation&#039;)
plt.plot(losses_std, label=&#039;Avec standardisation&#039;)
plt.xlabel(&#039;Epoch&#039;)
plt.ylabel(&#039;Loss MSE&#039;)
plt.title(&quot;√âvolution de la loss pendant l&#039;entra√Ænement&quot;)
plt.legend()
plt.show()</code></pre>
</div><div class="slide ">
<a id="title.1.8.2"></a><h3>7.2. Interpr√©tation du r√©sultat</h3>
<ul><li class="dash"><strong>Convergence</strong> :</li>
<ul><li class="dash">Si la loss diminue et se stabilise autour d‚Äôune valeur faible, le mod√®le converge.</li>
<li class="dash">Si la loss reste tr√®s √©lev√©e ou diverge, le mod√®le ne converge pas correctement.</li>
</ul>
<li class="dash"><strong>Choix du nombre d‚Äôepochs</strong> :</li>
<ul><li class="dash">En regardant le graphique, on peut d√©terminer √† partir de quel epoch la loss se stabilise.</li>
<li class="dash">Cela permet de choisir un nombre d‚Äôepochs suffisant sans sur-entra√Æner le mod√®le inutilement.</li>
<li class="dash">Dans cet exemple, on d√©couvre que pour le mod√®le qui s&#039;entra√Æne avec standardisation, la loss se stabilise √† 0 autour de 500 epochs. Vous pouvez r√©duire le nombre d&#039;epochs et v√©rifier que 500 epochs suffisent.</li>
</ul>
</ul>

<div class="alert alert-info"><p><strong>Remarque</strong> : Si vous relancer l&#039;entra√Ænement, le graphique de la loss peut varier √† cause de l&#039;initialisation al√©atoire des poids sauf si vous utilisez un <code>seed</code> fixe.</p>
</div>
</div><div class="slide ">
<a id="title.1.8.3"></a><h3>7.3. Early Stopping</h3>
<p>Pour √©viter de trop entra√Æner le mod√®le, on peut surveiller la loss et arr√™ter l‚Äôentra√Ænement lorsque la perte ne diminue plus. Cela s‚Äôappelle l‚Äôearly stopping. On peut automatiser le processus avec PyTorch. Tout d&#039;abord, il faut remmetre le nombre d&#039;epoch √† 5000. Ensuite il faut cr√©er les variables suivantes et les ajouter avant la classe qui construit le mod√®le :</p>
<pre><code class="python hljs">...

# Param√®tres pour l&#039;early stopping
patience = 50       # nombre d&#039;epochs sans am√©lioration avant arr√™t
best_loss_std = float(&#039;inf&#039;) # meilleure loss observ√©e pour le mod√®le avec standardisation (initialis√©e √† l&#039;infini pour que la premi√®re am√©lioration soit toujours accept√©e)
counter_std = 0 # compteur d&#039;epochs sans am√©lioration

patience_no_std = 50
best_loss_no_std = float(&#039;inf&#039;)    
counter_no_std = 0

...</code></pre>
</div><div class="slide ">
<p>Ensuite, il faut ajouter le code suivant √† la fin de chaque boucle d&#039;entra√Ænement pour v√©rifier si la loss s&#039;est am√©lior√©e ou non. Si elle ne s&#039;am√©liore pas pendant un certain nombre d&#039;epochs (d√©fini par <code>patience</code>), l&#039;entra√Ænement s&#039;arr√™te automatiquement. Voici le code √† ajouter :</p>
<pre><code class="python hljs">...

# Sans standardisation

...


losses_no_std.append(loss_no_std.item())

# Early stopping pour le mod√®le sans standardisation (code √† ajouter)
if loss_no_std.item() &lt; best_loss_no_std:
    best_loss_no_std = loss_no_std.item()
    counter_no_std = 0
else:
    counter_no_std += 1
if counter_no_std &gt;= patience_no_std:
    print(f&quot;Arr√™t anticip√© (sans std) √† l&#039;epoch {epoch}, loss = {best_loss_no_std:.4f}&quot;)
    break

# Avec standardisation

...

losses_std.append(loss_std.item())

# Early stopping pour le mod√®le standardis√© (code √† ajouter)
if loss_std.item() &lt; best_loss_std:
    best_loss_std = loss_std.item()
    counter_std = 0
else:
    counter_std += 1
if counter_std &gt;= patience:
    print(f&quot;Arr√™t anticip√© (avec std) √† l&#039;epoch {epoch}, loss = {best_loss_std:.4f}&quot;)
    break

...</code></pre>
</div><div class="slide ">
<p>üí° <strong>Remarque</strong> :  </p>
<ul><li class="dash">Cette m√©thode simple permet de d√©terminer un nombre d‚Äôepochs appropri√© automatiquement.</li>
<li class="dash">Pour cet exemple, le mod√®le sans standardisation des donn√©es ne converge jamais avec une loss \(\approx 0\) tandis que le mod√®le avec standardisation des donn√©es converge √† partir d&#039;environ 200 epochs.</li>
<li class="dash">Dans la pratique, on combine souvent early stopping avec un jeu de validation pour √©viter le surapprentissage.</li>
</ul>

</div><div class="slide ">
<a id="title.1.8.4"></a><h3>üìñ 8. Observer le mod√®le avec <code>torch-summary</code> et la performance des gradients avec autograd profiler</h3>
<p>Il existe plusieurs outils PyTorch qui permettent d&#039;inspecter et de profiler les mod√®les. Le but √©tant de parvenir √† identifier les goulots d&#039;√©tranglement et √† optimiser les performances. Parmi eux, on trouve :</p>
<ul><li class="dash"><code>torchsummary</code> : pour visualiser la structure du mod√®le et le nombre de param√®tres par couche.</li>
<li class="dash"><code>torch.autograd.profiler</code> : pour profiler le calcul des gradients et identifier les op√©rations co√ªteuses.</li>
</ul>

<a id="title.1.8.5"></a><h3>8.1. Utiliser <code>torchsummary</code></h3>
<p><code>torchsummary</code> permet de visualiser la structure du mod√®le et le nombre de param√®tres par couche avant l&#039;entra√Ænement. Pour l&#039;utiliser, il faut d&#039;abord l&#039;installer :</p>
<pre><code class="bash hljs">pip install torch-summary</code></pre>
<p>Ensuite, juste apr√®s la d√©finition de votre mod√®le, vous pouvez faire un r√©sum√© du mod√®le :</p>
<pre><code class="python hljs">from torchsummary import summary

# Mod√®le standardis√© d√©fini pr√©c√©demment
# Cr√©er une copie sur CPU pour torchsummary
model_std_cpu = MLP().to(&quot;cpu&quot;)

# R√©sum√© du mod√®le
# input_size correspond aux dimensions d&#039;un √©chantillon (hors batch)
# Ici, chaque √©chantillon a 1 feature (scalaire)
summary(model_std_cpu, input_size=(1,), device=&quot;cpu&quot;)</code></pre>
</div><div class="slide ">
<p>Explications¬†:</p>
<ul><li class="dash"><code>input_size</code> : dimensions d‚Äôun √©chantillon (hors batch).
  Dans notre exemple, chaque √©chantillon est un scalaire (1 feature), donc <code>input_size=(1,)</code>.  </li>
<li class="dash"><code>device</code> : ici &quot;cpu&quot; pour √©viter tout conflit CUDA si le mod√®le ou PyTorch envoie certains tenseurs sur GPU.</li>
<li class="dash">R√©sultat¬†: pour chaque couche, on voit :</li>
<ul><li class="dash">le type de couche (Linear, ReLU‚Ä¶)</li>
<li class="dash">la taille des tenseurs interm√©diaires</li>
<li class="dash">le nombre de param√®tres</li>
<li class="dash">le nombre de param√®tres entra√Ænables</li>
</ul>
</ul>

</div><div class="slide ">
<a id="title.1.8.6"></a><h3>8.2. R√¥le du profiler</h3>
<p>Pour encore plus am√©liorer la performance de votre mod√®le, PyTorch fournit <code>torch.autograd.profiler.profile</code> pour profiler le calcul des gradients ce qui permet de :</p>
<ul><li class="dash">Mesurer le temps et la m√©moire consomm√©s par chaque op√©ration.</li>
<li class="dash">Identifier les goulots d&#039;√©tranglement dans le r√©seau.</li>
<li class="dash">Optimiser et d√©bugger les mod√®les complexes.</li>
</ul>

</div><div class="slide ">
<a id="title.1.8.7"></a><h3>8.3. Exemple d&#039;utilisation du profiler pour l&#039;exemple de r√©gression</h3>
<p>Pour tester le profiler, il suffit d&#039;ajouter le code suivant juste apr√®s le code de <code>torchsummary</code> :</p>
<pre><code class="python hljs">...

# torch.autograd.profiler est utilis√© dans ce chapitre pour la simplicit√©
# Pour des usages avanc√©s (timeline, TensorBoard), on peut utiliser torch.profiler
import torch.autograd.profiler as profiler

# Faire un profiling sur une seule passe avant la boucle d&#039;entra√Ænement
with profiler.profile(use_cuda=True, profile_memory=True) as prof_dummy:
    # Forward + backward sur le mod√®le standardis√©
    pred_std = model_std(X_stdized)
    loss_std = ((pred_std - y)**2).mean()
    optimizer_std.zero_grad()
    loss_std.backward()

# Afficher le profil CPU (temps d&#039;ex√©cution)
print(&quot;Profil CPU pour le mod√®le standardis√© (une seule passe avant entra√Ænement) :&quot;)
print(prof_dummy.key_averages().table(sort_by=&quot;cpu_time_total&quot;))

# Afficher le profil GPU (m√©moire consomm√©e)
print(prof_dummy.key_averages().table(sort_by=&quot;self_cuda_memory_usage&quot;, row_limit=10))

...</code></pre>
</div><div class="slide ">
<p><strong>Conclusion</strong> : </p>
<ul><li class="dash">On peut profiler √† la fois le <strong>temps CPU</strong> et la <strong>m√©moire GPU</strong>.</li>
<li class="dash">On utilise :</li>
<ul><li class="dash"><code>cpu_time_total</code> pour identifier les op√©rations co√ªteuses en calcul,</li>
<li class="dash"><code>self_cuda_memory_usage</code> pour rep√©rer celles qui consomment le plus de m√©moire GPU.</li>
</ul>
<li class="dash">Le profiler ralentit fortement l&#039;ex√©cution : il ne doit pas √™tre utilis√© pendant tout l‚Äôentra√Ænement, mais seulement ponctuellement pour analyser ou optimiser.</li>
<li class="dash">Chaque op√©ration ex√©cut√©e sur le CPU par PyTorch y est list√©e avec :</li>
<ul><li class="dash"><code>Self CPU %</code> : temps pass√© directement dans l‚Äôop√©ration.</li>
<li class="dash"><code>CPU total %</code> : temps total incluant les sous-op√©rations.</li>
<li class="dash"><code># of Calls</code> : nombre d‚Äôappels √† l‚Äôop√©ration.</li>
</ul>
<li class="dash">Chaque op√©ration ex√©cut√©e sur le GPU par PyTorch y est list√©e avec :</li>
<ul><li class="dash"><code>Self CUDA Memory Usage</code> : m√©moire GPU utilis√©e directement par l‚Äôop√©ration.</li>
<li class="dash"><code>CUDA Memory Usage</code> : m√©moire totale incluant les sous-op√©rations.</li>
<li class="dash"><code># of Calls</code> : nombre d‚Äôappels √† l‚Äôop√©ration.</li>
</ul>
<li class="dash">Les <strong>couches lin√©aires</strong> (<code>aten::linear</code>) prennent la majeure partie du temps : multiplication matricielle + bias.</li>
<li class="dash">Les <strong>activations</strong> (<code>ReLU</code>, <code>Tanh</code>) et les calculs de <strong>loss</strong> (<code>mean</code>, <code>pow</code>) consomment moins de temps mais sont n√©cessaires pour propager les gradients.</li>
<li class="dash">Les op√©rations comme <code>detach</code> ou <code>clone</code> apparaissent lorsqu‚Äôon fait des copies ou qu‚Äôon d√©tache un tenseur du graphe pour ne pas calculer de gradient dessus.</li>
<li class="dash">Ce profilage permet de <strong>visualiser les goulots d‚Äô√©tranglement</strong> et d‚Äôoptimiser l‚Äôentra√Ænement si n√©cessaire.</li>
<li class="dash">Pour un petit MLP, le plus co√ªteux est le calcul des couches lin√©aires et du backward. Sur des mod√®les plus grands ou avec GPU, ces informations sont cruciales pour comprendre et am√©liorer les performances.</li>
</ul>

<a id="title.1.9"></a><h2>üìñ 8. Inspecter le mod√®le avec <code>torch-summary</code></h2>
<p>Un dernier outil PyTorch dont nous allons parler dans ce chapitre est appel√© <code>torch-summary</code> et permet de visualiser la structure du mod√®le et le nombre de param√®tres par couche. Pour cela, il suffit de taper le code suivant : </p>
<p>Permet de voir le nombre de param√®tres par couche et la structure du r√©seau.  </p>
<pre><code class="python hljs">from torchsummary import summary
summary(model, input_size=(1,))</code></pre>
</div><div class="slide ">
<a id="title.1.10"></a><h2>üèãÔ∏è Travaux Pratiques 2</h2>
<div class="toc"><ul><li><a href="TP_chap2.html#title.1">üèãÔ∏è Travaux Pratiques 2</a></li><ul><li><a href="TP_chap2.html#title.1.1">üçÄ Exercice 1 : Approximations d‚Äôune fonction non lin√©aire</a></li><li><a href="TP_chap2.html#title.1.2">‚öñÔ∏è Exercice 2 : Comparaison de l&#039;entra√Ænement d&#039;un MLP sur donn√©es brutes et standardis√©es</a></li></ul><li><a href="TP_chap2.html#title.2">üèãÔ∏è Exercices suppl√©mentaires 2</a></li><ul><li><a href="TP_chap2.html#title.2.1">‚öñÔ∏è Exercice suppl√©mentaire 1 : Approximation d&#039;une fonction 2D avec un MLP </a></li></ul></ul></div>
</div>
<nav><ul class="pagination justify-content-center"><li class="page-item"><a class="page-link" href="chap1.html">&larr; Chapitre 1 - Introduction √† PyTorch et Optimisation de Mod√®les</a></li><li class="page-item"><a class="page-link" href="index.html"><i class="bi bi-folder2"></i> Introduction aux fondamentaux de l&#039;apprentissage supervis√© et du Deep Learning</a></li></ul></nav>

</div> <!-- /contents -->
</div> <!-- /core -->

</body>
</html>
