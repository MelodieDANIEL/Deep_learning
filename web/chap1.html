<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8" />
<link rel="stylesheet" type="text/css" href="css/style.css" />
<title>Intro Python - Chapitre 1 - Introduction √† PyTorch et Optimisation de Mod√®les</title>

                <meta http-equiv="X-UA-Compatible" content="IE=edge">
                <meta name="viewport" content="viewport-fit=cover, width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
            

                <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
                <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
            
<link href="https://fonts.googleapis.com/css2?family=Gentium+Basic&display=swap" rel="stylesheet"> 
<link rel="stylesheet" type="text/css" href="slidey/bootstrap/css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" href="slidey/bootstrap-icons/font/bootstrap-icons.css" />
<link rel="stylesheet" type="text/css" href="slidey/highlight.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.menu.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.step.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.code.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.slide.css" />
<script type="text/javascript" src="slidey/js/jquery.js"></script>
<script type="text/javascript" src="slidey/js/slidey.permalink.js"></script>
<script type="text/javascript" src="slidey/js/slidey.menu.js"></script>
<script type="text/javascript" src="slidey/js/slidey.mobile.js"></script>
<script type="text/javascript" src="slidey/js/slidey.spoilers.js"></script>
<script type="text/javascript" src="slidey/js/slidey.steps.js"></script>
<script type="text/javascript" src="slidey/js/slidey.js"></script>
<script type="text/javascript" src="slidey/js/main.js"></script>
<script type="text/javascript" src="slidey/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="slidey/highlight/highlight.pack.js"></script>
<link rel="icon" type="image/x-icon" href="favicon.ico" />
</head>
<body>
<!-- Modal log-in window -->
<div class="modal fade" id="loginWindow">
  <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
            <h5 class="modal-title">Log-in</h5>
            <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
          </div>    
        <div class="modal-body">
            <form>
                Mot de passe&nbsp;:<br />
                <input class="form-control" type="password" name="password" />
            </form>
        </div>
      </div><!-- /.modal-content -->
    </div><!-- /.modal-dialog -->
</div>

<div class="core">

    <script>hljs.highlightAll();</script>

<!-- Extra-controls for mobile device -->
<div class="mobileControls">
    <div class="btn-group">
        <a href="javascript:void(0)" class="left btn btn-light btn-lg">
            <i class="bi bi-arrow-up"></i>
        </a>
        <a href="javascript:void(0)" class="right btn btn-light btn-lg">
            <i class="bi bi-arrow-down"></i>
        </a>
        <a href="javascript:void(0)" class="up btn btn-light btn-lg">
            <i class="bi bi-arrow-left"></i>
        </a>
        <a href="javascript:void(0)" class="down btn btn-light btn-lg">
            <i class="bi bi-arrow-right"></i>
        </a>
        <a href="javascript:void(0)" class="login btn btn-light btn-lg">
            <i class="bi bi-lock"></i>
        </a>
    </div>
</div>

<!-- Controls -->
<div class="slideMode">
    <div class="btn-group">
        <a href="javascript:void(0)" class="btn btn-light btn-lg slideModeSlide"><i class="bi bi-film"></i></a>
        <a href="javascript:void(0)" class="btn btn-light btn-lg followMode"><i class="bi bi-stopwatch"></i> </a>
        <a href="index.html" class="btn btn-light btn-lg goHome"><i class="bi bi-house"></i></a>
    </div>
</div>

<div class="exitSlideMode">
    <div class="btn-group">
        <a href="javascript:void(0)" class="btn btn-light btn-lg followMode"><i class="bi bi-stopwatch"></i></a>
        <a href="javascript:void(0)" class="btn btn-light btn-lg showMobile"><i class="bi bi-phone"></i></a>
        <a href="javascript:void(0)" class="btn btn-light btn-lg stopShow">
            <span class="currentSlideNumber">
            </span>
            <i class="bi bi-x-lg"></i>
        </a>
    </div>
</div>

<!-- Browsing menu -->
<div class="menu">
</div>

<div class="contents container">

<div class="slide ">
<a id="title.1"></a><h1>Chapitre 1 - Introduction √† PyTorch et Optimisation de Mod√®les</h1>
<a id="title.1.1"></a><h2>üéØ Objectifs du Chapitre</h2>
<div class="alert alert-light p-2 fs-5 text-center"><p>√Ä la fin de ce chapitre, vous saurez : </p>
<ul><li class="dash">Cr√©er et manipuler des tenseurs PyTorch sur CPU et GPU.</li>
<li class="dash">Calculer automatiquement les gradients √† l‚Äôaide de <code>autograd</code>.</li>
<li class="dash">D√©finir une fonction de perte.</li>
<li class="dash">Utiliser un optimiseur pour ajuster les param√®tres d‚Äôun mod√®le.</li>
<li class="dash">Impl√©menter une boucle d&#039;entra√Ænement simple.</li>
</ul>

</div>
</div><div class="slide ">
<a id="title.1.2"></a><h2>üìñ 1. Qu&#039;est-ce que PyTorch ? </h2>
<p>PyTorch est une biblioth√®que Python de machine learning open-source d√©velopp√©e par Facebook (FAIR). Elle est con√ßue pour faciliter la cr√©ation et l&#039;entra√Ænement de mod√®les, en particulier dans le domaine du deep learning. </p>
<p>Elle repose principalement sur deux √©l√©ments :</p>
<p>A) Les <em>tenseurs</em>, des structures de donn√©es similaires aux tableaux NumPy (<code>ndarray</code>), mais avec des fonctionnalit√©s suppl√©mentaires pour :</p>
<ul><li class="dash">le calcul diff√©rentiel automatique,</li>
<li class="dash">l&#039;acc√©l√©ration GPU,</li>
<li class="dash">l‚Äôentra√Ænement de r√©seaux de neurones.</li>
</ul>

<p>B) Le module <code>autograd</code> permet de calculer automatiquement les gradients n√©cessaires √† l&#039;entra√Ænement des mod√®les, en suivant toutes les op√©rations effectu√©es sur les tenseurs.</p>
</div><div class="slide ">
<p>D&#039;autres biblioth√®ques Python similaires existent, comme :</p>
<ul><li class="dash">TensorFlow : d√©velopp√© par Google, tr√®s utilis√© pour des d√©ploiements √† grande √©chelle.</li>
<li class="dash">Keras : interface haut niveau de TensorFlow, plus simple mais moins flexible.</li>
<li class="dash">JAX : plus r√©cent, optimis√© pour la recherche et les calculs scientifiques √† haute performance.</li>
</ul>

</div><div class="slide ">
<p>Dans le cadre de ce cours, nous utiliserons PyTorch car :</p>
<ul><li class="dash">elle est largement adopt√©e par la communaut√© de la recherche en deep learning,</li>
<li class="dash">elle est plus lisible et plus facile √† d√©boguer que TensorFlow et JAX,</li>
<li class="dash">elle offre plus de possibilit√©s que Keras,</li>
<li class="dash">elle est bien document√©e et est l&#039;une des biblioth√®ques les plus utilis√©es en science des donn√©es (Data Science en anglais) et en apprentissage machine (Machine Learning en anglais).</li>
</ul>

</div><div class="slide ">
<a id="title.1.3"></a><h2>üìñ 2. Qu&#039;est-ce qu&#039;un tenseur ?</h2>
<p>Les <strong>tenseurs</strong> sont la structure de base de PyTorch. Ce sont des tableaux multidimensionnels similaires aux <code>ndarray</code> de NumPy, mais avec des fonctionnalit√©s suppl√©mentaires pour le GPU et le calcul automatique des gradients. Un tenseur est une structure de donn√©es qui g√©n√©ralise les matrices √† un nombre quelconque de dimensions:</p>
<ul><li class="dash">Un scalaire est un tenseur 0D.</li>
<li class="dash">Un vecteur est un tenseur 1D.</li>
<li class="dash">Une matrice est un tenseur 2D.</li>
<li class="dash">On peut avoir des tenseurs 3D, 4D, etc.</li>
</ul>

<p>Les tenseurs √† haute dimension sont tr√®s utilis√©s en deep learning (par exemple pour les images ou les vid√©os). Nous allons voir comment cr√©er et manipuler des tenseurs dans PyTorch. Vous pouvez copier-coller les exemples de code ci-dessous dans un notebook Jupyter pour les tester et voir les affichages. Pour utiliserles fonctions de PyTorch, il faut d&#039;abord l&#039;importer :</p>
<pre><code class="python hljs">import torch</code></pre>
</div><div class="slide ">
<a id="title.1.4"></a><h2>üìñ 3. Cr√©ation de tenseurs</h2>
<p>Il existe plusieurs mani√®res de cr√©er un tenseur en PyTorch.</p>
<a id="title.1.4.1"></a><h3>3.1. √Ä partir de donn√©es Python (listes ou tuples)</h3>
<pre><code class="python hljs"># Depuis une liste
a = torch.tensor([1, 2, 3])
print(a)

# Depuis une liste de listes (matrice)
b = torch.tensor([[1, 2, 3], [4, 5, 6]])
print(b)

# On peut aussi sp√©cifier le type de donn√©es
c = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)
print(c, c.dtype)</code></pre>
</div><div class="slide ">
<a id="title.1.4.2"></a><h3>3.2. Avec des fonctions de construction</h3>
<pre><code class="python hljs"># Tenseur rempli de z√©ros
z = torch.zeros(2, 3)
print(z)

# Tenseur rempli de uns
o = torch.ones(2, 3)
print(o)

# Tenseur vide (valeurs non initialis√©es)
e = torch.empty(2, 3)
print(e)

# Identit√© (matrice diagonale)
eye = torch.eye(3)
print(eye)</code></pre>
</div><div class="slide ">
<a id="title.1.4.3"></a><h3>3.3. Avec des suites r√©guli√®res</h3>
<p>PyTorch permet de g√©n√©rer facilement des suites de nombres avec des pas r√©guliers. Deux fonctions sont particuli√®rement utiles :</p>
<ol><li class=""><strong>torch.arange(debut, fin, pas)</strong></li>
<ul><li class="dash">Cr√©e une suite en commen√ßant √† <code>debut</code></li>
<li class="dash">S‚Äôarr√™te avant <code>fin</code> (attention, la borne sup√©rieure est exclue !)</li>
<li class="dash">Utilise le <code>pas</code> indiqu√©</li>
</ul>
</ol>

<pre><code class="python hljs"># De 0 √† 8 inclus, avec un pas de 2
r = torch.arange(0, 10, 2)
print(&quot;torch.arange(0, 10, 2) :&quot;, r)

# De 5 √† 20 exclu, avec un pas de 3
r2 = torch.arange(5, 20, 3)
print(&quot;torch.arange(5, 20, 3) :&quot;, r2)

# ‚ö†Ô∏è Remarque : la borne sup√©rieure (ici 10 ou 20) n&#039;est jamais incluse</code></pre>
</div><div class="slide ">
<ol><li class=""><strong>torch.linspace(debut, fin, steps)</strong></li>
<ul><li class="dash">Cr√©e une suite de <code>steps</code> valeurs r√©guli√®rement espac√©es</li>
<li class="dash">Inclut <strong>√† la fois</strong> <code>debut</code> et <code>fin</code></li>
</ul>
</ol>

<pre><code class="python hljs"># 5 valeurs entre 0 et 1 inclus
l = torch.linspace(0, 1, steps=5)
print(&quot;torch.linspace(0, 1, steps=5) :&quot;, l)

# 4 valeurs entre -1 et 1 inclus
l2 = torch.linspace(-1, 1, steps=4)
print(&quot;torch.linspace(-1, 1, steps=4) :&quot;, l2)</code></pre>
<p><strong>R√©sum√© des diff√©rences</strong></p>
<ul><li class="dash"><code>arange</code> ‚Üí on fixe le <strong>pas</strong> entre les valeurs, la fin est exclue.</li>
<li class="dash"><code>linspace</code> ‚Üí on fixe le <strong>nombre de valeurs</strong>, la fin est incluse.</li>
</ul>

<p>Exemple comparatif :</p>
<pre><code class="python hljs">print(torch.arange(0, 1, 0.25))   # [0.00, 0.25, 0.50, 0.75]
print(torch.linspace(0, 1, 5))    # [0.00, 0.25, 0.50, 0.75, 1.00]</code></pre>
</div><div class="slide ">
<a id="title.1.4.4"></a><h3>3.4. Avec des nombres al√©atoires</h3>
<pre><code class="python hljs"># Attention dans les exemples suivants, les crochets [] veulent dire que la valeur de la borne est incluse, contrairement √† aux parenth√®ses () qui signifient que la borne est exclue.
# Uniforme entre [0, 1)
u = torch.rand(2, 2)
print(&quot;Uniforme [0,1) :\n&quot;, u)

# Distribution normale (moyenne=0, √©cart-type=1)
n = torch.randn(2, 2)
print(&quot;Normale standard (0,1) :\n&quot;, n)

# Distribution normale avec moyenne (mean) et √©cart-type (std) choisis
custom = torch.normal(mean=2.0, std=3.0, size=(2,2))
print(&quot;Normale (moyenne=10, √©cart-type=2) :\n&quot;, custom)

# Fixer la graine pour la reproductibilit√©
torch.manual_seed(42)
print(&quot;Reproductibilit√© :\n&quot;, torch.rand(2, 2))  # toujours le m√™me r√©sultat</code></pre>
</div><div class="slide ">
<a id="title.1.5"></a><h2>üìñ 4. Conna√Ætre la forme d&#039;un tenseur</h2>
<p>Un tenseur peut avoir n‚Äôimporte quelle dimension. La m√©thode <code>.shape</code> permet de conna√Ætre sa taille.</p>
<pre><code class="python hljs"># Scalaire (0D)
s = torch.tensor(5)
print(&quot;Scalaire :&quot;, s, &quot;shape =&quot;, s.shape)

# Vecteur (1D)
v = torch.tensor([1, 2, 3, 4])
print(&quot;Vecteur :&quot;, v, &quot;shape =&quot;, v.shape)

# Matrice (2D)
m = torch.tensor([[1, 2, 3], [4, 5, 6]])
print(&quot;Matrice :\n&quot;, m, &quot;shape =&quot;, m.shape)

# Tenseur 3D (par exemple, 2 matrices de taille 3x3)
t3 = torch.zeros(2, 3, 3)
print(&quot;Tenseur 3D shape =&quot;, t3.shape)

# Tenseur 4D (par exemple, un mini-batch de 10 images RGB de 32x32)
t4 = torch.zeros(10, 3, 32, 32)
print(&quot;Tenseur 4D shape =&quot;, t4.shape)</code></pre>
</div><div class="slide ">
<a id="title.1.6"></a><h2>üìñ 5. Types de tenseurs et conversion</h2>
<ul><li class="dash">Vous pouvez sp√©cifier le type de donn√©es (<code>dtype</code>) lors de la cr√©ation :</li>
</ul>

<pre><code class="python hljs">x = torch.tensor([1.2, 3.4, 5.6])
print(x.dtype)     # float32 par d√©faut

x_int = x.to(torch.int32)
print(x_int, x_int.dtype)

x_float64 = x.double()
print(x_float64, x_float64.dtype)</code></pre>
<ul><li class="dash">Conversion d‚Äôun tenseur existant :</li>
</ul>

<pre><code class="python hljs">x_int = x.to(torch.int32)
print(x_int.dtype)</code></pre>
</div><div class="slide ">
<a id="title.1.7"></a><h2>üìñ 6. Op√©rations de base</h2>
<p>PyTorch supporte de nombreuses op√©rations sur les tenseurs :</p>
<pre><code class="python hljs">a = torch.tensor([1, 2, 3])
b = torch.tensor([4, 5, 6])

# Addition
print(a + b)

# Multiplication √©l√©ment par √©l√©ment
print(a * b)

# Produit matriciel
mat1 = torch.rand(2, 3)
mat2 = torch.rand(3, 4)
print(torch.mm(mat1, mat2))</code></pre>
</div><div class="slide ">
<a id="title.1.8"></a><h2>üìñ 7. Tenseurs sur GPU</h2>
<p>Pour profiter de l‚Äôacc√©l√©ration GPU, il suffit de d√©placer un tenseur sur le device CUDA :</p>
<pre><code class="python hljs">if torch.cuda.is_available():
    device = torch.device(&quot;cuda&quot;)
    x_gpu = x.to(device)
    print(&quot;Tenseur sur GPU :&quot;, x_gpu)
else:
    print(&quot;Pas de GPU disponible, utilisation du CPU.&quot;)</code></pre>
</div><div class="slide ">
<a id="title.1.9"></a><h2>üìñ 8.  Manipulation avanc√©e des tenseurs</h2>
<p>Une fois cr√©√©s, les tenseurs peuvent √™tre transform√©s et r√©arrang√©s. PyTorch fournit de nombreuses fonctions pour modifier leur forme, leurs dimensions ou leur ordre.</p>
<a id="title.1.9.1"></a><h3>8.1. Changer la forme avec <code>view</code> et <code>reshape</code></h3>
<ul><li class="dash"><code>view</code> : retourne un nouveau tenseur qui partage la m√™me m√©moire que l‚Äôoriginal. Cela implique que le tenseur soit contigu. Un tenseur est dit contigu lorsque ses donn√©es sont stock√©es de mani√®re cons√©cutive en m√©moire, c‚Äôest-√†-dire que PyTorch peut lire tous les √©l√©ments dans l‚Äôordre sans sauts.
Certaines op√©rations, comme la transposition (<code>t()</code>), rendent le tenseur non contigu, et dans ce cas <code>view</code> √©choue.</li>
<li class="dash"><code>reshape</code> : similaire √† <code>view</code>, mais plus flexible car il tente d‚Äôutiliser la m√©moire existante, mais cr√©e une copie si n√©cessaire. <code>reshape</code> fonctionne dans tous les cas de figures.</li>
</ul>

<pre><code class="python hljs">x = torch.arange(12)   # tenseur 1D [0, 1, ..., 11]
print(&quot;x :&quot;, x)

# Transformer en matrice 3x4
x_view = x.view(3, 4)
print(&quot;view en 3x4 :\n&quot;, x_view)

# Transformer en matrice 2x6
x_reshape = x.reshape(2, 6)
print(&quot;reshape en 2x6 :\n&quot;, x_reshape)</code></pre>
</div><div class="slide ">
<p>Autre exemple pour illustrer la diff√©rence entre <code>view</code> et <code>reshape</code> :</p>
<pre><code class="python hljs"># Cr√©ation d&#039;un tenseur 2x3
x = torch.arange(6).view(2, 3)
print(&quot;x :\n&quot;, x)
print(&quot;Contigu :&quot;, x.is_contiguous())

# Transposition ‚Üí rend le tenseur non contigu
y = x.t()
print(&quot;\ny (transpos√©) :\n&quot;, y)
print(&quot;Contigu :&quot;, y.is_contiguous())

# view √©choue sur un tenseur non contigu
try:
    z = y.view(6)
except Exception as e:
    print(&quot;\nErreur avec view :&quot;, e)

# reshape fonctionne toujours
z2 = y.reshape(6)
print(&quot;\nreshape fonctionne :&quot;, z2)</code></pre>
</div><div class="slide ">
<a id="title.1.9.2"></a><h3>8.2. Changer l‚Äôordre des dimensions : <code>permute</code></h3>
<ul><li class="dash"><code>permute</code> r√©arrange les dimensions dans un nouvel ordre.</li>
<li class="dash">Tr√®s utile pour manipuler les donn√©es d‚Äôimages ou de s√©quences.</li>
</ul>

<pre><code class="python hljs"># Exemple avec un tenseur 3D (batch, hauteur, largeur)
t = torch.randn(2, 3, 4)  # forme (2, 3, 4)
print(&quot;Tenseur original :&quot;, t.shape)

# Inverser l&#039;ordre (largeur, hauteur, batch)
p = t.permute(2, 1, 0)
print(&quot;Apr√®s permute :&quot;, p.shape)</code></pre>
</div><div class="slide ">
<a id="title.1.9.3"></a><h3>8.3. Ajouter ou supprimer des dimensions : <code>unsqueeze</code> et <code>squeeze</code></h3>
<ul><li class="dash"><code>unsqueeze(dim)</code> : ajoute une dimension de taille 1 √† la position <code>dim</code>.</li>
<li class="dash"><code>squeeze()</code> : supprime toutes les dimensions de taille 1.</li>
</ul>

<pre><code class="python hljs">v = torch.tensor([1, 2, 3])
print(&quot;Forme initiale :&quot;, v.shape)

v_unsq = v.unsqueeze(0)  # ajoute une dimension au d√©but
print(&quot;Apr√®s unsqueeze(0) :&quot;, v_unsq.shape)

v_sq = v_unsq.squeeze()  # supprime les dimensions de taille 1
print(&quot;Apr√®s squeeze() :&quot;, v_sq.shape)</code></pre>
</div><div class="slide ">
<a id="title.1.9.4"></a><h3>8.4. Concat√©ner ou empiler des tenseurs</h3>
<ul><li class="dash"><code>torch.cat</code> : concat√®ne le long d‚Äôune dimension existante.</li>
<li class="dash"><code>torch.stack</code> : empile en ajoutant une nouvelle dimension.</li>
</ul>

<pre><code class="python hljs">a = torch.tensor([1, 2, 3])
b = torch.tensor([4, 5, 6])

cat = torch.cat((a, b), dim=0)
print(&quot;torch.cat :&quot;, cat)

stack = torch.stack((a, b), dim=0)
print(&quot;torch.stack :&quot;, stack)
print(&quot;Forme de stack :&quot;, stack.shape)</code></pre>
</div><div class="slide ">
<a id="title.1.10"></a><h2>üìñ 9. Autograd avec PyTorch</h2>
<p>En Deep Learning, nous travaillons souvent avec des fonctions compliqu√©es d√©pendant de plusieurs variables. Pour entra√Æner un mod√®le, nous avons besoin de calculer automatiquement les d√©riv√©es de ces fonctions. C&#039;est l√† qu&#039;intervient Autograd qui est le moteur de diff√©rentiation automatique de PyTorch. </p>
<a id="title.1.10.1"></a><h3>9.1. Cr√©ation d&#039;un tenseur suivi</h3>
<p>Pour qu&#039;un tenseur suive les op√©rations et calcule les gradients automatiquement, il faut d√©finir <code>requires_grad=True</code> :</p>
<pre><code class="python hljs">x = torch.tensor([2.0, 3.0], requires_grad=True)
print(x)</code></pre>
<p>Ici, <code>x</code> est maintenant un tenseur avec suivi des gradients. Toutes les op√©rations futures sur ce tenseur seront enregistr√©es pour pouvoir calculer les d√©riv√©es automatiquement.</p>
</div><div class="slide ">
<a id="title.1.10.2"></a><h3>9.2. Op√©rations sur les tenseurs</h3>
<p>Toutes les op√©rations effectu√©es sur ce tenseur sont automatiquement enregistr√©es dans un graphe computationnel dynamique.</p>
<pre><code class="python hljs">y = x ** 2 + 3 * x # y = [y1, y2]
print(y)</code></pre>
<p>Dans ce cas :</p>
<ul><li class="dash"><code>x</code> est la variable d&#039;entr√©e.</li>
<li class="dash"><code>y</code> est calcul√© √† partir de <code>x</code> avec les op√©rations <code>x**2</code> et <code>3*x</code>.</li>
</ul>

<p>Chaque op√©ration devient un n≈ìud du graphe et PyTorch garde la trace des d√©pendances pour pouvoir calculer les gradients.</p>
</div><div class="slide ">
<a id="title.1.11"></a><h2>üìñ 10. Graphe computationnel</h2>
<p>Un graphe computationnel est une structure qui repr√©sente toutes les op√©rations effectu√©es sur les tenseurs. Chaque n≈ìud du graphe correspond √† un tenseur ou √† une op√©ration math√©matique, et les ar√™tes indiquent les d√©pendances entre eux.</p>
<a id="title.1.11.1"></a><h3>10.1. <code>torchviz</code></h3>
<p>Pour visualiser le graphe dans PyTorch, on peut utiliser <code>torchviz</code> (qu&#039;il faudra installer avec <code>pip install torchviz</code>)  :</p>
<pre><code class="python hljs">from torchviz import make_dot

z = y.sum()
make_dot(z, params={&#039;x&#039;: x})</code></pre>
<p>Cela produira une image avec des n≈ìuds pour chaque op√©ration et des fl√®ches indiquant les d√©pendances :</p>
<ul><li class="dash">Les n≈ìuds \(x^2\) et \(3x\) repr√©sentent les op√©rations effectu√©es sur \(x\).</li>
<li class="dash">Le n≈ìud \(y\) combine ces deux r√©sultats.</li>
<li class="dash">Le graphe permet √† PyTorch de savoir quelles d√©riv√©es calculer et dans quel ordre.</li>
</ul>

</div><div class="slide ">
<a id="title.1.11.2"></a><h3>10.2. Note sur le graphe g√©n√©r√© par PyTorch</h3>
<p>Quand on visualise le graphe interne avec un outil comme <code>torchviz</code> :</p>
<ul><li class="dash">Le <strong>bloc jaune avec ()</strong> correspond au tenseur final (ici <code>z</code>).</li>
<li class="dash">Les <strong>blocs interm√©diaires</strong> (<code>PowBackward0</code>, <code>AddBackward0</code>, etc.) repr√©sentent
  les op√©rations qui seront diff√©renti√©es telles que <code>PowBackward0</code> est l&#039;op√©ration op√©ration inverse associ√©e √† <code>x**2</code>, <code>MulBackward0</code> celle associ√©e √† <code>3*x</code>,<br />  <code>AddBackward0</code> combine les deux r√©sultats et repr√©sente <code>y</code> et enfin <code>SumBackward0</code> correspond au <code>y.sum()</code> qui est √©gal √† <code>z</code>.</li>
<li class="dash">Le <strong>bloc <code>AccumulateGrad</code></strong> correspond √† l‚Äôendroit o√π le gradient est stock√©
  dans la variable d‚Äôentr√©e (ici <code>x.grad</code>).</li>
</ul>

</div><div class="slide ">
<a id="title.1.12"></a><h2>üìñ 11. Calcul des gradients et r√©tropropagation </h2>
<p>Autograd utilise ce graphe pour calculer automatiquement les d√©riv√©es par rapport √† <code>x</code>, en utilisant la m√©thode <code>backward()</code> :</p>
<pre><code class="python hljs">z = y.sum()  # z = y1 + y2
z.backward()
print(x.grad)</code></pre>
<ul><li class="dash"><code>backward()</code> calcule les d√©riv√©es de <code>z</code> par rapport √† chaque √©l√©ment de <code>x</code>.</li>
<li class="dash"><code>x.grad</code> contient maintenant les gradients.</li>
</ul>

</div><div class="slide ">
<a id="title.1.12.1"></a><h3>11.1. But de la r√©tropropagation</h3>
<p>Le but est de minimiser une fonction de perte en ajustant les param√®tres du mod√®le. La r√©tropropagation permet de calculer efficacement les gradients n√©cessaires pour mettre √† jour ces param√®tres via des algorithmes d&#039;optimisation comme la descente de gradient.</p>
<p>Le gradient d‚Äôune fonction \(f(x)\) est la pente de la courbe en un point. Le gradient indique la direction de variation la plus forte de la fonction : c‚Äôest comme une boussole qui pointe vers la direction o√π la fonction cro√Æt le plus vite. Pour minimiser la perte, on avance dans la direction oppos√©e. Voici comment on calcule le gradient :</p>
<ul><li class="dash">En 1D : \(f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}\)</li>
<li class="dash">En plusieurs dimensions : \(\nabla f(x) = \left( \frac{\partial f}{\partial x_1}, \dots, \frac{\partial f}{\partial x_n} \right)\)</li>
</ul>

<p>Par exemple si \(f(x) = x^2\) alors : </p>
<figure><img src="images/chap1_grad.png"  alt="" align="center" /><figcaption><ul><li class="dash">Pour \( x &lt; 0 \), gradient n√©gatif ‚Üí la fonction d√©cro√Æt.</li>
<li class="dash">Pour \( x &gt; 0 \), gradient positif ‚Üí la fonction cro√Æt.</li>
<li class="dash">Au minimum (en \( x=0 \)), gradient nul.</li>
</ul></figcaption></figure>
<div class="alert alert-info"><p>Pour minimiser la fonction de perte, il faut trouver \(x\) pour lequel \(\nabla f(x) = 0\). <br /><strong>Attention</strong> : un gradient nul peut aussi correspondre √† un maximum. En apprentissage, on esp√®re converger vers un minimum.</p>
</div>
</div><div class="slide ">
<a id="title.1.12.2"></a><h3>11.2. Principe de la r√©tropropagation</h3>
<p>Le principe de la r√©tropropagation signifie que PyTorch parcourt le graphe <strong>en sens inverse</strong> pour faire le calcul des d√©riv√©es. Si on repart sur l&#039;exemple de la section pr√©c√©dente, la r√©tropropagation dans PyTorch :</p>
<ol><li class="">Commence par la sortie <code>z</code>.</li>
<li class="">Recule vers les n≈ìuds pr√©c√©dents (<code>y</code> puis <code>x</code>) en appliquant la r√®gle de d√©rivation.</li>
<li class="">Stocke le gradient dans <code>x.grad</code>.</li>
</ol>

</div><div class="slide ">
<a id="title.1.12.3"></a><h3>11.3. Calcul des gradients dans notre exemple</h3>
<ul><li class="dash">\(\frac{dz}{dy} = 1\) car \(z = y.sum()\)</li>
<li class="dash">\(\frac{dy}{dx} =\) d√©riv√©e de \((x^2 + 3*x) = 2*x + 3\)</li>
<li class="dash">\(\frac{dz}{dx} = \frac{dz}{dy} * \frac{dy}{dx} = 2*x + 3\)</li>
</ul>

<p>On obtient donc :</p>
<pre><code class="python hljs">print(x.grad)  # tensor([7., 9.])</code></pre>
</div><div class="slide ">
<a id="title.1.12.4"></a><h3>11.4. D√©tail du calcul des gradients</h3>
<p>On a \(y = [y_1, y_2] = [x_1¬≤ + 3x_1,  x_2¬≤ + 3x_2]\) et \(z = y_1 + y_2\).</p>
<p><strong>√âtape 1 : d√©riv√©e de z par rapport √† y</strong></p>
<p>Comme \(z = y_1 + y_2\), on a \(\frac{dz}{dy_1} = 1\) et \(\frac{dz}{dy_2} = 1\).</p>
<p>On peut regrouper sous forme vectorielle, telle que \(\frac{dz}{dy} = [\frac{dz}{dy_1}, \frac{dz}{dy_2}] = [1, 1]\).</p>
<p><strong>√âtape 2 : d√©riv√©e de y par rapport √† x</strong></p>
<p>On a \(\frac{dy_1}{dx_1} = 2x_1 + 3\) et \(\frac{dy_2}{dx_2} = 2x_2 + 3\).
On peut aussi regrouper sous forme vectorielle, telle que \(\frac{dy}{dx} = [\frac{dy_1}{dx_1}, \frac{dy_2}{dx_2}] = [2x_1 + 3, 2x_2 + 3]\).</p>
<p><strong>√âtape 3 : application de la r√®gle de la cha√Æne</strong></p>
<p>Pour obtenir les d√©riv√©es de z par rapport √† x, on applique la r√®gle de la cha√Æne :</p>
<p>\(\frac{dz}{dx} = [\frac{dz}{dx_1}, \frac{dz}{dx_2}] = \frac{dz}{dy} * \frac{dy}{dx}\) et \(\frac{dz}{dx} = [\frac{dz}{dy_1}*\frac{dy_1}{dx_1}, \frac{dz}{dy_2}*\frac{dy_2}{dx_2}] = [1 * (2x_1 + 3), 1 * (2x_2 + 3)]\) </p>
<p>et donc \(\frac{dz}{dx} = [2x_1 + 3, 2x_2 + 3]\). </p>
</div><div class="slide ">
<a id="title.1.12.5"></a><h3>11.5. R√©sultat num√©rique pour notre exemple </h3>
<pre><code class="python hljs">print(x)       # tensor([2., 3.], requires_grad=True)
print(x.grad)  # tensor([7., 9.])</code></pre>
<p>Car :</p>
<ul><li class="dash">Pour \(x_1 = 2 ‚Üí \frac{dz}{dx_1} = 2*2 + 3 = 7\)</li>
<li class="dash">Pour \(x_2 = 3 ‚Üí \frac{dz}{dx_2} = 2*3 + 3 = 9\)</li>
</ul>

<p>Ainsi, Autograd reproduit automatiquement ce calcul gr√¢ce au graphe computationnel et √† la r√®gle de la cha√Æne.</p>
</div><div class="slide ">
<a id="title.1.13"></a><h2>üìñ 12. Manipuler les tenseurs sans gradients </h2>
<p>En PyTorch, il est souvent utile de s√©parer certaines op√©rations du calcul des gradients. Voici trois outils pour cela : <code>.detach()</code>, <code>.clone()</code> et <code>torch.no_grad()</code>.</p>
<a id="title.1.13.1"></a><h3>12.1. <code>.detach()</code></h3>
<ul><li class="dash">Cr√©e un nouveau tenseur avec les m√™mes valeurs que l‚Äôoriginal, mais sans suivre le calcul des gradients.</li>
<li class="dash">Utile pour utiliser ou visualiser des valeurs sans affecter la r√©tropropagation.</li>
</ul>

<pre><code class="python hljs">x = torch.tensor([1.0, 2.0], requires_grad=True)
y = x * 2
z = y.detach()  # z ne calcule pas de gradient
print(z)</code></pre>
</div><div class="slide ">
<a id="title.1.13.2"></a><h3>12.2. <code>.clone()</code></h3>
<ul><li class="dash">Cr√©e une copie ind√©pendante d‚Äôun tenseur.</li>
<li class="dash">La copie peut continuer √† calculer des gradients si `requires_grad=True`.</li>
<li class="dash">Utile pour conserver un √©tat avant modification.</li>
</ul>

<pre><code class="python hljs">y_clone = y.clone()
print(y_clone)</code></pre>
</div><div class="slide ">
<a id="title.1.13.3"></a><h3>12.3. <code>torch.no_grad()</code></h3>
<ul><li class="dash">Contexte qui emp√™che toutes les op√©rations √† l‚Äôint√©rieur de calculer des gradients.</li>
<li class="dash">Utile pour l&#039;√©valuation du mod√®le, quand on ne veut pas mettre √† jour les param√®tres du mod√®le.</li>
<li class="dash">Permet d&#039;√©conomiser de la m√©moire et d&#039;acc√©l√©rer les calculs.</li>
</ul>

<pre><code class="python hljs">with torch.no_grad():
    y_no_grad = x * 2
    print(y_no_grad)</code></pre>
</div><div class="slide ">
<a id="title.1.14"></a><h2>üìñ 13. Les fonctions de perte (Loss Functions)</h2>
<p>Lorsqu‚Äôon entra√Æne un r√©seau de neurones, l‚Äôobjectif est de minimiser l‚Äôerreur entre les pr√©dictions du mod√®le et les valeurs attendues. Cette erreur est mesur√©e par une fonction de perte (loss function en anglais).</p>
<p>Une fonction de perte prend en entr√©e :</p>
<ul><li class="dash">la sortie du mod√®le (la pr√©diction),</li>
<li class="dash">la valeur cible (la r√©ponse attendue, donn√©e par les donn√©es d‚Äôapprentissage),</li>
</ul>

<p>et retourne un nombre r√©el qui indique &quot;√† quel point le mod√®le s&#039;est tromp√©&quot;.</p>
<p>Par cons√©quent, plus la perte est grande ‚Üí plus le mod√®le se trompe et plus la perte est petite ‚Üí plus le mod√®le est proche de la bonne r√©ponse.</p>
</div><div class="slide ">
<a id="title.1.15"></a><h2>üìñ 14. Pourquoi la fonction de perte est essentielle ?</h2>
<p>La fonction de perte est essentielle pour plusieurs raisons :</p>
<ul><li class="dash">Elle quantifie l&#039;erreur du mod√®le : elle donne une mesure num√©rique de la performance du mod√®le.</li>
<li class="dash">Elle permet de guider l&#039;apprentissage : le mod√®le apprend en essayant de r√©duire cette valeur.</li>
<li class="dash">Elle est le point de d√©part de la r√©tropropagation : les gradients sont calcul√©s √† partir de la fonction de perte.</li>
<li class="dash">Elle est utilis√©e par les algorithmes d&#039;optimisation pour ajuster les param√®tres du mod√®le.</li>
<li class="dash">Elle permet de comparer diff√©rents mod√®les : en utilisant la m√™me fonction de perte, on peut √©valuer quel mod√®le est le meilleur.</li>
<li class="dash">Elle est essentielle pour le processus d&#039;entra√Ænement : sans fonction de perte, le mod√®le n&#039;aurait aucun signal pour savoir comment s‚Äôam√©liorer.</li>
</ul>

</div><div class="slide ">
<a id="title.1.16"></a><h2>üìñ 15. R√©gression &amp; Erreur quadratique moyenne (MSE)</h2>
<a id="title.1.16.1"></a><h3>15.1. D√©finitions</h3>
<p>On appelle r√©gression le cas o√π le mod√®le doit pr√©dire une valeur num√©rique par exemple : la temp√©rature demain, la taille d‚Äôune personne, etc.</p>
<p>Dans ce cas, la fonction de perte la plus utilis√©e est l‚Äôerreur quadratique moyenne (MSE de l&#039;anglais Mean Squared Error) :</p>
$$L(y, \hat{y}) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2,$$
<p>o√π :</p>
<ul><li class="dash">\(L\) est la fonction de perte,</li>
<li class="dash">\(n\) est le nombre de donn√©es,</li>
<li class="dash">\(y_i\) est la valeur attendue (target) et</li>
<li class="dash">\(\hat{y}_i\) est la pr√©diction du mod√®le.</li>
</ul>

<p>La fonction MSE calcule la moyenne des erreurs au carr√© de toutes les donn√©es.</p>
</div><div class="slide ">
<a id="title.1.16.2"></a><h3>15.2. Exemple d&#039;une r√©gression avec MSE dans PyTorch</h3>
<p>Pour utiliser la fonction MSE dans PyTorch, on peut utiliser la classe <code>nn.MSELoss()</code>. Pour cela, il faut d&#039;abord importer le module <code>torch.nn</code> qui contient les fonctions de perte :</p>
<pre><code class="python hljs">import torch.nn as nn</code></pre>
<p><strong>Exemple</strong> : </p>
<pre><code class="python hljs"># Valeurs r√©elles et pr√©dictions
y_true = torch.tensor([2.0, 3.0, 4.0])
y_pred = torch.tensor([2.5, 2.7, 4.2])

# D√©finition de la fonction de perte MSE
loss_fn = nn.MSELoss()

# Calcul de la perte
loss = loss_fn(y_pred, y_true)
print(loss)</code></pre>
</div><div class="slide ">
<a id="title.1.17"></a><h2>üìñ 16. Classification &amp; Entropie crois√©e</h2>
<a id="title.1.17.1"></a><h3>16.1. D√©finitions</h3>
<p>On appelle classification le cas o√π le mod√®le doit pr√©dire √† quelle cat√©gorie appartient la donn√©e parmi plusieurs possibles par exemple : &quot;chat&quot; ou &quot;chien&quot;, ou bien &quot;spam&quot; ou &quot;non spam&quot;, etc.</p>
<p>Dans ce cas, la fonction de perte la plus courante est l&#039;entropie crois√©e (Cross-Entropy Loss en anglais). Elle compare la probabilit√© pr√©dite par le mod√®le et la vraie cat√©gorie (donn√©e par les donn√©es d‚Äôapprentissage) :</p>
$$L(y, \hat{y}) = -\sum_{i=1}^n y_i \log(\hat{y}_i),$$
<p>o√π :</p>
<ul><li class="dash">\(L\) est la fonction de perte,</li>
<li class="dash">\(n\) est le nombre de classes,</li>
<li class="dash">\(y_i\) est la valeur attendue (target) pour la classe \(i\) ((souvent cod√©e en <em>one-hot encoding</em>, c&#039;est-√†-dire un vecteur avec un 1 pour la bonne classe et 0 pour les autres),</li>
<li class="dash">\(\hat{y}_i\) est la probabilit√© pr√©dite par le mod√®le pour la classe \(i\).</li>
</ul>

<p>La fonction enropie crois√©e mesure la distance entre la distribution de probabilit√© pr√©dite par le mod√®le et la distribution de probabilit√© r√©elle (la vraie classe).
La pr√©sence de la somme permet de prendre en compte toutes les classes.   Mais, dans le cas du <em>one-hot encoding</em>, seul le terme correspondant √† la vraie classe reste (puisque tous les autres \(y_i\) valent 0).</p>
</div><div class="slide ">
<a id="title.1.17.2"></a><h3>16.2. Pourquoi l&#039;entropie crois√©e ?</h3>
<p>L&#039;entropie crois√©e est utilis√©e car :</p>
<ul><li class="dash">Elle est adapt√©e aux probl√®mes de classification multi-classes.</li>
<li class="dash">Elle p√©nalise fortement les erreurs de classification, surtout lorsque la probabilit√© pr√©dite pour la classe correcte est faible.</li>
<li class="dash">Elle est diff√©rentiable, ce qui permet de l&#039;utiliser avec les algorithmes d&#039;optimisation bas√©s sur la r√©tropropagation.</li>
</ul>

</div><div class="slide ">
<a id="title.1.17.3"></a><h3>16.3. Exemple d&#039;une classification avec Cross-Entropy Loss </h3>
<p>Prenons un exemple o√π on a 3 classes possibles : &quot;Chat&quot;, &quot;Chien&quot;, &quot;Oiseau&quot;. Nous avons : </p>
<ul><li class="dash">La sortie du mod√®le suivante : \(\hat{y} = [0.7, 0.2, 0.1]\) et</li>
<li class="dash">imaginons que la vraie classe est &quot;Chat&quot;, donc \(y = [1, 0, 0]\).</li>
</ul>

<p>Alors :</p>
$$L = - \big( 1 \cdot \log(0.7) + 0 \cdot \log(0.2) + 0 \cdot \log(0.1) \big)$$
<p>Les termes multipli√©s par 0 disparaissent :</p>
$$L = -\log(0.7)$$
<p>üëâ La perte est faible car le mod√®le a donn√© une forte probabilit√© √† la bonne classe.</p>
<p>Si au contraire le mod√®le avait pr√©dit : \(\hat{y} = [0.2, 0.7, 0.1]\) :</p>
$$L = -\log(0.2)$$
<p>üëâ La perte serait plus grande, car la probabilit√© attribu√©e √† la bonne classe (&quot;Chat&quot;) est faible.</p>
</div><div class="slide ">
<a id="title.1.17.4"></a><h3>16.4. Le m√™me exemple dans PyTorch </h3>
<p>Pour utiliser la fonction Cross-Entropy Loss dans PyTorch, on peut utiliser la classe <code>nn.CrossEntropyLoss()</code> du module <code>torch.nn</code>.</p>
<pre><code class="python hljs"># D√©finition de la fonction de perte
loss_fn = nn.CrossEntropyLoss()

# Cas 1 : le mod√®le pr√©dit correctement (forte valeur pour &quot;Chat&quot;)
logits1 = torch.tensor([[2.0, 1.0, 0.1]])  # sortie brute du mod√®le qui sera convertie √† l&#039;aide d&#039;une fonction de PyTorch en probabilit√©s
y_true = torch.tensor([0])  # la vraie classe est &quot;Chat&quot; (indice 0)

loss1 = loss_fn(logits1, y_true)
print(&quot;Perte (bonne pr√©diction) :&quot;, loss1.item())

# Cas 2 : le mod√®le se trompe (forte valeur pour &quot;Chien&quot;)
logits2 = torch.tensor([[0.2, 2.0, 0.1]])  # sortie brute du mod√®le qui sera convertie √† l&#039;aide d&#039;une fonction de PyTorch en probabilit√©s
loss2 = loss_fn(logits2, y_true)
print(&quot;Perte (mauvaise pr√©diction) :&quot;, loss2.item())</code></pre>
</div><div class="slide ">
<a id="title.1.18"></a><h2>üìñ 17. Optimisation</h2>
<p>L‚Äôoptimisation est l‚Äô√©tape qui permet d‚Äôajuster les param√®tres du mod√®le pour qu‚Äôil r√©alise mieux la t√¢che demand√©e.  </p>
<p>L‚Äôid√©e est simple :  </p>
<ol><li class="">On calcule la perte (loss en anglais) qui indique l‚Äôerreur du mod√®le.</li>
<li class="">On calcule le gradient de la perte par rapport aux param√®tres (gr√¢ce √† Autograd).</li>
<li class="">On met √† jour les param√®tres dans la bonne direction (celle qui diminue la perte).</li>
</ol>

<p>C‚Äôest un processus it√©ratif qui se r√©p√®te jusqu‚Äô√† ce que le mod√®le apprenne correctement.</p>
</div><div class="slide ">
<a id="title.1.19"></a><h2>üìñ 18. Descente de gradient</h2>
<p>L‚Äôalgorithme d‚Äôoptimisation le plus courant est la descente de gradient (ou Gradient Descent en anglais). </p>
<a id="title.1.19.1"></a><h3>18.1. Principe et formule de la descente de gradient</h3>
<p>Imaginons une montagne : <br />- La hauteur correspond √† la valeur de la fonction de perte. <br />- Le but est de descendre la montagne pour atteindre la vall√©e (la perte minimale). <br />- Le gradient indique la pente : on suit la pente descendante pour r√©duire la perte.</p>
<p>Formule de mise √† jour des param√®tres :</p>
$$\theta_{new} = \theta_{old} - \eta \cdot \nabla_\theta L(\theta)$$
<p>o√π :  </p>
<ul><li class="dash">\(\theta\) repr√©sente l‚Äôensemble des param√®tres du mod√®le,</li>
<li class="dash">\(L\) est la fonction de perte,</li>
<li class="dash">\(\eta\) est le taux d‚Äôapprentissage (<em>learning rate</em> en anglais) : il contr√¥le la taille des pas et</li>
<li class="dash">\(\nabla_\theta L(\theta)\) d√©signe le vecteur des d√©riv√©es partielles de \(L\) par rapport √† chacun des param√®tres.</li>
</ul>

</div><div class="slide ">
<a id="title.1.19.2"></a><h3>üìñ 18.2. Exemple simple de la descente de gradient</h3>
<p>Prenons un exemple tr√®s simple : nous voulons ajuster un seul param√®tre \(a\) pour approximer une fonction.</p>
<p>Supposons que le mod√®le soit une droite passant par l‚Äôorigine :</p>
$$f(x) = a x$$
<p>Nous avons une donn√©e d‚Äôapprentissage :  </p>
<ul><li class="dash">Entr√©e : \(x = 2\)</li>
<li class="dash">Sortie attendue : \(y = 4\)</li>
</ul>

<p>On part du param√®tre initial : \(a = 0\).</p>
</div><div class="slide ">
<p><strong>1. Fonction de perte</strong></p>
<p>On utilise l‚Äôerreur quadratique (MSE) pour mesurer l‚Äô√©cart entre la pr√©diction et la vraie valeur :</p>
$$L(a) = (f(x) - y)^2 = (a * 2 - 4)^2$$
<p><strong>2. Calcul du gradient</strong></p>
<p>On d√©rive la perte par rapport √† \(a\) :</p>
$$\frac{\partial L}{\partial a} = 2 * (a * 2 - 4) * 2 = 8a - 16$$
</div><div class="slide ">
<p><strong>3. Mise √† jour avec descente de gradient</strong></p>
<p>On choisit un taux d‚Äôapprentissage \(\eta = 0.1\) et on applique la formule :</p>
$$a_{new} = a_{old} - \eta \cdot \frac{\partial L}{\partial a}$$
<p><strong>4. Exemple num√©rique</strong></p>
<ul><li class="dash">Point de d√©part : \(a = 0\)</li>
<li class="dash">Gradient : \(\frac{\partial L}{\partial a} = 8 * 0 - 16 = -16\)</li>
<li class="dash">Mise √† jour :</li>
</ul>

$$a_{new} = 0 - 0.1 * (-16) = 1.6$$
<p>üëâ Apr√®s une √©tape, \(a\) se rapproche d√©j√† de la bonne valeur (qui devrait √™tre \(a = 2\) pour que \(f(x) = 2 * 2 = 4\)).  </p>
<p>En r√©p√©tant plusieurs mises √† jour, \(a\) converge vers 2, et la perte devient de plus en plus faible.</p>
</div><div class="slide ">
<a id="title.1.20"></a><h2>üìñ 19. Descente de gradient avec PyTorch</h2>
<p>PyTorch fournit le module <code>torch.optim</code> qui impl√©mente plusieurs algorithmes d‚Äôoptimisation. Dans PyTorch, l‚Äôalgorithme de descente de gradient est appel√© SGD (Stochastic Gradient Descent) et peut √™tre import√© via <code>torch.optim.SGD</code> :</p>
<pre><code class="python hljs">import torch.optim as optim</code></pre>
<p>On reprend le mod√®le simple :</p>
<ul><li class="dash">Mod√®le : f(x) = a * x</li>
<li class="dash">Objectif : trouver a tel que f(x) ‚âà y</li>
<li class="dash">Jeu de donn√©es : x = [1, 2, 3, 4], y = [2, 4, 6, 8]</li>
<li class="dash">Param√®tre initial : a = 0</li>
<li class="dash">Taux d&#039;apprentissage : lr = 0.1</li>
</ul>

</div><div class="slide ">
<pre><code class="python hljs"># Donn√©es
x = torch.tensor([1.0, 2.0, 3.0, 4.0])
y = torch.tensor([2.0, 4.0, 6.0, 8.0])
a = torch.tensor([0.0], requires_grad=True)

# Optimiseur : descente de gradient
optimizer = optim.SGD([a], lr=0.1)

# Fonction de perte : MSE
loss_fn = nn.MSELoss()

for i in range(10):
    # 1. Remettre les gradients √† z√©ro avant de recalculer
    optimizer.zero_grad()
    
    # 2. Calcul de la pr√©diction
    y_pred = a * x
    
    # 3. Calcul de la perte avec MSE
    loss = loss_fn(y_pred, y)
    
    # 4. Calcul automatique des gradients
    loss.backward()
    
    # 5. Mise √† jour du param√®tre a
    optimizer.step()
    
    print(f&quot;Iter {i+1}: a = {a.item()}, loss = {loss.item()}&quot;)</code></pre>
<div class="alert alert-info"><p>Explications des nouvelles lignes de code :</p>
<ul><li class="dash"><code>optimizer.zero_grad()</code> : remet √† z√©ro les gradients calcul√©s lors de la derni√®re it√©ration.
   Sinon, PyTorch additionne les gradients √† chaque <code>backward()</code>, ce qui fausserait les calculs.</li>
<li class="dash"><code>optimizer.step()</code> : applique la mise √† jour des param√®tres selon la r√®gle de la descente de gradient :
   \(\theta_new = \theta_old - lr * gradient\).</li>
</ul>

</div>
<p>Dans cet exemple, SGD converge tr√®s vite car le probl√®me est simple.</p>
</div><div class="slide ">
<a id="title.1.21"></a><h2>üìñ 20. Optimiseur Adam</h2>
<a id="title.1.21.1"></a><h3>20.1. D√©finition</h3>
<p>Adam est un autre algorithme d&#039;optimisation qui adapte le pas pour chaque param√®tre gr√¢ce √† une moyenne mobile des gradients (\(m_t\) ) et une moyenne mobile des carr√©s des gradients (\(v_t\)).  </p>
<p>On d√©finit :</p>
<ul><li class="dash">\(g_t = \nabla_\theta L(\theta)\) : le gradient √† l&#039;it√©ration t</li>
<li class="dash">\(m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t\) : moyenne mobile des gradients (1er moment)</li>
<li class="dash">\(v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2\) : moyenne mobile des carr√©s des gradients (2e moment)</li>
<li class="dash">\(\hat{m}_t = \frac{m_t}{1-\beta_1^t}\) : correction de biais pour le 1er moment</li>
<li class="dash">\(\hat{v}_t = \frac{v_t}{1-\beta_2^t}\) : correction de biais pour le 2e moment</li>
<li class="dash">\(\epsilon\) : petite constante pour √©viter la division par z√©ro</li>
</ul>

<p>La mise √† jour des param√®tres est alors :</p>
$$\theta_{\text{new}} = \theta_{\text{old}} - \eta \cdot \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}$$
<p>üí° Interpr√©tation :</p>
<ul><li class="dash">\(m_t\) capture la direction moyenne des gradients (√©vite les oscillations),</li>
<li class="dash">\(v_t\) ajuste le pas selon la variance des gradients (pas plus grand si le gradient est bruit√©),</li>
<li class="dash">\(\epsilon\) emp√™che la division par z√©ro et</li>
<li class="dash">La correction de biais \(\hat{m}_t, \hat{v}_t\) est importante surtout au d√©but pour ne pas sous-estimer les moments.</li>
</ul>

</div><div class="slide ">
<a id="title.1.21.2"></a><h3>20.2. Adam vs. SGD</h3>
<blockquote><p>Diff√©rences entre Adam et la descente de gradient classique (SGD) :</p>
<ol><li class=""><strong>SGD</strong> applique la m√™me r√®gle de mise √† jour pour tous les param√®tres √† chaque it√©ration :
      \theta_new = \theta_old - lr * gradient</li>
<li class=""><strong>Adam</strong> adapte le taux d&#039;apprentissage pour chaque param√®tre individuellement,
      en utilisant des moyennes mobiles des gradients et des carr√©s des gradients. <br />      Cela permet souvent une convergence plus rapide et plus stable.</li>
<li class="">La syntaxe PyTorch reste tr√®s similaire : on utilise toujours <code>optimizer.zero_grad()</code>, <code>loss.backward()</code> et <code>optimizer.step()</code>. On peut reprendre le m√™me mod√®le simple que pr√©c√©demment √† titre d&#039;exemple.</li>
</ol>

</blockquote>
<div class="alert alert-info"><p>‚ö†Ô∏è Remarque : Dans le cadre de ce cours, nous utiliserons principalement Adam pour sa robustesse et sa facilit√© d&#039;utilisation. Nous allons surtout utiliser l&#039;impl√©mentation de ADAM dans Pytorch sans avoir √† recoder les √©quations. Elles sont √©nonc√©es √† titre informatif.</p>
</div>
</div><div class="slide ">
<a id="title.1.21.3"></a><h3>20.3. Impl√©mentation d&#039;Adam avec PyTorch</h3>
<p>Dans PyTorch, Adam est impl√©ment√© via <code>torch.optim.Adam</code> :</p>
<pre><code class="python hljs"># Donn√©es
x = torch.tensor([1.0, 2.0, 3.0, 4.0])
y = torch.tensor([2.0, 4.0, 6.0, 8.0])
a = torch.tensor([0.0], requires_grad=True)

# Optimiseur : Adam
optimizer = torch.optim.Adam([a], lr=0.1)

# Fonction de perte : MSE
loss_fn = nn.MSELoss()

for i in range(50):
    optimizer.zero_grad()  # remise √† z√©ro des gradients
    y_pred = a * x
    loss = loss_fn(y_pred, y)  # perte MSE
    loss.backward()  # calcul automatique des gradients
    optimizer.step()  # mise √† jour du param√®tre
    
    print(f&quot;Iter {i+1}: a = {a.item()}, loss = {loss.item()}&quot;)</code></pre>
<p>üí° Remarques :</p>
<ul><li class="dash">Pour des probl√®mes <strong>simples</strong> comme \(f(x)=ax\), SGD converge tr√®s vite et Adam peut sembler plus lent sur peu d‚Äôit√©rations.</li>
<li class="dash">Pour des <strong>mod√®les complexes</strong> avec beaucoup de param√®tres et des gradients bruit√©s, Adam est souvent plus efficace gr√¢ce √† ses ajustements adaptatifs.</li>
</ul>

</div><div class="slide ">
<a id="title.1.22"></a><h2>üèãÔ∏è Travaux Pratiques 1</h2>
<div class="toc"><ul><li><a href="TP_chap1.html#title.1">üèãÔ∏è Travaux Pratiques 1</a></li><ul><li><a href="TP_chap1.html#title.1.1">üçÄ Exercice 1 : Calculer le gradient d‚Äôune fonction simple avec PyTorch</a></li><li><a href="TP_chap1.html#title.1.2">‚öñÔ∏è Exercice 2 : Trouver la droite qui passe au mieux par les donn√©es avec MSE</a></li><li><a href="TP_chap1.html#title.1.3">‚öñÔ∏è Exercice 3 : Trouver la droite qui passe au mieux par les donn√©es avec une fonction de perte de type valeur absolue</a></li></ul><li><a href="TP_chap1.html#title.2">üèãÔ∏è Exercices suppl√©mentaires 1</a></li><ul><li><a href="TP_chap1.html#title.2.1">üçÄ Exercice suppl√©mentaire 1 : Gradient d‚Äôune fonction polynomiale</a></li><li><a href="TP_chap1.html#title.2.2">üçÄ Exercice suppl√©mentaire 2 : Gradient de deux variables</a></li><li><a href="TP_chap1.html#title.2.3">‚öñÔ∏è Exercice suppl√©mentaire 3 : Comparaison des fonctions de perte MSE et MAE</a></li><li><a href="TP_chap1.html#title.2.4">üå∂Ô∏è Exercice suppl√©mentaire 4 : Visualiser une surface de perte en 3D &amp; descente de gradient</a></li></ul></ul></div>
</div>
<nav><ul class="pagination justify-content-center"><li class="page-item"><a class="page-link" href="chap0.html">&larr; Chapitre 0 - Installation des paquets et bibliothques n√©cessaires pour le cours</a></li><li class="page-item"><a class="page-link" href="index.html"><i class="bi bi-folder2"></i> Introduction aux fondamentaux de l&#039;apprentissage supervis√© et du Deep Learning</a></li><li class="page-item"><a class="page-link" href="chap2.html">Chapitre 2 ‚Äî Perceptron multi-couches  &rarr;</a></li></ul></nav>

</div> <!-- /contents -->
</div> <!-- /core -->

</body>
</html>
