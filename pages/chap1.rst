
.. slide::

Chapitre 1 - Introduction √† PyTorch et Optimisation de Mod√®les
================

üéØ Objectifs du Chapitre
----------------------


.. important::

   √Ä la fin de ce chapitre, vous saurez : 

   - Cr√©er et manipuler des tenseurs PyTorch sur CPU et GPU.
   - Calculer automatiquement les gradients √† l‚Äôaide de ``autograd``.
   - D√©finir une fonction de perte.
   - Utiliser un optimiseur pour ajuster les param√®tres d‚Äôun mod√®le.
   - Impl√©menter une boucle d'entra√Ænement simple.

.. slide::

üìñ 1. Qu'est-ce que PyTorch ? 
----------------------
PyTorch est une biblioth√®que Python de machine learning open-source d√©velopp√©e par Facebook (FAIR). Elle est con√ßue pour faciliter la cr√©ation et l'entra√Ænement de mod√®les, en particulier dans le domaine du deep learning. 

Elle repose principalement sur deux √©l√©ments :

A) Les *tenseurs*, des structures de donn√©es similaires aux tableaux NumPy (``ndarray``), mais avec des fonctionnalit√©s suppl√©mentaires pour :
    
    - le calcul diff√©rentiel automatique,
    - l'acc√©l√©ration GPU,
    - l‚Äôentra√Ænement de r√©seaux de neurones.

B) Le module ``autograd`` permet de calculer automatiquement les gradients n√©cessaires √† l'entra√Ænement des mod√®les, en suivant toutes les op√©rations effectu√©es sur les tenseurs.

.. slide::

D'autres biblioth√®ques Python similaires existent, comme :

- TensorFlow : d√©velopp√© par Google, tr√®s utilis√© pour des d√©ploiements √† grande √©chelle.
- Keras : interface haut niveau de TensorFlow, plus simple mais moins flexible.
- JAX : plus r√©cent, optimis√© pour la recherche et les calculs scientifiques √† haute performance.

.. slide::

Dans le cadre de ce cours, nous utiliserons PyTorch car :

- elle est largement adopt√©e par la communaut√© de la recherche en deep learning,
- elle est plus lisible et plus facile √† d√©boguer que TensorFlow et JAX,
- elle offre plus de possibilit√©s que Keras,
- elle est bien document√©e et est l'une des biblioth√®ques les plus utilis√©es en science des donn√©es (Data Science en anglais) et en apprentissage machine (Machine Learning en anglais).

.. slide::

üìñ 2. Qu'est-ce qu'un tenseur ?
----------------------

Les **tenseurs** sont la structure de base de PyTorch. Ce sont des tableaux multidimensionnels similaires aux ``ndarray`` de NumPy, mais avec des fonctionnalit√©s suppl√©mentaires pour le GPU et le calcul automatique des gradients. Un tenseur est une structure de donn√©es qui g√©n√©ralise les matrices √† un nombre quelconque de dimensions:

- Un scalaire est un tenseur 0D.  
- Un vecteur est un tenseur 1D.  
- Une matrice est un tenseur 2D.  
- On peut avoir des tenseurs 3D, 4D, etc.   

Les tenseurs √† haute dimensions sont tr√®s utilis√©s en deep learning (par exemple pour les images ou les vid√©os). Nous allons voir comment cr√©er et manipuler des tenseurs dans PyTorch. Vous pouvez copier-coller les exemples de code ci-dessous dans un notebook Jupyter pour les tester et voir les affichages. Pour utiliserles fonctions de PyTorch, il faut d'abord l'importer :
.. code-block:: python

   import torch

.. slide::
    
üìñ 3. Cr√©ation de tenseurs
----------------------

Il existe plusieurs mani√®res de cr√©er un tenseur en PyTorch.

3.1. √Ä partir de donn√©es Python (listes ou tuples)
~~~~~~~~~~~~~~~~~~~

.. code-block:: python

   # Depuis une liste
   a = torch.tensor([1, 2, 3])
   print(a)

   # Depuis une liste de listes (matrice)
   b = torch.tensor([[1, 2, 3], [4, 5, 6]])
   print(b)

   # On peut aussi sp√©cifier le type de donn√©es
   c = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)
   print(c, c.dtype)

.. slide::
3.2. Avec des fonctions de construction
~~~~~~~~~~~~~~~~~~~
.. code-block:: python

   # Tenseur rempli de z√©ros
   z = torch.zeros(2, 3)
   print(z)

   # Tenseur rempli de uns
   o = torch.ones(2, 3)
   print(o)

   # Tenseur vide (valeurs non initialis√©es)
   e = torch.empty(2, 3)
   print(e)

   # Identit√© (matrice diagonale)
   eye = torch.eye(3)
   print(eye)

.. slide::
3.3. Avec des suites r√©guli√®res
~~~~~~~~~~~~~~~~~~~
PyTorch permet de g√©n√©rer facilement des suites de nombres avec des pas r√©guliers. Deux fonctions sont particuli√®rement utiles :

1. **torch.arange(debut, fin, pas)**  

   - Cr√©e une suite en commen√ßant √† ``debut``  
   - S‚Äôarr√™te *avant* ``fin`` (attention, la borne sup√©rieure est exclue !)  
   - Utilise le ``pas`` indiqu√©  

.. code-block:: python

   # De 0 √† 8 inclus, avec un pas de 2
   r = torch.arange(0, 10, 2)
   print("torch.arange(0, 10, 2) :", r)

   # De 5 √† 20 exclu, avec un pas de 3
   r2 = torch.arange(5, 20, 3)
   print("torch.arange(5, 20, 3) :", r2)

   # ‚ö†Ô∏è Remarque : la borne sup√©rieure (ici 10 ou 20) n'est jamais incluse

.. slide::
2. **torch.linspace(debut, fin, steps)**  

   - Cr√©e une suite de ``steps`` valeurs r√©guli√®rement espac√©es  
   - Inclut **√† la fois** ``debut`` et ``fin``  

.. code-block:: python

   # 5 valeurs entre 0 et 1 inclus
   l = torch.linspace(0, 1, steps=5)
   print("torch.linspace(0, 1, steps=5) :", l)

   # 4 valeurs entre -1 et 1 inclus
   l2 = torch.linspace(-1, 1, steps=4)
   print("torch.linspace(-1, 1, steps=4) :", l2)

**R√©sum√© des diff√©rences**

- ``arange`` ‚Üí on fixe le **pas** entre les valeurs, la fin est exclue.  
- ``linspace`` ‚Üí on fixe le **nombre de valeurs**, la fin est incluse.  

Exemple comparatif :

.. code-block:: python

   print(torch.arange(0, 1, 0.25))   # [0.00, 0.25, 0.50, 0.75]
   print(torch.linspace(0, 1, 5))    # [0.00, 0.25, 0.50, 0.75, 1.00]


.. slide::
3.4. Avec des nombres al√©atoires
~~~~~~~~~~~~~~~~~~~

.. code-block:: python
   # Attention dans les exemples suivants, les crochets [] veulent dire que la valeur de la borne est incluse, contrairement √† aux parenth√®ses () qui signifient que la borne est exclue.
   # Uniforme entre [0, 1)
   u = torch.rand(2, 2)
   print("Uniforme [0,1) :\n", u)

   # Distribution normale (moyenne=0, √©cart-type=1)
   n = torch.randn(2, 2)
   print("Normale standard (0,1) :\n", n)

   # Distribution normale avec moyenne (mean) et √©cart-type (std) choisis
   custom = torch.normal(mean=2.0, std=3.0, size=(2,2))
   print("Normale (moyenne=10, √©cart-type=2) :\n", custom)

   # Fixer la graine pour la reproductibilit√©
   torch.manual_seed(42)
   print("Reproductibilit√© :\n", torch.rand(2, 2))  # toujours le m√™me r√©sultat


.. slide::
üìñ 4. Conna√Ætre la forme d'un tenseur
------------------------

Un tenseur peut avoir n‚Äôimporte quelle dimension. La m√©thode ``.shape`` permet de conna√Ætre sa taille.

.. code-block:: python

   # Scalaire (0D)
   s = torch.tensor(5)
   print("Scalaire :", s, "shape =", s.shape)

   # Vecteur (1D)
   v = torch.tensor([1, 2, 3, 4])
   print("Vecteur :", v, "shape =", v.shape)

   # Matrice (2D)
   m = torch.tensor([[1, 2, 3], [4, 5, 6]])
   print("Matrice :\n", m, "shape =", m.shape)

   # Tenseur 3D (par exemple, 2 matrices de taille 3x3)
   t3 = torch.zeros(2, 3, 3)
   print("Tenseur 3D shape =", t3.shape)

   # Tenseur 4D (par exemple, un mini-batch de 10 images RGB de 32x32)
   t4 = torch.zeros(10, 3, 32, 32)
   print("Tenseur 4D shape =", t4.shape)


.. slide::
üìñ 5. Types de tenseurs et conversion
------------------------

- Vous pouvez sp√©cifier le type de donn√©es (``dtype``) lors de la cr√©ation :

.. code-block:: python

   x = torch.tensor([1.2, 3.4, 5.6])
   print(x.dtype)     # float32 par d√©faut

   x_int = x.to(torch.int32)
   print(x_int, x_int.dtype)

   x_float64 = x.double()
   print(x_float64, x_float64.dtype)

- Conversion d‚Äôun tenseur existant :

.. code-block:: python

   x_int = x.to(torch.int32)
   print(x_int.dtype)

.. slide::
üìñ 6. Op√©rations de base
------------------------

PyTorch supporte de nombreuses op√©rations sur les tenseurs :

.. code-block:: python

   a = torch.tensor([1, 2, 3])
   b = torch.tensor([4, 5, 6])

   # Addition
   print(a + b)

   # Multiplication √©l√©ment par √©l√©ment
   print(a * b)

   # Produit matriciel
   mat1 = torch.rand(2, 3)
   mat2 = torch.rand(3, 4)
   print(torch.mm(mat1, mat2))

.. slide::
üìñ 7. Tenseurs sur GPU
------------------------

Pour profiter de l‚Äôacc√©l√©ration GPU, il suffit de d√©placer un tenseur sur le device CUDA :

.. code-block:: python

   if torch.cuda.is_available():
       device = torch.device("cuda")
       x_gpu = x.to(device)
       print("Tenseur sur GPU :", x_gpu)
   else:
       print("Pas de GPU disponible, utilisation du CPU.")

.. slide::
üìñ 8.  Manipulation avanc√©e des tenseurs
--------------------

Une fois cr√©√©s, les tenseurs peuvent √™tre transform√©s et r√©arrang√©s. PyTorch fournit de nombreuses fonctions pour modifier leur forme, leurs dimensions ou leur ordre.

8.1. Changer la forme avec ``view`` et ``reshape``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``view`` : retourne un nouveau tenseur qui partage la m√™me m√©moire que l‚Äôoriginal. Cela implique que le tenseur soit contigu. Un tenseur est dit contigu lorsque ses donn√©es sont stock√©es de mani√®re cons√©cutive en m√©moire, c‚Äôest-√†-dire que PyTorch peut lire tous les √©l√©ments dans l‚Äôordre sans sauts.  
Certaines op√©rations, comme la transposition (``t()``), rendent le tenseur non contigu, et dans ce cas ``view`` √©choue.
- ``reshape`` : similaire √† ``view``, mais plus flexible car il tente d‚Äôutiliser la m√©moire existante, mais cr√©e une copie si n√©cessaire. ``reshape`` fonctionne dans tous les cas de figures.

.. code-block:: python

   x = torch.arange(12)   # tenseur 1D [0, 1, ..., 11]
   print("x :", x)

   # Transformer en matrice 3x4
   x_view = x.view(3, 4)
   print("view en 3x4 :\n", x_view)

   # Transformer en matrice 2x6
   x_reshape = x.reshape(2, 6)
   print("reshape en 2x6 :\n", x_reshape)

.. slide::
Autre exemple pour illustrer la diff√©rence entre ``view`` et ``reshape`` :

.. code-block:: python

   # Cr√©ation d'un tenseur 2x3
   x = torch.arange(6).view(2, 3)
   print("x :\n", x)
   print("Contigu :", x.is_contiguous())

   # Transposition ‚Üí rend le tenseur non contigu
   y = x.t()
   print("\ny (transpos√©) :\n", y)
   print("Contigu :", y.is_contiguous())

   # view √©choue sur un tenseur non contigu
   try:
       z = y.view(6)
   except Exception as e:
       print("\nErreur avec view :", e)

   # reshape fonctionne toujours
   z2 = y.reshape(6)
   print("\nreshape fonctionne :", z2)

.. slide::
8.2. Changer l‚Äôordre des dimensions : ``permute``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``permute`` r√©arrange les dimensions dans un nouvel ordre.  
- Tr√®s utile pour manipuler les donn√©es d‚Äôimages ou de s√©quences.

.. code-block:: python

   # Exemple avec un tenseur 3D (batch, hauteur, largeur)
   t = torch.randn(2, 3, 4)  # forme (2, 3, 4)
   print("Tenseur original :", t.shape)

   # Inverser l'ordre (largeur, hauteur, batch)
   p = t.permute(2, 1, 0)
   print("Apr√®s permute :", p.shape)

.. slide::
8.3. Ajouter ou supprimer des dimensions : ``unsqueeze`` et ``squeeze``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``unsqueeze(dim)`` : ajoute une dimension de taille 1 √† la position ``dim``.  
- ``squeeze()`` : supprime toutes les dimensions de taille 1.  

.. code-block:: python

   v = torch.tensor([1, 2, 3])
   print("Forme initiale :", v.shape)

   v_unsq = v.unsqueeze(0)  # ajoute une dimension au d√©but
   print("Apr√®s unsqueeze(0) :", v_unsq.shape)

   v_sq = v_unsq.squeeze()  # supprime les dimensions de taille 1
   print("Apr√®s squeeze() :", v_sq.shape)

.. slide::
8.4. Concat√©ner ou empiler des tenseurs
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``torch.cat`` : concat√®ne le long d‚Äôune dimension existante.  
- ``torch.stack`` : empile en ajoutant une nouvelle dimension.  

.. code-block:: python

   a = torch.tensor([1, 2, 3])
   b = torch.tensor([4, 5, 6])

   cat = torch.cat((a, b), dim=0)
   print("torch.cat :", cat)

   stack = torch.stack((a, b), dim=0)
   print("torch.stack :", stack)
   print("Forme de stack :", stack.shape)

.. slide::
üìñ 9. Autograd avec PyTorch
-----------------------

En Deep Learning, nous travaillons souvent avec des fonctions compliqu√©es d√©pendant de plusieurs variables. Pour entra√Æner un mod√®le, nous avons besoin de calculer automatiquement les d√©riv√©es de ces fonctions. C'est l√† qu'intervient Autograd qui est le moteur de diff√©rentiation automatique de PyTorch. 

9.1. Cr√©ation d'un tenseur suivi
~~~~~~~~~~~~~~~~~~~

Pour qu'un tenseur suive les op√©rations et calcule les gradients automatiquement, il faut d√©finir ``requires_grad=True`` :

.. code-block:: python

    x = torch.tensor([2.0, 3.0], requires_grad=True)
    print(x)

Ici, ``x`` est maintenant un tenseur avec suivi des gradients. Toutes les op√©rations futures sur ce tenseur seront enregistr√©es pour pouvoir calculer les d√©riv√©es automatiquement.


.. slide::
9.2. Op√©rations sur les tenseurs
~~~~~~~~~~~~~~~~~~~

Toutes les op√©rations effectu√©es sur ce tenseur sont automatiquement enregistr√©es dans un graphe computationnel dynamique.

.. code-block:: python

    y = x ** 2 + 3 * x # y = [y1, y2]
    print(y)

Dans ce cas :

- ``x`` est la variable d'entr√©e.
- ``y`` est calcul√© √† partir de ``x`` avec les op√©rations ``x**2`` et ``3*x``.

Chaque op√©ration devient un n≈ìud du graphe et PyTorch garde la trace des d√©pendances pour pouvoir calculer les gradients.

.. slide::
üìñ 10. Graphe computationnel
-----------------------------

Un graphe computationnel est une structure qui repr√©sente toutes les op√©rations effectu√©es sur les tenseurs. Chaque n≈ìud du graphe correspond √† un tenseur ou √† une op√©ration math√©matique, et les ar√™tes indiquent les d√©pendances entre eux.

10.1. ``torchviz``
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Pour visualiser le graphe dans PyTorch, on peut utiliser ``torchviz`` (qu'il faudra installer avec ``pip install torchviz``)  :

.. code-block:: python

    from torchviz import make_dot

    z = y.sum()
    make_dot(z, params={'x': x})

Cela produira une image avec des n≈ìuds pour chaque op√©ration et des fl√®ches indiquant les d√©pendances :

- Les n≈ìuds $$x^2$$ et $$3x$$ repr√©sentent les op√©rations effectu√©es sur $$x$$.
- Le n≈ìud $$y$$ combine ces deux r√©sultats.
- Le graphe permet √† PyTorch de savoir quelles d√©riv√©es calculer et dans quel ordre.

.. slide::
10.2. Note sur le graphe g√©n√©r√© par PyTorch
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Quand on visualise le graphe interne avec un outil comme ``torchviz`` :

- Le **bloc jaune avec ()** correspond au tenseur final (ici ``z``).
- Les **blocs interm√©diaires** (``PowBackward0``, ``AddBackward0``, etc.) repr√©sentent
  les op√©rations qui seront diff√©renti√©es telles que ``PowBackward0`` est l'op√©ration op√©ration inverse associ√©e √† ``x**2``, ``MulBackward0`` celle associ√©e √† ``3*x``, 
  ``AddBackward0`` combine les deux r√©sultats et repr√©sente ``y`` et enfin ``SumBackward0`` correspond au ``y.sum()`` qui est √©gal √† ``z``.
- Le **bloc ``AccumulateGrad``** correspond √† l‚Äôendroit o√π le gradient est stock√©
  dans la variable d‚Äôentr√©e (ici ``x.grad``).

.. slide::
üìñ 11. Calcul des gradients et r√©tropropagation 
-----------------------

Autograd utilise ce graphe pour calculer automatiquement les d√©riv√©es par rapport √† ``x``, en utilisant la m√©thode ``backward()`` :

.. code-block:: python
    z = y.sum()  # z = y1 + y2
    z.backward()
    print(x.grad)

- ``backward()`` calcule les d√©riv√©es de ``z`` par rapport √† chaque √©l√©ment de ``x``.
- ``x.grad`` contient maintenant les gradients.

11.1. Principe de la r√©tropropagation
~~~~~~~~~~~~~~~~~

Le principe de la r√©tropropagation signifie PyTorch parcourt le graphe **en sens inverse** pour faire le calcul des d√©riv√©es.


1. Commence par la sortie ``z``.
2. Recule vers les n≈ìuds pr√©c√©dents (``y`` puis ``x``) en appliquant la r√®gle de d√©rivation.
3. Stocke le gradient dans ``x.grad``.

.. slide::
11.2. Calcul des gradients dans notre exemple
~~~~~~~~~~~~~~~~~

- $$\frac{dz}{dy} = 1$$ car $$z = y.sum()$$ 
- $$\frac{dy}{dx} =$$ d√©riv√©e de $$(x^2 + 3*x) = 2*x + 3$$
- $$\frac{dz}{dx} = \frac{dz}{dy} * \frac{dy}{dx} = 2*x + 3$$

On obtient donc :

.. code-block:: python

    print(x.grad)  # tensor([7., 9.])

.. slide::
11.3. D√©tail du calcul des gradients
~~~~~~~~~~~~~~~~~

On a $$y = [y_1, y_2] = [x_1¬≤ + 3x_1,  x_2¬≤ + 3x_2]$$ et $$z = y_1 + y_2$$.


**√âtape 1 : d√©riv√©e de z par rapport √† y**

Comme $$z = y_1 + y_2$$, on a $$\frac{dz}{dy_1} = 1$$ et $$\frac{dz}{dy_2} = 1$$.

On peut regrouper sous forme vectorielle, telle que $$\frac{dz}{dy} = [\frac{dz}{dy_1}, \frac{dz}{dy_2}] = [1, 1]$$.

**√âtape 2 : d√©riv√©e de y par rapport √† x**

On a $$\frac{dy_1}{dx_1} = 2x_1 + 3$$ et $$\frac{dy_2}{dx_2} = 2x_2 + 3$$.
On peut aussi regrouper sous forme vectorielle, telle que $$\frac{dy}{dx} = [\frac{dy_1}{dx_1}, \frac{dy_2}{dx_2}] = [2x_1 + 3, 2x_2 + 3]$$.

**√âtape 3 : application de la r√®gle de la cha√Æne**

Pour obtenir les d√©riv√©es de z par rapport √† x, on applique la r√®gle de la cha√Æne :

$$\frac{dz}{dx} = [\frac{dz}{dx_1}, \frac{dz}{dx_2}] = \frac{dz}{dy} * \frac{dy}{dx}$$ et $$\frac{dz}{dx} = [\frac{dz}{dy_1}*\frac{dy_1}{dx_1}, \frac{dz}{dy_2}*\frac{dy_2}{dx_2}] = [1 * (2x_1 + 3), 1 * (2x_2 + 3)]$$ 

et donc $$\frac{dz}{dx} = [2x_1 + 3, 2x_2 + 3]$$. 

.. slide::
11.4. R√©sultat num√©rique pour notre exemple 
~~~~~~~~~~~~~~~~~

.. code-block:: python

    print(x)       # tensor([2., 3.], requires_grad=True)
    print(x.grad)  # tensor([7., 9.])

Car :

- Pour $$x_1 = 2 ‚Üí \frac{dz}{dx_1} = 2*2 + 3 = 7$$
- Pour $$x_2 = 3 ‚Üí \frac{dz}{dx_2} = 2*3 + 3 = 9$$

Ainsi, Autograd reproduit automatiquement ce calcul gr√¢ce au graphe computationnel et √† la r√®gle de la cha√Æne.


.. slide::
üìñ 12. D√©sactivation du suivi des gradients
---------------------

Pour certaines op√©rations, par exemple lors de l'√©valuation d'un mod√®le, il est inutile
de calculer les gradients. On peut alors d√©sactiver le suivi avec ``torch.no_grad()`` :

.. code-block:: python

    with torch.no_grad():
        z = x * 2
    print(z)

Cela permet d'√©conomiser de la m√©moire et d'acc√©l√©rer les calculs.

.. slide::
üìñ 13. Les fonctions de perte (Loss Functions)
-------------------------------

Lorsqu‚Äôon entra√Æne un r√©seau de neurones, l‚Äôobjectif est de minimiser l‚Äôerreur entre les pr√©dictions du mod√®le et les valeurs attendues. Cette erreur est mesur√©e par une fonction de perte (loss function en anglais).

Une fonction de perte prend en entr√©e :

    - la sortie du mod√®le (la pr√©diction),
    - la valeur cible (la r√©ponse attendue, donn√©e par les donn√©es d‚Äôapprentissage),

et retourne un nombre r√©el qui indique "√† quel point le mod√®le s'est tromp√©".

Par cons√©quent, plus la perte est grande ‚Üí plus le mod√®le se trompe et plus la perte est petite ‚Üí plus le mod√®le est proche de la bonne r√©ponse.

.. slide::
üìñ 14. Pourquoi la fonction de perte est essentielle ?
----------------------------------------------------
La fonction de perte est essentielle pour plusieurs raisons :

    - Elle quantifie l'erreur du mod√®le : elle donne une mesure num√©rique de la performance du mod√®le.
    - Elle permet de guider l'apprentissage : le mod√®le apprend en essayant de r√©duire cette valeur.
    - Elle est le point de d√©part de la r√©tropropagation : les gradients sont calcul√©s √† partir de la fonction de perte.
    - Elle est utilis√©e par les algorithmes d'optimisation pour ajuster les param√®tres du mod√®le.
    - Elle permet de comparer diff√©rents mod√®les : en utilisant la m√™me fonction de perte, on peut √©valuer quel mod√®le est le meilleur.
    - Elle est essentielle pour le processus d'entra√Ænement : sans fonction de perte, le mod√®le n'aurait aucun signal pour savoir comment s‚Äôam√©liorer.

.. slide::
üìñ 15. R√©gression & Erreur quadratique moyenne (MSE)
----------------------------------------------------

15.1. D√©finitions
~~~~~~~~~~~~~~~~~
On appelle r√©gression le cas o√π le mod√®le doit pr√©dire une valeur num√©rique par exemple : la temp√©rature demain, la taille d‚Äôune personne, etc.

Dans ce cas, la fonction de perte la plus utilis√©e est l‚Äôerreur quadratique moyenne (MSE de l'anglais Mean Squared Error) :

.. math::

   L(y, \hat{y}) = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2,

o√π :

    - $$L$$ est la fonction de perte,
    - $$n$$ est le nombre de donn√©es,
    - $$y_i$$ est la valeur attendue (target) et
    - $$\hat{y}_i$$ est la pr√©diction du mod√®le.

La fonction MSE calcule la moyenne des erreurs au carr√©es de toutes les donn√©es.

.. slide::
15.2. Exemple d'une r√©gression avec MSE dans PyTorch
~~~~~~~~~~~~~~~~~~~~~
Pour utiliser la fonction MSE dans PyTorch, on peut utiliser la classe ``nn.MSELoss()``. Pour cela, il faut d'abord importer le module ``torch.nn`` qui contient les fonctions de perte :
.. code-block:: python

    import torch.nn as nn

**Exemple** : 

.. code-block:: python

    # Valeurs r√©elles et pr√©dictions
    y_true = torch.tensor([2.0, 3.0, 4.0])
    y_pred = torch.tensor([2.5, 2.7, 4.2])

    # D√©finition de la fonction de perte MSE
    loss_fn = nn.MSELoss()

    # Calcul de la perte
    loss = loss_fn(y_pred, y_true)
    print(loss)

.. slide::
üìñ 16. Classification & Entropie crois√©e
------------------------------------------------------------

16.1. D√©finitions
~~~~~~~~~~~~~~~~~~~

On appelle classification le cas o√π le mod√®le doit pr√©dire √† quelle cat√©gorie appartient la donn√©e parmi plusieurs possibles par exemple : "chat" ou "chien", ou bien "spam" ou "non spam", etc.

Dans ce cas, la fonction de perte la plus courante est l'entropie crois√©e (Cross-Entropy Loss en anglais). Elle compare la probabilit√© pr√©dite par le mod√®le et la vraie cat√©gorie (donn√©e par les donn√©es d‚Äôapprentissage) :

.. math::
   L(y, \hat{y}) = -\sum_{i=1}^n y_i \log(\hat{y}_i),
o√π :

    - $$L$$ est la fonction de perte,
    - $$n$$ est le nombre de classes,
    - $$y_i$$ est la valeur attendue (target) pour la classe $$i$$ ((souvent cod√©e en *one-hot encoding*, c'est-√†-dire un vecteur avec un 1 pour la bonne classe et 0 pour les autres),
    - $$\hat{y}_i$$ est la probabilit√© pr√©dite par le mod√®le pour la classe $$i$$.

La fonction enropie crois√©e mesure la distance entre la distribution de probabilit√© pr√©dite par le mod√®le et la distribution de probabilit√© r√©elle (la vraie classe).
La pr√©sence de la somme permet de prendre en compte toutes les classes.   Mais, dans le cas du *one-hot encoding*, seul le terme correspondant √† la vraie classe reste (puisque tous les autres $$y_i$$ valent 0).

.. slide::
16.2. Pourquoi l'entropie crois√©e ?
~~~~~~~~~~~~~~~~~~~
L'entropie crois√©e est utilis√©e car :

    - Elle est adapt√©e aux probl√®mes de classification multi-classes.
    - Elle p√©nalise fortement les erreurs de classification, surtout lorsque la probabilit√© pr√©dite pour la classe correcte est faible.
    - Elle est diff√©rentiable, ce qui permet de l'utiliser avec les algorithmes d'optimisation bas√©s sur la r√©tropropagation.

.. slide::
16.3. Exemple d'une classification avec Cross-Entropy Loss 
~~~~~~~~~~~~~~~~~~~~
Prenons un exemple o√π on a 3 classes possibles : "Chat", "Chien", "Oiseau". Nous avons : 

- La sortie du mod√®le suivante : $$\hat{y} = [0.7, 0.2, 0.1]$$ et
- imaginons que la vraie classe est "Chat", donc $$y = [1, 0, 0]$$.

Alors :

.. math::

    L = - \big( 1 \cdot \log(0.7) + 0 \cdot \log(0.2) + 0 \cdot \log(0.1) \big)

Les termes multipli√©s par 0 disparaissent :

.. math::

    L = -\log(0.7)

üëâ La perte est faible car le mod√®le a donn√© une forte probabilit√© √† la bonne classe.

Si au contraire le mod√®le avait pr√©dit : $$\hat{y} = [0.2, 0.7, 0.1]$$ :

.. math::

    L = -\log(0.2)

üëâ La perte serait plus grande, car la probabilit√© attribu√©e √† la bonne classe ("Chat") est faible.


.. slide::
16.4. Le m√™me exemple dans PyTorch 
~~~~~~~~~~~~~~~~~~~~

Pour utiliser la fonction Cross-Entropy Loss dans PyTorch, on peut utiliser la classe ``nn.CrossEntropyLoss()`` du module ``torch.nn``.

.. code-block:: python

    # D√©finition de la fonction de perte
    loss_fn = nn.CrossEntropyLoss()

    # Cas 1 : le mod√®le pr√©dit correctement (forte valeur pour "Chat")
    logits1 = torch.tensor([[2.0, 1.0, 0.1]])  # sortie brute du mod√®le qui sera convertie √† l'aide d'une fonction de PyTorch en probabilit√©s
    y_true = torch.tensor([0])  # la vraie classe est "Chat" (indice 0)

    loss1 = loss_fn(logits1, y_true)
    print("Perte (bonne pr√©diction) :", loss1.item())

    # Cas 2 : le mod√®le se trompe (forte valeur pour "Chien")
    logits2 = torch.tensor([[0.2, 2.0, 0.1]])  # sortie brute du mod√®le qui sera convertie √† l'aide d'une fonction de PyTorch en probabilit√©s
    loss2 = loss_fn(logits2, y_true)
    print("Perte (mauvaise pr√©diction) :", loss2.item())

.. slide::
üìñ 17. Optimisation
-----------------------

L‚Äôoptimisation est l‚Äô√©tape qui permet d‚Äôajuster les param√®tres du mod√®le pour qu‚Äôil r√©alise mieux la t√¢che demand√©e.  

L‚Äôid√©e est simple :  

1. On calcule la perte (loss en anglais) qui indique l‚Äôerreur du mod√®le.  
2. On calcule le gradient de la perte par rapport aux param√®tres (gr√¢ce √† Autograd).  
3. On met √† jour les param√®tres dans la bonne direction (celle qui diminue la perte).  

C‚Äôest un processus it√©ratif qui se r√©p√®te jusqu‚Äô√† ce que le mod√®le apprenne correctement.


.. slide::
üìñ 18. Descente de gradient
-----------------------

L‚Äôalgorithme d‚Äôoptimisation le plus courant est la descente de gradient (ou Gradient Descent en anglais). 

18.1. Principe et formule de la descente de gradient
~~~~~~~~~~~~~~~~~~~~~~~~~~~

Imaginons une montagne :  
- La hauteur correspond √† la valeur de la fonction de perte.  
- Le but est de descendre la montagne pour atteindre la vall√©e (la perte minimale).  
- Le gradient indique la pente : on suit la pente descendante pour r√©duire la perte.

Formule de mise √† jour des param√®tres :

.. math::

   \theta_{new} = \theta_{old} - \eta \cdot \nabla_\theta L(\theta)

o√π :  

- $$\theta$$ repr√©sente l‚Äôensemble des param√®tres du mod√®le,  
- $$L$$ est la fonction de perte,  
- $$\eta$$ est le taux d‚Äôapprentissage (*learning rate* en anglais) : il contr√¥le la taille des pas et  
- $$\nabla_\theta L(\theta)$$ d√©signe le vecteur des d√©riv√©es partielles de $$L$$ par rapport √† chacun des param√®tres.  


.. slide::
üìñ 18.2. Exemple simple de la descente de gradient
~~~~~~~~~~~~~~~~~~~~~~~~
Prenons un exemple tr√®s simple : nous voulons ajuster un seul param√®tre $$a$$ pour approximer une fonction.

Supposons que le mod√®le soit une droite passant par l‚Äôorigine :

.. math::

   f(x) = a x

Nous avons une donn√©e d‚Äôapprentissage :  

- Entr√©e : $$x = 2$$  
- Sortie attendue : $$y = 4$$  

On part du param√®tre initial : $$a = 0$$.

.. slide::
**1. Fonction de perte**

On utilise l‚Äôerreur quadratique (MSE) pour mesurer l‚Äô√©cart entre la pr√©diction et la vraie valeur :

.. math::

   L(a) = (f(x) - y)^2 = (a * 2 - 4)^2


**2. Calcul du gradient**

On d√©rive la perte par rapport √† $$a$$ :

.. math::

   \frac{\partial L}{\partial a} = 2 * (a * 2 - 4) * 2 = 8a - 16

.. slide::

**3. Mise √† jour avec descente de gradient**

On choisit un taux d‚Äôapprentissage $$\eta = 0.1$$ et on applique la formule :

.. math::

   a_{new} = a_{old} - \eta \cdot \frac{\partial L}{\partial a}


**4. Exemple num√©rique**

- Point de d√©part : $$a = 0$$  
- Gradient : $$\frac{\partial L}{\partial a} = 8 * 0 - 16 = -16$$  
- Mise √† jour :  

.. math::

   a_{new} = 0 - 0.1 * (-16) = 1.6

üëâ Apr√®s une √©tape, $$a$$ se rapproche d√©j√† de la bonne valeur (qui devrait √™tre $$a = 2$$ pour que $$f(x) = 2 * 2 = 4$$).  

En r√©p√©tant plusieurs mises √† jour, $$a$$ converge vers 2, et la perte devient de plus en plus faible.


.. slide::
üìñ 19. Descente de gradient avec PyTorch
----------------------------------------

PyTorch fournit le module ``torch.optim`` qui impl√©mente plusieurs algorithmes d‚Äôoptimisation. Dans PyTorch, l‚Äôalgorithme de descente de gradient est appel√© SGD (Stochastic Gradient Descent) et peut-√™tre import√© via ``torch.optim.SGD`` :

.. code-block:: python
   import torch.optim as optim

On reprend le mod√®le simple :

- Mod√®le : f(x) = a * x
- Objectif : trouver a tel que f(x) ‚âà y
- Jeu de donn√©es : x = [1, 2, 3, 4], y = [2, 4, 6, 8]
- Param√®tre initial : a = 0
- Taux d'apprentissage : lr = 0.1

.. slide::
.. code-block:: python
    # Donn√©es
    x = torch.tensor([1.0, 2.0, 3.0, 4.0])
    y = torch.tensor([2.0, 4.0, 6.0, 8.0])
    a = torch.tensor([0.0], requires_grad=True)

    # Optimiseur : descente de gradient
    optimizer = optim.SGD([a], lr=0.1)

    # Fonction de perte : MSE
    loss_fn = nn.MSELoss()

    for i in range(10):
        # 1. Remettre les gradients √† z√©ro avant de recalculer
        optimizer.zero_grad()
        
        # 2. Calcul de la pr√©diction
        y_pred = a * x
        
        # 3. Calcul de la perte avec MSE
        loss = loss_fn(y_pred, y)
        
        # 4. Calcul automatique des gradients
        loss.backward()
        
        # 5. Mise √† jour du param√®tre a
        optimizer.step()
        
        print(f"Iter {i+1}: a = {a.item()}, loss = {loss.item()}")

.. note::

      Explications des nouvelles lignes de code :

         - ``optimizer.zero_grad()`` : remet √† z√©ro les gradients calcul√©s lors de la derni√®re it√©ration.  
         Sinon, PyTorch additionne les gradients √† chaque ``backward()``, ce qui fausserait les calculs.
         
         - ``optimizer.step()`` : applique la mise √† jour des param√®tres selon la r√®gle de la descente de gradient :  
         $$\theta_new = \theta_old - lr * gradient$$.
         

Dans cet exemple, SGD converge tr√®s vite car le probl√®me est simple.
 
.. slide::
üìñ 20. Optimiseur Adam
--------------------------------------

20.1. D√©finition
~~~~~~~~~~~~~~~~~~
Adam est un autre algorithme d'optimisation qui adapte le pas pour chaque param√®tre gr√¢ce √† une moyenne mobile des gradients ($$m_t$$ ) et une moyenne mobile des carr√©s des gradients ($$v_t$$).  

On d√©finit :

- $$g_t = \nabla_\theta L(\theta)$$ : le gradient √† l'it√©ration t  
- $$m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t$$ : moyenne mobile des gradients (1er moment)  
- $$v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2$$ : moyenne mobile des carr√©s des gradients (2e moment)  
- $$\hat{m}_t = \frac{m_t}{1-\beta_1^t}$$ : correction de biais pour le 1er moment  
- $$\hat{v}_t = \frac{v_t}{1-\beta_2^t}$$ : correction de biais pour le 2e moment  
- $$\epsilon$$ : petite constante pour √©viter la division par z√©ro  

La mise √† jour des param√®tres est alors :

.. math::
  \theta_{\text{new}} = \theta_{\text{old}} - \eta \cdot \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}

üí° Interpr√©tation :

- $$m_t$$ capture la direction moyenne des gradients (√©vite les oscillations),  
- $$v_t$$ ajuste le pas selon la variance des gradients (pas plus grand si le gradient est bruit√©),  
- $$\epsilon$$ emp√™che la division par z√©ro et
- La correction de biais $$\hat{m}_t, \hat{v}_t$$ est importante surtout au d√©but pour ne pas sous-estimer les moments.

.. slide::
20.2. Adam vs. SGD
~~~~~~~~~~~~~~~~~~~~~
 Diff√©rences entre Adam et la descente de gradient classique (SGD) :

    1. **SGD** applique la m√™me r√®gle de mise √† jour pour tous les param√®tres √† chaque it√©ration :  
       \theta_new = \theta_old - lr * gradient
       
    2. **Adam** adapte le taux d'apprentissage pour chaque param√®tre individuellement,  
       en utilisant des moyennes mobiles des gradients et des carr√©s des gradients.  
       Cela permet souvent une convergence plus rapide et plus stable.
    
    3. La syntaxe PyTorch reste tr√®s similaire : on utilise toujours ``optimizer.zero_grad()``, ``loss.backward()`` et ``optimizer.step()``. On peut reprendre le m√™me mod√®le simple que pr√©c√©demment √† titre d'exemple.

.. note::
   ‚ö†Ô∏è Remarque : Dans le cadre de ce cours, nous utiliserons principalement Adam pour sa robustesse et sa facilit√© d'utilisation. Nous allons surtout utiliser l'impl√©mentation de ADAM dans Pytorch sans avoir √† recoder les √©quations. Elles sont √©nonc√©es √† titre informatif.

.. slide::
20.3. Impl√©mentation d'Adam avec PyTorch
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Dans PyTorch, Adam est impl√©ment√© via ``torch.optim.Adam`` :

.. code-block:: python
    # Donn√©es
    x = torch.tensor([1.0, 2.0, 3.0, 4.0])
    y = torch.tensor([2.0, 4.0, 6.0, 8.0])
    a = torch.tensor([0.0], requires_grad=True)

    # Optimiseur : Adam
    optimizer = torch.optim.Adam([a], lr=0.1)

    # Fonction de perte : MSE
    loss_fn = nn.MSELoss()

    for i in range(50):
        optimizer.zero_grad()  # remise √† z√©ro des gradients
        y_pred = a * x
        loss = loss_fn(y_pred, y)  # perte MSE
        loss.backward()  # calcul automatique des gradients
        optimizer.step()  # mise √† jour du param√®tre
        
        print(f"Iter {i+1}: a = {a.item()}, loss = {loss.item()}")

üí° Remarques :

   - Pour des probl√®mes **simples** comme $$f(x)=ax$$, SGD converge tr√®s vite et Adam peut sembler plus lent sur peu d‚Äôit√©rations.  
   - Pour des **mod√®les complexes** avec beaucoup de param√®tres et des gradients bruit√©s, Adam est souvent plus efficace gr√¢ce √† ses ajustements adaptatifs.

.. slide::
üèãÔ∏è Travaux Pratiques 1
--------------------

.. toctree::

    TP_chap1