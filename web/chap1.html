<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8" />
<link rel="stylesheet" type="text/css" href="css/style.css" />
<title>Intro Python - Chapitre 1 - Introduction √† PyTorch et Optimisation de Mod√®les</title>

                <meta http-equiv="X-UA-Compatible" content="IE=edge">
                <meta name="viewport" content="viewport-fit=cover, width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
            

                <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
                <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
            
<link href="https://fonts.googleapis.com/css2?family=Gentium+Basic&display=swap" rel="stylesheet"> 
<link rel="stylesheet" type="text/css" href="slidey/bootstrap/css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" href="slidey/bootstrap-icons/font/bootstrap-icons.css" />
<link rel="stylesheet" type="text/css" href="slidey/highlight.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.menu.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.step.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.code.css" />
<link rel="stylesheet" type="text/css" href="slidey/slidey.slide.css" />
<script type="text/javascript" src="slidey/js/jquery.js"></script>
<script type="text/javascript" src="slidey/js/slidey.permalink.js"></script>
<script type="text/javascript" src="slidey/js/slidey.menu.js"></script>
<script type="text/javascript" src="slidey/js/slidey.mobile.js"></script>
<script type="text/javascript" src="slidey/js/slidey.spoilers.js"></script>
<script type="text/javascript" src="slidey/js/slidey.steps.js"></script>
<script type="text/javascript" src="slidey/js/slidey.js"></script>
<script type="text/javascript" src="slidey/js/main.js"></script>
<script type="text/javascript" src="slidey/bootstrap/js/bootstrap.min.js"></script>
<script type="text/javascript" src="slidey/highlight/highlight.pack.js"></script>
<link rel="icon" type="image/x-icon" href="favicon.ico" />
</head>
<body>
<!-- Modal log-in window -->
<div class="modal fade" id="loginWindow">
  <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-header">
            <h5 class="modal-title">Log-in</h5>
            <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
          </div>    
        <div class="modal-body">
            <form>
                Mot de passe&nbsp;:<br />
                <input class="form-control" type="password" name="password" />
            </form>
        </div>
      </div><!-- /.modal-content -->
    </div><!-- /.modal-dialog -->
</div>

<div class="core">

    <script>hljs.highlightAll();</script>

<!-- Extra-controls for mobile device -->
<div class="mobileControls">
    <div class="btn-group">
        <a href="javascript:void(0)" class="left btn btn-light btn-lg">
            <i class="bi bi-arrow-up"></i>
        </a>
        <a href="javascript:void(0)" class="right btn btn-light btn-lg">
            <i class="bi bi-arrow-down"></i>
        </a>
        <a href="javascript:void(0)" class="up btn btn-light btn-lg">
            <i class="bi bi-arrow-left"></i>
        </a>
        <a href="javascript:void(0)" class="down btn btn-light btn-lg">
            <i class="bi bi-arrow-right"></i>
        </a>
        <a href="javascript:void(0)" class="login btn btn-light btn-lg">
            <i class="bi bi-lock"></i>
        </a>
    </div>
</div>

<!-- Controls -->
<div class="slideMode">
    <div class="btn-group">
        <a href="javascript:void(0)" class="btn btn-light btn-lg slideModeSlide"><i class="bi bi-film"></i></a>
        <a href="javascript:void(0)" class="btn btn-light btn-lg followMode"><i class="bi bi-stopwatch"></i> </a>
        <a href="index.html" class="btn btn-light btn-lg goHome"><i class="bi bi-house"></i></a>
    </div>
</div>

<div class="exitSlideMode">
    <div class="btn-group">
        <a href="javascript:void(0)" class="btn btn-light btn-lg followMode"><i class="bi bi-stopwatch"></i></a>
        <a href="javascript:void(0)" class="btn btn-light btn-lg showMobile"><i class="bi bi-phone"></i></a>
        <a href="javascript:void(0)" class="btn btn-light btn-lg stopShow">
            <span class="currentSlideNumber">
            </span>
            <i class="bi bi-x-lg"></i>
        </a>
    </div>
</div>

<!-- Browsing menu -->
<div class="menu">
</div>

<div class="contents container">

<div class="slide ">
<a id="title.1"></a><h1>Chapitre 1 - Introduction √† PyTorch et Optimisation de Mod√®les</h1>
<a id="title.1.1"></a><h2>üéØ Objectifs du Chapitre</h2>
<div class="alert alert-light p-2 fs-5 text-center"><p>√Ä la fin de ce chapitre, vous saurez : </p>
<ul><li class="dash">Cr√©er et manipuler des tenseurs PyTorch sur CPU et GPU.</li>
<li class="dash">Calculer automatiquement les gradients √† l‚Äôaide de <code>autograd</code>.</li>
<li class="dash">D√©finir une fonction de co√ªt.</li>
<li class="dash">Utiliser un optimiseur pour ajuster les param√®tres d‚Äôun mod√®le.</li>
<li class="dash">Impl√©menter une boucle d&#039;entra√Ænement simple.</li>
</ul>

</div>
</div><div class="slide ">
<a id="title.1.2"></a><h2>üìñ 1. Qu&#039;est-ce que PyTorch ? </h2>
<p>PyTorch est une biblioth√®que Python de machine learning open-source d√©velopp√©e par Facebook (FAIR). Elle est con√ßue pour faciliter la cr√©ation et l&#039;entra√Ænement de mod√®les, en particulier dans le domaine du deep learning. </p>
<p>Elle repose principalement sur deux √©l√©ments :</p>
<p>A) Les <em>tenseurs</em>, des structures de donn√©es similaires aux tableaux NumPy (<code>ndarray</code>), mais avec des fonctionnalit√©s suppl√©mentaires pour :</p>
<ul><li class="dash">le calcul diff√©rentiel automatique,</li>
<li class="dash">l&#039;acc√©l√©ration GPU,</li>
<li class="dash">l‚Äôentra√Ænement de r√©seaux de neurones.</li>
</ul>

<p>B) Le module <code>autograd</code> permet de calculer automatiquement les gradients n√©cessaires √† l&#039;entra√Ænement des mod√®les, en suivant toutes les op√©rations effectu√©es sur les tenseurs.</p>
</div><div class="slide ">
<p>D&#039;autres biblioth√®ques Python similaires existent, comme :</p>
<ul><li class="dash">TensorFlow : d√©velopp√© par Google, tr√®s utilis√© pour des d√©ploiements √† grande √©chelle.</li>
<li class="dash">Keras : interface haut niveau de TensorFlow, plus simple mais moins flexible.</li>
<li class="dash">JAX : plus r√©cent, optimis√© pour la recherche et les calculs scientifiques √† haute performance.</li>
</ul>

</div><div class="slide ">
<p>Dans le cadre de ce cours, nous utiliserons PyTorch car :</p>
<ul><li class="dash">elle est largement adopt√©e par la communaut√© de la recherche en deep learning,</li>
<li class="dash">elle est plus lisible et plus facile √† d√©boguer que TensorFlow et JAX,</li>
<li class="dash">elle offre plus de possibilit√©s que Keras,</li>
<li class="dash">elle est bien document√©e et est l&#039;une des biblioth√®ques les plus utilis√©es en science des donn√©es (Data Science en anglais) et en apprentissage machine (Machine Learning en anglais).</li>
</ul>

</div><div class="slide ">
<a id="title.1.3"></a><h2>üìñ 2. Qu&#039;est-ce qu&#039;un tenseur ?</h2>
<p>Les <strong>tenseurs</strong> sont la structure de base de PyTorch. Ce sont des tableaux multidimensionnels similaires aux <code>ndarray</code> de NumPy, mais avec des fonctionnalit√©s suppl√©mentaires pour le GPU et le calcul automatique des gradients. Un tenseur est une structure de donn√©es qui g√©n√©ralise les matrices √† un nombre quelconque de dimensions:</p>
<ul><li class="dash">Un scalaire est un tenseur 0D.</li>
<li class="dash">Un vecteur est un tenseur 1D.</li>
<li class="dash">Une matrice est un tenseur 2D.</li>
<li class="dash">On peut avoir des tenseurs 3D, 4D, etc.</li>
</ul>

<p>Les tenseurs √† haute dimensions sont tr√®s utilis√©s en deep learning (par exemple pour les images ou les vid√©os). Nous allons voir comment cr√©er et manipuler des tenseurs dans PyTorch. Vous pouvez copier-coller les exemples de code ci-dessous dans un notebook Jupyter pour les tester et voir les affichages. Pour utiliserles fonctions de PyTorch, il faut d&#039;abord l&#039;importer :</p>
<pre><code class="python hljs">import torch</code></pre>
</div><div class="slide ">
<a id="title.1.4"></a><h2>üìñ 3. Cr√©ation de tenseurs</h2>
<p>Il existe plusieurs mani√®res de cr√©er un tenseur en PyTorch.</p>
<a id="title.1.4.1"></a><h3>3.1 √Ä partir de donn√©es Python (listes ou tuples)</h3>
<pre><code class="python hljs"># Depuis une liste
a = torch.tensor([1, 2, 3])
print(a)

# Depuis une liste de listes (matrice)
b = torch.tensor([[1, 2, 3], [4, 5, 6]])
print(b)

# On peut aussi sp√©cifier le type de donn√©es
c = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)
print(c, c.dtype)</code></pre>
</div><div class="slide ">
<a id="title.1.4.2"></a><h3>3.2 Avec des fonctions de construction</h3>
<pre><code class="python hljs"># Tenseur rempli de z√©ros
z = torch.zeros(2, 3)
print(z)

# Tenseur rempli de uns
o = torch.ones(2, 3)
print(o)

# Tenseur vide (valeurs non initialis√©es)
e = torch.empty(2, 3)
print(e)

# Identit√© (matrice diagonale)
eye = torch.eye(3)
print(eye)</code></pre>
</div><div class="slide ">
<a id="title.1.4.3"></a><h3>3.3 Avec des suites r√©guli√®res</h3>
<p>PyTorch permet de g√©n√©rer facilement des suites de nombres avec des pas r√©guliers. Deux fonctions sont particuli√®rement utiles :</p>
<ol><li class=""><strong>torch.arange(debut, fin, pas)</strong></li>
<ul><li class="dash">Cr√©e une suite en commen√ßant √† <code>debut</code></li>
<li class="dash">S‚Äôarr√™te <em>avant</em> <code>fin</code> (attention, la borne sup√©rieure est exclue !)</li>
<li class="dash">Utilise le <code>pas</code> indiqu√©</li>
</ul>
</ol>

<pre><code class="python hljs"># De 0 √† 8 inclus, avec un pas de 2
r = torch.arange(0, 10, 2)
print(&quot;torch.arange(0, 10, 2) :&quot;, r)

# De 5 √† 20 exclu, avec un pas de 3
r2 = torch.arange(5, 20, 3)
print(&quot;torch.arange(5, 20, 3) :&quot;, r2)

# ‚ö†Ô∏è Remarque : la borne sup√©rieure (ici 10 ou 20) n&#039;est jamais incluse</code></pre>
</div><div class="slide ">
<ol><li class=""><strong>torch.linspace(debut, fin, steps)</strong></li>
<ul><li class="dash">Cr√©e une suite de <code>steps</code> valeurs r√©guli√®rement espac√©es</li>
<li class="dash">Inclut <strong>√† la fois</strong> <code>debut</code> et <code>fin</code></li>
</ul>
</ol>

<pre><code class="python hljs"># 5 valeurs entre 0 et 1 inclus
l = torch.linspace(0, 1, steps=5)
print(&quot;torch.linspace(0, 1, steps=5) :&quot;, l)

# 4 valeurs entre -1 et 1 inclus
l2 = torch.linspace(-1, 1, steps=4)
print(&quot;torch.linspace(-1, 1, steps=4) :&quot;, l2)</code></pre>
<p><strong>R√©sum√© des diff√©rences</strong></p>
<ul><li class="dash"><code>arange</code> ‚Üí on fixe le <strong>pas</strong> entre les valeurs, la fin est exclue.</li>
<li class="dash"><code>linspace</code> ‚Üí on fixe le <strong>nombre de valeurs</strong>, la fin est incluse.</li>
</ul>

<p>Exemple comparatif :</p>
<pre><code class="python hljs">print(torch.arange(0, 1, 0.25))   # [0.00, 0.25, 0.50, 0.75]
print(torch.linspace(0, 1, 5))    # [0.00, 0.25, 0.50, 0.75, 1.00]</code></pre>
</div><div class="slide ">
<a id="title.1.4.4"></a><h3>3.4 Avec des nombres al√©atoires</h3>
<pre><code class="python hljs"># Attention dans les exemples suivants, les crochets [] veulent dire que la valeur de la borne est incluse, contrairement √† aux parenth√®ses () qui signifient que la borne est exclue.
# Uniforme entre [0, 1)
u = torch.rand(2, 2)
print(&quot;Uniforme [0,1) :\n&quot;, u)

# Distribution normale (moyenne=0, √©cart-type=1)
n = torch.randn(2, 2)
print(&quot;Normale standard (0,1) :\n&quot;, n)

# Distribution normale avec moyenne (mean) et √©cart-type (std) choisis
custom = torch.normal(mean=2.0, std=3.0, size=(2,2))
print(&quot;Normale (moyenne=10, √©cart-type=2) :\n&quot;, custom)

# Fixer la graine pour la reproductibilit√©
torch.manual_seed(42)
print(&quot;Reproductibilit√© :\n&quot;, torch.rand(2, 2))  # toujours le m√™me r√©sultat</code></pre>
</div><div class="slide ">
<a id="title.1.5"></a><h2>üìñ 4. Conna√Ætre la forme d&#039;un tenseur</h2>
<p>Un tenseur peut avoir n‚Äôimporte quelle dimension. La m√©thode <code>.shape</code> permet de conna√Ætre sa taille.</p>
<pre><code class="python hljs"># Scalaire (0D)
s = torch.tensor(5)
print(&quot;Scalaire :&quot;, s, &quot;shape =&quot;, s.shape)

# Vecteur (1D)
v = torch.tensor([1, 2, 3, 4])
print(&quot;Vecteur :&quot;, v, &quot;shape =&quot;, v.shape)

# Matrice (2D)
m = torch.tensor([[1, 2, 3], [4, 5, 6]])
print(&quot;Matrice :\n&quot;, m, &quot;shape =&quot;, m.shape)

# Tenseur 3D (par exemple, 2 matrices de taille 3x3)
t3 = torch.zeros(2, 3, 3)
print(&quot;Tenseur 3D shape =&quot;, t3.shape)

# Tenseur 4D (par exemple, un mini-batch de 10 images RGB de 32x32)
t4 = torch.zeros(10, 3, 32, 32)
print(&quot;Tenseur 4D shape =&quot;, t4.shape)</code></pre>
</div><div class="slide ">
<a id="title.1.6"></a><h2>üìñ 5. Types de tenseurs et conversion</h2>
<ul><li class="dash">Vous pouvez sp√©cifier le type de donn√©es (<code>dtype</code>) lors de la cr√©ation :</li>
</ul>

<pre><code class="python hljs">x = torch.tensor([1.2, 3.4, 5.6])
print(x.dtype)     # float32 par d√©faut

x_int = x.to(torch.int32)
print(x_int, x_int.dtype)

x_float64 = x.double()
print(x_float64, x_float64.dtype)</code></pre>
<ul><li class="dash">Conversion d‚Äôun tenseur existant :</li>
</ul>

<pre><code class="python hljs">x_int = x.to(torch.int32)
print(x_int.dtype)</code></pre>
</div><div class="slide ">
<a id="title.1.7"></a><h2>üìñ 6. Op√©rations de base</h2>
<p>PyTorch supporte de nombreuses op√©rations sur les tenseurs :</p>
<pre><code class="python hljs">a = torch.tensor([1, 2, 3])
b = torch.tensor([4, 5, 6])

# Addition
print(a + b)

# Multiplication √©l√©ment par √©l√©ment
print(a * b)

# Produit matriciel
mat1 = torch.rand(2, 3)
mat2 = torch.rand(3, 4)
print(torch.mm(mat1, mat2))</code></pre>
</div><div class="slide ">
<a id="title.1.8"></a><h2>üìñ 7. Tenseurs sur GPU</h2>
<p>Pour profiter de l‚Äôacc√©l√©ration GPU, il suffit de d√©placer un tenseur sur le device CUDA :</p>
<pre><code class="python hljs">if torch.cuda.is_available():
    device = torch.device(&quot;cuda&quot;)
    x_gpu = x.to(device)
    print(&quot;Tenseur sur GPU :&quot;, x_gpu)
else:
    print(&quot;Pas de GPU disponible, utilisation du CPU.&quot;)</code></pre>
</div><div class="slide ">
<a id="title.1.9"></a><h2>üìñ 8.  Manipulation avanc√©e des tenseurs</h2>
<p>Une fois cr√©√©s, les tenseurs peuvent √™tre transform√©s et r√©arrang√©s. PyTorch fournit de nombreuses fonctions pour modifier leur forme, leurs dimensions ou leur ordre.</p>
<a id="title.1.9.1"></a><h3>8.1 Changer la forme avec <code>view</code> et <code>reshape</code></h3>
<ul><li class="dash"><code>view</code> : retourne un nouveau tenseur qui partage la m√™me m√©moire que l‚Äôoriginal. Cela implique que le tenseur soit contigu. Un tenseur est dit contigu lorsque ses donn√©es sont stock√©es de mani√®re cons√©cutive en m√©moire, c‚Äôest-√†-dire que PyTorch peut lire tous les √©l√©ments dans l‚Äôordre sans sauts.
Certaines op√©rations, comme la transposition (`t()`), rendent le tenseur non contigu, et dans ce cas <code>view</code> √©choue.</li>
<li class="dash"><code>reshape</code> : similaire √† <code>view</code>, mais plus flexible car il tente d‚Äôutiliser la m√©moire existante, mais cr√©e une copie si n√©cessaire. <code>reshape</code> fonctionne dans tous les cas de figures.</li>
</ul>

<pre><code class="python hljs">x = torch.arange(12)   # tenseur 1D [0, 1, ..., 11]
print(&quot;x :&quot;, x)

# Transformer en matrice 3x4
x_view = x.view(3, 4)
print(&quot;view en 3x4 :\n&quot;, x_view)

# Transformer en matrice 2x6
x_reshape = x.reshape(2, 6)
print(&quot;reshape en 2x6 :\n&quot;, x_reshape)</code></pre>
<p>Autre exemple pour illustrer la diff√©rence entre <code>view</code> et <code>reshape</code> :</p>
<pre><code class="python hljs"># Cr√©ation d&#039;un tenseur 2x3
x = torch.arange(6).view(2, 3)
print(&quot;x :\n&quot;, x)
print(&quot;Contigu :&quot;, x.is_contiguous())

# Transposition ‚Üí rend le tenseur non contigu
y = x.t()
print(&quot;\ny (transpos√©) :\n&quot;, y)
print(&quot;Contigu :&quot;, y.is_contiguous())

# view √©choue sur un tenseur non contigu
try:
    z = y.view(6)
except Exception as e:
    print(&quot;\nErreur avec view :&quot;, e)

# reshape fonctionne toujours
z2 = y.reshape(6)
print(&quot;\nreshape fonctionne :&quot;, z2)</code></pre>
</div><div class="slide ">
<a id="title.1.9.2"></a><h3>8.2 Changer l‚Äôordre des dimensions : <code>permute</code></h3>
<ul><li class="dash"><code>permute</code> r√©arrange les dimensions dans un nouvel ordre.</li>
<li class="dash">Tr√®s utile pour manipuler les donn√©es d‚Äôimages ou de s√©quences.</li>
</ul>

<pre><code class="python hljs"># Exemple avec un tenseur 3D (batch, hauteur, largeur)
t = torch.randn(2, 3, 4)  # forme (2, 3, 4)
print(&quot;Tenseur original :&quot;, t.shape)

# Inverser l&#039;ordre (largeur, hauteur, batch)
p = t.permute(2, 1, 0)
print(&quot;Apr√®s permute :&quot;, p.shape)</code></pre>
</div><div class="slide ">
<a id="title.1.9.3"></a><h3>8.3 Ajouter ou supprimer des dimensions : <code>unsqueeze</code> et <code>squeeze</code></h3>
<ul><li class="dash"><code>unsqueeze(dim)</code> : ajoute une dimension de taille 1 √† la position <code>dim</code>.</li>
<li class="dash"><code>squeeze()</code> : supprime toutes les dimensions de taille 1.</li>
</ul>

<pre><code class="python hljs">v = torch.tensor([1, 2, 3])
print(&quot;Forme initiale :&quot;, v.shape)

v_unsq = v.unsqueeze(0)  # ajoute une dimension au d√©but
print(&quot;Apr√®s unsqueeze(0) :&quot;, v_unsq.shape)

v_sq = v_unsq.squeeze()  # supprime les dimensions de taille 1
print(&quot;Apr√®s squeeze() :&quot;, v_sq.shape)</code></pre>
</div><div class="slide ">
<a id="title.1.9.4"></a><h3>8.4 Concat√©ner ou empiler des tenseurs</h3>
<ul><li class="dash"><code>torch.cat</code> : concat√®ne le long d‚Äôune dimension existante.</li>
<li class="dash"><code>torch.stack</code> : empile en ajoutant une nouvelle dimension.</li>
</ul>

<pre><code class="python hljs">a = torch.tensor([1, 2, 3])
b = torch.tensor([4, 5, 6])

cat = torch.cat((a, b), dim=0)
print(&quot;torch.cat :&quot;, cat)

stack = torch.stack((a, b), dim=0)
print(&quot;torch.stack :&quot;, stack)
print(&quot;Forme de stack :&quot;, stack.shape)</code></pre>
</div><div class="slide ">
</div>
<nav><ul class="pagination justify-content-center"><li class="page-item"><a class="page-link" href="chap0.html">&larr; Chapitre 0 - Installation des paquets et bibliothques n√©cessaires pour le cours</a></li><li class="page-item"><a class="page-link" href="index.html"><i class="bi bi-folder2"></i> Introduction aux fondamentaux de l&#039;apprentissage supervis√© et du Deep Learning</a></li></ul></nav>

</div> <!-- /contents -->
</div> <!-- /core -->

</body>
</html>
